[[{"query":"open \"data.csv\" file","hypotheses":[{"id":0,"score":0.0,"value":"Data \u003d namedtuple(\"Data\", next(reader))"},{"id":0,"score":0.0,"value":"next(reader)"},{"id":0,"score":0.0,"value":"import csv\nfrom collections import namedtuple\nfrom itertools import imap\n\nwith open(\"data_file.txt\", mode\u003d\"rb\") as infile:\n    reader \u003d csv.reader(infile)\n    Data \u003d namedtuple(\"Data\", next(reader))  # get names from column headers\n    for data in imap(Data._make, reader):\n        print data.foo\n        # ...further processing of a line..."},{"id":0,"score":0.0,"value":"import csv\nfrom collections import namedtuple\n\nwith open(\"data_file.txt\", newline\u003d\"\") as infile:\n    reader \u003d csv.reader(infile)\n    Data \u003d namedtuple(\"Data\", next(reader))  # get names from column headers\n    for data in map(Data._make, reader):\n        print(data.foo)\n        # ...further processing of a line..."},{"id":0,"score":0.0,"value":"with open(\u0027data_file.txt\u0027) as infile:\n    reader \u003d csv.DictReader(infile)\n    Data \u003d collections.namedtuple(\u0027Data\u0027, reader.fieldnames)\n    tuples \u003d [Data(**row) for row in reader]"},{"id":0,"score":0.0,"value":"import pandas as pd\ndata \u003d pd.read_csv(\u0027google-us-data.csv.gz\u0027, nrows\u003d100, compression\u003d\u0027gzip\u0027,\n                   error_bad_lines\u003dFalse)\nprint(data)"},{"id":0,"score":0.0,"value":"a,54.2\ns,78.5\nk,89.62\na,77.2\na,65.56"}]},{"query":"open csv file","hypotheses":[{"id":0,"score":0.0,"value":"\u003copen file \u0027amount2.csv\u0027, mode \u0027r\u0027 at 0x1004656f0\u003e"},{"id":0,"score":0.0,"value":"with open(\u0027test.csv\u0027, \u0027rb\u0027) as f:\n    reader \u003d csv.reader(f)\n    for row in reader:\n        # row is a list of strings\n        # use string.join to put them together\n        print \u0027, \u0027.join(row)"},{"id":0,"score":0.0,"value":"changes \u003d [    \n    [\u00271 dozen\u0027,\u002712\u0027],                                                            \n    [\u00271 banana\u0027,\u002713\u0027],                                                           \n    [\u00271 dollar\u0027,\u0027elephant\u0027,\u0027heffalump\u0027],                                         \n    ]                                                                            \n\nwith open(\u0027test.csv\u0027, \u0027ab\u0027) as f:                                    \n    writer \u003d csv.writer(f)                                                       \n    writer.writerows(changes)"},{"id":0,"score":0.0,"value":"import csv\n\nnew_rows \u003d [] # a holder for our modified rows when we make them\nchanges \u003d {   # a dictionary of changes to make, find \u0027key\u0027 substitue with \u0027value\u0027\n    \u00271 dozen\u0027 : \u002712\u0027, # I assume both \u0027key\u0027 and \u0027value\u0027 are strings\n    }\n\nwith open(\u0027test.csv\u0027, \u0027rb\u0027) as f:\n    reader \u003d csv.reader(f) # pass the file to our csv reader\n    for row in reader:     # iterate over the rows in the file\n        new_row \u003d row      # at first, just copy the row\n        for key, value in changes.items(): # iterate over \u0027changes\u0027 dictionary\n            new_row \u003d [ x.replace(key, value) for x in new_row ] # make the substitutions\n        new_rows.append(new_row) # add the modified rows\n\nwith open(\u0027test.csv\u0027, \u0027wb\u0027) as f:\n    # Overwrite the old file with the modified rows\n    writer \u003d csv.writer(f)\n    writer.writerows(new_rows)"},{"id":0,"score":0.0,"value":"new_row \u003d [ x.replace(key, value) for x in new_row ]"},{"id":0,"score":0.0,"value":"temp \u003d []\nfor x in new_row:\n    temp.append( x.replace(key, value) )\nnew_row \u003d temp"},{"id":0,"score":0.0,"value":"import pandas as pd\ndata \u003d pd.read_csv(\u0027google-us-data.csv.gz\u0027, nrows\u003d100, compression\u003d\u0027gzip\u0027,\n                   error_bad_lines\u003dFalse)\nprint(data)"}]}],[{"query":"copy file `ddd.png`","hypotheses":[{"id":0,"score":0.0,"value":"from shutil import copyfile\ncopyfile(src, dst)"},{"id":0,"score":0.0,"value":"import shutil\nshutil.copy2(\u0027/src/dir/file.ext\u0027, \u0027/dst/dir/newname.ext\u0027) # complete target filename given\nshutil.copy2(\u0027/src/file.ext\u0027, \u0027/dst/dir\u0027) # target filename is /dst/dir/file.ext"},{"id":0,"score":0.0,"value":"import shutil\nshutil.copy(\u0027/etc/hostname\u0027, \u0027/var/tmp/testhostname\u0027)"},{"id":0,"score":0.0,"value":"import os\nimport shutil\nimport subprocess"},{"id":0,"score":0.0,"value":"shutil.copyfile(src_file, dest_file, *, follow_symlinks\u003dTrue)\n\n# example    \nshutil.copyfile(\u0027source.txt\u0027, \u0027destination.txt\u0027)"},{"id":0,"score":0.0,"value":"shutil.copy(src_file, dest_file, *, follow_symlinks\u003dTrue)\n\n# example\nshutil.copy(\u0027source.txt\u0027, \u0027destination.txt\u0027)"},{"id":0,"score":0.0,"value":"shutil.copy2(src_file, dest_file, *, follow_symlinks\u003dTrue)\n\n# example\nshutil.copy2(\u0027source.txt\u0027, \u0027destination.txt\u0027)"}]},{"query":"copy file","hypotheses":[{"id":0,"score":0.0,"value":"from shutil import copyfile\ncopyfile(src, dst)"},{"id":0,"score":0.0,"value":"import shutil\nshutil.copy2(\u0027/src/dir/file.ext\u0027, \u0027/dst/dir/newname.ext\u0027) # complete target filename given\nshutil.copy2(\u0027/src/file.ext\u0027, \u0027/dst/dir\u0027) # target filename is /dst/dir/file.ext"},{"id":0,"score":0.0,"value":"import shutil, errno\n\ndef copyanything(src, dst):\n    try:\n        shutil.copytree(src, dst)\n    except OSError as exc: # python \u003e2.5\n        if exc.errno \u003d\u003d errno.ENOTDIR:\n            shutil.copy(src, dst)\n        else: raise"},{"id":0,"score":0.0,"value":"import shutil\nshutil.copy(\u0027/etc/hostname\u0027, \u0027/var/tmp/testhostname\u0027)"},{"id":0,"score":0.0,"value":"import os\nimport shutil\nimport subprocess"},{"id":0,"score":0.0,"value":"shutil.copyfile(src_file, dest_file, *, follow_symlinks\u003dTrue)\n\n# example    \nshutil.copyfile(\u0027source.txt\u0027, \u0027destination.txt\u0027)"},{"id":0,"score":0.0,"value":"shutil.copy(src_file, dest_file, *, follow_symlinks\u003dTrue)\n\n# example\nshutil.copy(\u0027source.txt\u0027, \u0027destination.txt\u0027)"}]}],[{"query":"save `compan_df` dataframe to a file","hypotheses":[{"id":0,"score":0.0,"value":"df.to_pickle(file_name)  # where to save it, usually as a .pkl"},{"id":0,"score":0.0,"value":"df \u003d pd.read_pickle(file_name)"},{"id":0,"score":0.0,"value":"import pandas as pd\nstore \u003d pd.HDFStore(\u0027store.h5\u0027)\n\nstore[\u0027df\u0027] \u003d df  # save it\nstore[\u0027df\u0027]  # load it"},{"id":0,"score":0.0,"value":"np.savetxt(r\u0027c:\\data\\np.txt\u0027, df.values, fmt\u003d\u0027%d\u0027)"},{"id":0,"score":0.0,"value":"18 55 1 70\n18 55 2 67\n18 57 2 75\n18 58 1 35\n19 54 2 70"},{"id":0,"score":0.0,"value":"df.to_csv(r\u0027c:\\data\\pandas.txt\u0027, header\u003dNone, index\u003dNone, sep\u003d\u0027 \u0027, mode\u003d\u0027a\u0027)"},{"id":0,"score":0.0,"value":"In [97]: print df.to_csv(sep\u003d\u0027 \u0027, index\u003dFalse, header\u003dFalse)\n18 55 1 70\n18 55 2 67\n18 57 2 75\n18 58 1 35\n19 54 2 70"}]},{"query":"save dataframe to a file","hypotheses":[{"id":0,"score":0.0,"value":"df.to_csv(file_name, sep\u003d\u0027\\t\u0027)"},{"id":0,"score":0.0,"value":"df.to_csv(file_name, sep\u003d\u0027\\t\u0027, encoding\u003d\u0027utf-8\u0027)"},{"id":0,"score":0.0,"value":"df.to_pickle(file_name)  # where to save it, usually as a .pkl"},{"id":0,"score":0.0,"value":"df \u003d pd.read_pickle(file_name)"},{"id":0,"score":0.0,"value":"import pandas as pd\nstore \u003d pd.HDFStore(\u0027store.h5\u0027)\n\nstore[\u0027df\u0027] \u003d df  # save it\nstore[\u0027df\u0027]  # load it"},{"id":0,"score":0.0,"value":"df.to_csv(file_name, encoding\u003d\u0027utf-8\u0027, index\u003dFalse)"},{"id":0,"score":0.0,"value":"Color  Number\n0   red     22\n1  blue     10"}]}],[{"query":"save `compand_df` dataframe to a file","hypotheses":[{"id":0,"score":0.0,"value":"df.to_pickle(file_name)  # where to save it, usually as a .pkl"},{"id":0,"score":0.0,"value":"df \u003d pd.read_pickle(file_name)"},{"id":0,"score":0.0,"value":"import pandas as pd\nstore \u003d pd.HDFStore(\u0027store.h5\u0027)\n\nstore[\u0027df\u0027] \u003d df  # save it\nstore[\u0027df\u0027]  # load it"},{"id":0,"score":0.0,"value":"np.savetxt(r\u0027c:\\data\\np.txt\u0027, df.values, fmt\u003d\u0027%d\u0027)"},{"id":0,"score":0.0,"value":"18 55 1 70\n18 55 2 67\n18 57 2 75\n18 58 1 35\n19 54 2 70"},{"id":0,"score":0.0,"value":"df.to_csv(r\u0027c:\\data\\pandas.txt\u0027, header\u003dNone, index\u003dNone, sep\u003d\u0027 \u0027, mode\u003d\u0027a\u0027)"},{"id":0,"score":0.0,"value":"In [97]: print df.to_csv(sep\u003d\u0027 \u0027, index\u003dFalse, header\u003dFalse)\n18 55 1 70\n18 55 2 67\n18 57 2 75\n18 58 1 35\n19 54 2 70"}]},{"query":"save dataframe to a file","hypotheses":[{"id":0,"score":0.0,"value":"df.to_pickle(file_name)  # where to save it, usually as a .pkl"},{"id":0,"score":0.0,"value":"df \u003d pd.read_pickle(file_name)"},{"id":0,"score":0.0,"value":"import pandas as pd\nstore \u003d pd.HDFStore(\u0027store.h5\u0027)\n\nstore[\u0027df\u0027] \u003d df  # save it\nstore[\u0027df\u0027]  # load it"},{"id":0,"score":0.0,"value":"np.savetxt(r\u0027c:\\data\\np.txt\u0027, df.values, fmt\u003d\u0027%d\u0027)"},{"id":0,"score":0.0,"value":"18 55 1 70\n18 55 2 67\n18 57 2 75\n18 58 1 35\n19 54 2 70"},{"id":0,"score":0.0,"value":"df.to_csv(r\u0027c:\\data\\pandas.txt\u0027, header\u003dNone, index\u003dNone, sep\u003d\u0027 \u0027, mode\u003d\u0027a\u0027)"},{"id":0,"score":0.0,"value":"df_object.to_csv(\u0027xgboost.txt\u0027, sep\u003d\u0027\\t\u0027, index\u003dFalse)"}]}],[{"query":"get the head of dataframe `df`","hypotheses":[{"id":0,"score":0.0,"value":"df.head(5) # will print out the first 5 rows\ndf.tail(5) # will print out the 5 last rows"},{"id":0,"score":0.0,"value":"import pandas as pd\ndf \u003d pd.DataFrame( data\u003dnp.ones([4,4]) )\ndf.name \u003d \u0027Ones\u0027\n\nprint df.name\n\u003e\u003e\u003e\nOnes"},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e df \u003d pd.DataFrame({\"A\": range(1000), \"B\": range(1000)})\n\u003e\u003e\u003e df\n\u003cclass \u0027pandas.core.frame.DataFrame\u0027\u003e\nInt64Index: 1000 entries, 0 to 999\nData columns:\nA    1000  non-null values\nB    1000  non-null values\ndtypes: int64(2)\n\u003e\u003e\u003e df[:5]\n   A  B\n0  0  0\n1  1  1\n2  2  2\n3  3  3\n4  4  4"},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e df \u003d pd.DataFrame({i: range(1000) for i in range(100)})\n\u003e\u003e\u003e df.ix[:5, :10]\n   0   1   2   3   4   5   6   7   8   9   10\n0   0   0   0   0   0   0   0   0   0   0   0\n1   1   1   1   1   1   1   1   1   1   1   1\n2   2   2   2   2   2   2   2   2   2   2   2\n3   3   3   3   3   3   3   3   3   3   3   3\n4   4   4   4   4   4   4   4   4   4   4   4\n5   5   5   5   5   5   5   5   5   5   5   5"},{"id":0,"score":0.0,"value":"print df.shape[1]\n2\n\nprint range(df.shape[1])\n[0, 1]\n\ndf.columns \u003d range(df.shape[1])\nprint df\n    0   1\n0  23  12\n1  21  44\n2  98  21"},{"id":0,"score":0.0,"value":"print df.to_csv(header\u003dNone,index\u003dFalse)\n23,12\n21,44\n98,21\n\nprint pd.read_csv(io.StringIO(u\"\"+df.to_csv(header\u003dNone,index\u003dFalse)), header\u003dNone)\n    0   1\n0  23  12\n1  21  44\n2  98  21"},{"id":0,"score":0.0,"value":"print df.to_csv(index\u003dFalse)\nA,B\n23,12\n21,44\n98,21\n\nprint pd.read_csv(io.StringIO(u\"\"+df.to_csv(index\u003dFalse)), header\u003dNone, skiprows\u003d1)\n    0   1\n0  23  12\n1  21  44\n2  98  21"}]},{"query":"get the head of dataframe","hypotheses":[{"id":0,"score":0.0,"value":"df.head(5) # will print out the first 5 rows\ndf.tail(5) # will print out the 5 last rows"},{"id":0,"score":0.0,"value":"import pandas as pd\ndf \u003d pd.DataFrame( data\u003dnp.ones([4,4]) )\ndf.name \u003d \u0027Ones\u0027\n\nprint df.name\n\u003e\u003e\u003e\nOnes"},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e df \u003d pd.DataFrame({\"A\": range(1000), \"B\": range(1000)})\n\u003e\u003e\u003e df\n\u003cclass \u0027pandas.core.frame.DataFrame\u0027\u003e\nInt64Index: 1000 entries, 0 to 999\nData columns:\nA    1000  non-null values\nB    1000  non-null values\ndtypes: int64(2)\n\u003e\u003e\u003e df[:5]\n   A  B\n0  0  0\n1  1  1\n2  2  2\n3  3  3\n4  4  4"},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e df \u003d pd.DataFrame({i: range(1000) for i in range(100)})\n\u003e\u003e\u003e df.ix[:5, :10]\n   0   1   2   3   4   5   6   7   8   9   10\n0   0   0   0   0   0   0   0   0   0   0   0\n1   1   1   1   1   1   1   1   1   1   1   1\n2   2   2   2   2   2   2   2   2   2   2   2\n3   3   3   3   3   3   3   3   3   3   3   3\n4   4   4   4   4   4   4   4   4   4   4   4\n5   5   5   5   5   5   5   5   5   5   5   5"},{"id":0,"score":0.0,"value":"print df.shape[1]\n2\n\nprint range(df.shape[1])\n[0, 1]\n\ndf.columns \u003d range(df.shape[1])\nprint df\n    0   1\n0  23  12\n1  21  44\n2  98  21"},{"id":0,"score":0.0,"value":"print df.to_csv(header\u003dNone,index\u003dFalse)\n23,12\n21,44\n98,21\n\nprint pd.read_csv(io.StringIO(u\"\"+df.to_csv(header\u003dNone,index\u003dFalse)), header\u003dNone)\n    0   1\n0  23  12\n1  21  44\n2  98  21"},{"id":0,"score":0.0,"value":"print df.to_csv(index\u003dFalse)\nA,B\n23,12\n21,44\n98,21\n\nprint pd.read_csv(io.StringIO(u\"\"+df.to_csv(index\u003dFalse)), header\u003dNone, skiprows\u003d1)\n    0   1\n0  23  12\n1  21  44\n2  98  21"}]}],[{"query":"sort dataframe `jdf` by `scores`","hypotheses":[{"id":0,"score":0.0,"value":"In [18]:\ndf.sort_values(\u00272\u0027)\n\nOut[18]:\n        0          1     2\n4    85.6    January   1.0\n3    95.5   February   2.0\n7   104.8      March   3.0\n0   354.7      April   4.0\n8   283.5        May   5.0\n6   238.7       June   6.0\n5   152.0       July   7.0\n1    55.4     August   8.0\n11  212.7  September   9.0\n10  249.6    October  10.0\n9   278.8   November  11.0\n2   176.5   December  12.0"},{"id":0,"score":0.0,"value":"final_df \u003d df.sort_values(by\u003d[\u00272\u0027], ascending\u003dFalse)"},{"id":0,"score":0.0,"value":"df1 \u003d pd.DataFrame({\u0027Col1\u0027: [\u0027a\u0027,\u0027b\u0027,\u0027c\u0027,\u0027d\u0027,\u0027e\u0027], \u0027Col2\u0027: \n[\u0027chocolate\u0027,\u0027chicken\u0027,\u0027pizza\u0027,\u0027icecream\u0027,\u0027cake\u0027] })\nOut :\n  Col1       Col2\n0    a  chocolate\n1    b    chicken\n2    c      pizza\n3    d   icecream\n4    e       cake\ndf2 \u003d pd.DataFrame({\u0027Col1\u0027: [\u0027f\u0027,\u0027g\u0027,\u0027h\u0027,\u0027i\u0027,\u0027j\u0027], \u0027Col2\u0027: [\u0027chicken\u0027,\u0027cake\u0027,\u0027icecream\u0027,\u0027chocolate\u0027,\u0027pizza\u0027] })\nOut :\n  Col1       Col2\n0    f    chicken\n1    g       cake\n2    h   icecream\n3    i  chocolate\n4    j      pizza\ndf1 \u003d df1.set_index(\u0027Col2\u0027)\ndf1 \u003d df1.reindex(index\u003ddf2[\u0027Col2\u0027])\ndf1 \u003d df1.reset_index()\nOut :\n        Col2 Col1\n0    chicken    b\n1       cake    e\n2   icecream    d\n3  chocolate    a\n4      pizza    c"},{"id":0,"score":0.0,"value":"df.rename(columns\u003d{1:\u0027month\u0027},inplace\u003dTrue)\ndf[\u0027month\u0027] \u003d pd.Categorical(df[\u0027month\u0027],categories\u003d[\u0027December\u0027,\u0027November\u0027,\u0027October\u0027,\u0027September\u0027,\u0027August\u0027,\u0027July\u0027,\u0027June\u0027,\u0027May\u0027,\u0027April\u0027,\u0027March\u0027,\u0027February\u0027,\u0027January\u0027],ordered\u003dTrue)\ndf \u003d df.sort_values(\u0027month\u0027,ascending\u003dFalse)"},{"id":0,"score":0.0,"value":"sorted_df \u003d df.sort_values(by\u003d[\u0027Column_name\u0027], ascending\u003dTrue)"},{"id":0,"score":0.0,"value":"ID         cost      tax    label\n1       216590      1600    test      \n2       523213      1800    test \n3          250      1500    experiment\n\n(df[\u0027label\u0027].value_counts().to_frame().reset_index()).sort_values(\u0027label\u0027, ascending\u003dFalse)"},{"id":0,"score":0.0,"value":"index   label\n0   test        2\n1   experiment  1"}]},{"query":"sort dataframe by column","hypotheses":[{"id":0,"score":0.0,"value":"df.sort_values([\u0027a\u0027, \u0027b\u0027], ascending\u003d[True, False])"},{"id":0,"score":0.0,"value":"df.sort([\u0027a\u0027, \u0027b\u0027], ascending\u003d[True, False])"},{"id":0,"score":0.0,"value":"In [11]: df1 \u003d pd.DataFrame(np.random.randint(1, 5, (10,2)), columns\u003d[\u0027a\u0027,\u0027b\u0027])\n\nIn [12]: df1.sort([\u0027a\u0027, \u0027b\u0027], ascending\u003d[True, False])\nOut[12]:\n   a  b\n2  1  4\n7  1  3\n1  1  2\n3  1  2\n4  3  2\n6  4  4\n0  4  3\n9  4  3\n5  4  1\n8  4  1"},{"id":0,"score":0.0,"value":"df1 \u003d df1.sort([\u0027a\u0027, \u0027b\u0027], ascending\u003d[True, False])"},{"id":0,"score":0.0,"value":"df1.sort([\u0027a\u0027, \u0027b\u0027], ascending\u003d[True, False], inplace\u003dTrue)"},{"id":0,"score":0.0,"value":"In [18]:\ndf.sort_values(\u00272\u0027)\n\nOut[18]:\n        0          1     2\n4    85.6    January   1.0\n3    95.5   February   2.0\n7   104.8      March   3.0\n0   354.7      April   4.0\n8   283.5        May   5.0\n6   238.7       June   6.0\n5   152.0       July   7.0\n1    55.4     August   8.0\n11  212.7  September   9.0\n10  249.6    October  10.0\n9   278.8   November  11.0\n2   176.5   December  12.0"},{"id":0,"score":0.0,"value":"final_df \u003d df.sort_values(by\u003d[\u00272\u0027], ascending\u003dFalse)"}]}],[{"query":"sort dataframe `jdf` by the values of column \u0027scores\u0027","hypotheses":[{"id":0,"score":0.0,"value":"In [18]:\ndf.sort_values(\u00272\u0027)\n\nOut[18]:\n        0          1     2\n4    85.6    January   1.0\n3    95.5   February   2.0\n7   104.8      March   3.0\n0   354.7      April   4.0\n8   283.5        May   5.0\n6   238.7       June   6.0\n5   152.0       July   7.0\n1    55.4     August   8.0\n11  212.7  September   9.0\n10  249.6    October  10.0\n9   278.8   November  11.0\n2   176.5   December  12.0"},{"id":0,"score":0.0,"value":"final_df \u003d df.sort_values(by\u003d[\u00272\u0027], ascending\u003dFalse)"},{"id":0,"score":0.0,"value":"df1 \u003d pd.DataFrame({\u0027Col1\u0027: [\u0027a\u0027,\u0027b\u0027,\u0027c\u0027,\u0027d\u0027,\u0027e\u0027], \u0027Col2\u0027: \n[\u0027chocolate\u0027,\u0027chicken\u0027,\u0027pizza\u0027,\u0027icecream\u0027,\u0027cake\u0027] })\nOut :\n  Col1       Col2\n0    a  chocolate\n1    b    chicken\n2    c      pizza\n3    d   icecream\n4    e       cake\ndf2 \u003d pd.DataFrame({\u0027Col1\u0027: [\u0027f\u0027,\u0027g\u0027,\u0027h\u0027,\u0027i\u0027,\u0027j\u0027], \u0027Col2\u0027: [\u0027chicken\u0027,\u0027cake\u0027,\u0027icecream\u0027,\u0027chocolate\u0027,\u0027pizza\u0027] })\nOut :\n  Col1       Col2\n0    f    chicken\n1    g       cake\n2    h   icecream\n3    i  chocolate\n4    j      pizza\ndf1 \u003d df1.set_index(\u0027Col2\u0027)\ndf1 \u003d df1.reindex(index\u003ddf2[\u0027Col2\u0027])\ndf1 \u003d df1.reset_index()\nOut :\n        Col2 Col1\n0    chicken    b\n1       cake    e\n2   icecream    d\n3  chocolate    a\n4      pizza    c"},{"id":0,"score":0.0,"value":"df.rename(columns\u003d{1:\u0027month\u0027},inplace\u003dTrue)\ndf[\u0027month\u0027] \u003d pd.Categorical(df[\u0027month\u0027],categories\u003d[\u0027December\u0027,\u0027November\u0027,\u0027October\u0027,\u0027September\u0027,\u0027August\u0027,\u0027July\u0027,\u0027June\u0027,\u0027May\u0027,\u0027April\u0027,\u0027March\u0027,\u0027February\u0027,\u0027January\u0027],ordered\u003dTrue)\ndf \u003d df.sort_values(\u0027month\u0027,ascending\u003dFalse)"},{"id":0,"score":0.0,"value":"sorted_df \u003d df.sort_values(by\u003d[\u0027Column_name\u0027], ascending\u003dTrue)"},{"id":0,"score":0.0,"value":"import natsort as ns\n\ndf[\u0027a\u0027] \u003d pd.Categorical(df[\u0027a\u0027], ordered\u003dTrue, categories\u003d ns.natsorted(df[\u0027a\u0027].unique()))\ndf \u003d df.sort_values(\u0027a\u0027)\nprint (df)\n     a    b\n5   a1   b1\n2   a1  b11\n4   a3   b4\n3  a10  b22\n6  a11  b12\n1  a20   b2\n0  a22   b5"},{"id":0,"score":0.0,"value":"df[\u0027b\u0027] \u003d pd.Categorical(df[\u0027b\u0027], ordered\u003dTrue, categories\u003d ns.natsorted(df[\u0027b\u0027].unique()))\n\ndf \u003d df.sort_values(\u0027b\u0027)\nprint (df)\n     a    b\n5   a1   b1\n1  a20   b2\n4   a3   b4\n0  a22   b5\n2   a1  b11\n6  a11  b12\n3  a10  b22"}]},{"query":"sort dataframe by the values of column","hypotheses":[{"id":0,"score":0.0,"value":"In [18]:\ndf.sort_values(\u00272\u0027)\n\nOut[18]:\n        0          1     2\n4    85.6    January   1.0\n3    95.5   February   2.0\n7   104.8      March   3.0\n0   354.7      April   4.0\n8   283.5        May   5.0\n6   238.7       June   6.0\n5   152.0       July   7.0\n1    55.4     August   8.0\n11  212.7  September   9.0\n10  249.6    October  10.0\n9   278.8   November  11.0\n2   176.5   December  12.0"},{"id":0,"score":0.0,"value":"final_df \u003d df.sort_values(by\u003d[\u00272\u0027], ascending\u003dFalse)"},{"id":0,"score":0.0,"value":"In[16]:\n\ndf.reindex(df.b.abs().sort_values().index)\nOut[16]: \n   a  b\n2  3 -1\n3  4  2\n0  1 -3\n1  2  5\n4  5 -9"},{"id":0,"score":0.0,"value":"In [11]: df \u003d pd.DataFrame(np.random.randn(4,4), columns\u003dlist(\u0027ABCD\u0027))\n\nIn [12]: df\nOut[12]:\n          A         B         C         D\n0  0.933069  1.432486  0.288637 -1.867853\n1 -0.455952 -0.725268  0.339908  1.318175\n2 -0.894331  0.573868  1.116137  0.508845\n3  0.661572  0.819360 -0.527327 -0.925478\n\nIn [13]: df.mean()\nOut[13]:\nA    0.061089\nB    0.525112\nC    0.304339\nD   -0.241578\ndtype: float64\n\nIn [14]: df.mean().sort_values()\nOut[14]:\nD   -0.241578\nA    0.061089\nC    0.304339\nB    0.525112\ndtype: float64"},{"id":0,"score":0.0,"value":"In [15]: df.reindex(df.mean().sort_values().index, axis\u003d1)\nOut[15]:\n          D         A         C         B\n0 -1.867853  0.933069  0.288637  1.432486\n1  1.318175 -0.455952  0.339908 -0.725268\n2  0.508845 -0.894331  1.116137  0.573868\n3 -0.925478  0.661572 -0.527327  0.819360"},{"id":0,"score":0.0,"value":"df.rename(columns\u003d{1:\u0027month\u0027},inplace\u003dTrue)\ndf[\u0027month\u0027] \u003d pd.Categorical(df[\u0027month\u0027],categories\u003d[\u0027December\u0027,\u0027November\u0027,\u0027October\u0027,\u0027September\u0027,\u0027August\u0027,\u0027July\u0027,\u0027June\u0027,\u0027May\u0027,\u0027April\u0027,\u0027March\u0027,\u0027February\u0027,\u0027January\u0027],ordered\u003dTrue)\ndf \u003d df.sort_values(\u0027month\u0027,ascending\u003dFalse)"},{"id":0,"score":0.0,"value":"df.iloc[df[\u0027b\u0027].abs().argsort()]\n\n   a  b\n2  3 -1\n3  4  2\n0  1 -3\n1  2  5\n4  5 -9"}]}],[{"query":"pandas read csv named \"data.csv\"","hypotheses":[{"id":0,"score":0.0,"value":"from numpy import genfromtxt\nmy_data \u003d genfromtxt(\u0027my_file.csv\u0027, delimiter\u003d\u0027,\u0027)"},{"id":0,"score":0.0,"value":"import pandas as pd\ndf\u003dpd.read_csv(\u0027myfile.csv\u0027, sep\u003d\u0027,\u0027,header\u003dNone)\ndf.values\narray([[ 1. ,  2. ,  3. ],\n       [ 4. ,  5.5,  6. ]])"},{"id":0,"score":0.0,"value":"1.0, 2, 3\n4, 5.5, 6\n\nimport numpy as np\nnp.genfromtxt(\u0027myfile.csv\u0027,delimiter\u003d\u0027,\u0027)"},{"id":0,"score":0.0,"value":"array([[ 1. ,  2. ,  3. ],\n       [ 4. ,  5.5,  6. ]])"},{"id":0,"score":0.0,"value":"np.genfromtxt(\u0027myfile.csv\u0027,delimiter\u003d\u0027,\u0027,dtype\u003dNone)"},{"id":0,"score":0.0,"value":"array([(1.0, 2.0, 3), (4.0, 5.5, 6)], \n      dtype\u003d[(\u0027f0\u0027, \u0027\u003cf8\u0027), (\u0027f1\u0027, \u0027\u003cf8\u0027), (\u0027f2\u0027, \u0027\u003ci4\u0027)])"},{"id":0,"score":0.0,"value":"from numpy import genfromtxt\ngenfromtxt(fname \u003d dest_file, dtype \u003d (\u003cwhatever options\u003e))"}]},{"query":"pandas read csv","hypotheses":[{"id":0,"score":0.0,"value":"import os\nimport boto3\nimport pandas as pd\nimport sys\n\nif sys.version_info[0] \u003c 3: \n    from StringIO import StringIO # Python 2.x\nelse:\n    from io import StringIO # Python 3.x\n\n# get your credentials from environment variables\naws_id \u003d os.environ[\u0027AWS_ID\u0027]\naws_secret \u003d os.environ[\u0027AWS_SECRET\u0027]\n\nclient \u003d boto3.client(\u0027s3\u0027, aws_access_key_id\u003daws_id,\n        aws_secret_access_key\u003daws_secret)\n\nbucket_name \u003d \u0027my_bucket\u0027\n\nobject_key \u003d \u0027my_file.csv\u0027\ncsv_obj \u003d client.get_object(Bucket\u003dbucket_name, Key\u003dobject_key)\nbody \u003d csv_obj[\u0027Body\u0027]\ncsv_string \u003d body.read().decode(\u0027utf-8\u0027)\n\ndf \u003d pd.read_csv(StringIO(csv_string))"},{"id":0,"score":0.0,"value":"def read_file(bucket_name,region, remote_file_name, aws_access_key_id, aws_secret_access_key):\n    # reads a csv from AWS\n\n    # first you stablish connection with your passwords and region id\n\n    conn \u003d boto.s3.connect_to_region(\n        region,\n        aws_access_key_id\u003daws_access_key_id,\n        aws_secret_access_key\u003daws_secret_access_key)\n\n    # next you obtain the key of the csv you want to read\n    # you will need the bucket name and the csv file name\n\n    bucket \u003d conn.get_bucket(bucket_name, validate\u003dFalse)\n    key \u003d Key(bucket)\n    key.key \u003d remote_file_name\n    data \u003d key.get_contents_as_string()\n    key.close()\n\n    # you store it into a string, therefore you will need to split it\n    # usually the split characters are \u0027\\r\\n\u0027 if not just read the file normally \n    # and find out what they are \n\n    reader \u003d csv.reader(data.split(\u0027\\r\\n\u0027))\n    data \u003d []\n    header \u003d next(reader)\n    for row in reader:\n        data.append(row)\n\n    return data"},{"id":0,"score":0.0,"value":"from pathlib import Path\nimport pandas as pd\nroot \u003d Path(\u0027main\u0027, \u0027data\u0027)\ndf \u003d pd.read_csv(root / \u0027data1.csv\u0027)"},{"id":0,"score":0.0,"value":"import os\nimport pandas as pd\nfrom smart_open import smart_open\n\naws_key \u003d os.environ[\u0027AWS_ACCESS_KEY\u0027]\naws_secret \u003d os.environ[\u0027AWS_SECRET_ACCESS_KEY\u0027]\n\nbucket_name \u003d \u0027my_bucket\u0027\nobject_key \u003d \u0027my_file.csv\u0027\n\npath \u003d \u0027s3://{}:{}@{}/{}\u0027.format(aws_key, aws_secret, bucket_name, object_key)\n\ndf \u003d pd.read_csv(smart_open(path))"},{"id":0,"score":0.0,"value":"df \u003d pd.read_csv(\u0027ING_DAILY - ING_DAILY.csv\u0027,  sep\u003d\u0027[\"]*,[\"]*\u0027, engine\u003d\u0027python\u0027)"},{"id":0,"score":0.0,"value":"df.columns \u003d df.columns.str.strip(\u0027\"\u0027)\ndf.iloc[:, [0,-1]] \u003d df.iloc[:, [0,-1]].apply(lambda x: x.str.strip(\u0027\"\u0027))\nprint (df.head(3))\n\n           ISIN                          MIC       Datum   Open    Hoog  \\\n0  NL0011821202  Euronext Amsterdam Brussels  04/09/2017  14.82  14.950   \n1  NL0011821202  Euronext Amsterdam Brussels  05/09/2017  14.91  14.920   \n2  NL0011821202  Euronext Amsterdam Brussels  06/09/2017  14.69  14.725   \n\n     Laag   Close  Number of Shares  Number of Trades      Turnover Valuta  \n0  14.785  14.855           7482805              6970  1.113455e+08    EUR  \n1  14.585  14.655          15240971             12549  2.242653e+08    EUR  \n2  14.570  14.615          14851426             15303  2.175316e+08    EUR"},{"id":0,"score":0.0,"value":"import pandas as pd\n\ndf \u003d pd.read_csv(\u0027file1.csv\u0027)\ndf[\u0027value3\u0027] \u003d [10, 11]\ndf[\u0027value4\u0027] \u003d [20, 21]\ndf.to_csv(\u0027file2.csv\u0027)"}]}],[{"query":"make directory \"output\" if it doesn\u0027t exist","hypotheses":[{"id":0,"score":0.0,"value":"New-Item -ItemType Directory -Force -Path C:\\Path\\That\\May\\Or\\May\\Not\\Exist"},{"id":0,"score":0.0,"value":"if [ ! -d /home/mlzboy/b2c2/shared/db ]; then\n  mkdir -p /home/mlzboy/b2c2/shared/db;\nfi"},{"id":0,"score":0.0,"value":"mkdir -p /home/mlzboy/b2c2/shared/db;"},{"id":0,"score":0.0,"value":"$path \u003d \"C:\\temp\\NewFolder\"\nIf(!(test-path $path))\n{\n      New-Item -ItemType Directory -Force -Path $path\n}"},{"id":0,"score":0.0,"value":"mkdir -p /home/mlzboy/b2c2/shared/db"},{"id":0,"score":0.0,"value":"with open(filename, \u0027a+\u0027) as f:\n    f.write(...)"},{"id":0,"score":0.0,"value":"mkdir /path/to/your/potentially/existing/folder"}]},{"query":"make directory if it doesn\u0027t exist","hypotheses":[{"id":0,"score":0.0,"value":"New-Item -ItemType Directory -Force -Path C:\\Path\\That\\May\\Or\\May\\Not\\Exist"},{"id":0,"score":0.0,"value":"if [ ! -d /home/mlzboy/b2c2/shared/db ]; then\n  mkdir -p /home/mlzboy/b2c2/shared/db;\nfi"},{"id":0,"score":0.0,"value":"mkdir -p /home/mlzboy/b2c2/shared/db;"},{"id":0,"score":0.0,"value":"$path \u003d \"C:\\temp\\NewFolder\"\nIf(!(test-path $path))\n{\n      New-Item -ItemType Directory -Force -Path $path\n}"},{"id":0,"score":0.0,"value":"pathlib.Path(\u0027/tmp/sub1/sub2\u0027).mkdir(parents\u003dTrue, exist_ok\u003dTrue)"},{"id":0,"score":0.0,"value":"mkdir -p /home/mlzboy/b2c2/shared/db"},{"id":0,"score":0.0,"value":"mkdir /path/to/your/potentially/existing/folder"}]}],[{"query":"read a json file named `f`","hypotheses":[{"id":0,"score":0.0,"value":"import json\n\nwith open(\u0027strings.json\u0027) as f:\n    d \u003d json.load(f)\n    print(d)"},{"id":0,"score":0.0,"value":"import json\n\nwith open(\"test.json\") as json_file:\n    json_data \u003d json.load(json_file)\n    print(json_data)"},{"id":0,"score":0.0,"value":"{\n    \"a\": [1,3,\"asdf\",true],\n    \"b\": {\n        \"Hello\": \"world\"\n    }\n}"},{"id":0,"score":0.0,"value":"import json\n\nwith open(\u0027data.json\u0027, \u0027r+\u0027) as f:\n    data \u003d json.load(f)\n    data[\u0027id\u0027] \u003d 134 # \u003c--- add `id` value.\n    f.seek(0)        # \u003c--- should reset file position to the beginning.\n    json.dump(data, f, indent\u003d4)\n    f.truncate()     # remove remaining part"},{"id":0,"score":0.0,"value":"with open(file_path) as f:\n    data \u003d json.loads(f.read())\n    print(data[0][\u0027text\u0027])"},{"id":0,"score":0.0,"value":"import json\nimport os\n\nfilename \u003d \u0027data.json\u0027\nwith open(filename, \u0027r\u0027) as f:\n    data \u003d json.load(f)\n    data[\u0027id\u0027] \u003d 134 # \u003c--- add `id` value.\n\nos.remove(filename)\nwith open(filename, \u0027w\u0027) as f:\n    json.dump(data, f, indent\u003d4)"},{"id":0,"score":0.0,"value":"with open(\u0027strings.json\u0027) as json_data:\n    d \u003d json.load(json_data)\n    pprint(d)"}]},{"query":"read a json file","hypotheses":[{"id":0,"score":0.0,"value":"import json\n\nwith open(\u0027strings.json\u0027) as f:\n    d \u003d json.load(f)\n    print(d)"},{"id":0,"score":0.0,"value":"import json\n\nwith open(\"test.json\") as json_file:\n    json_data \u003d json.load(json_file)\n    print(json_data)"},{"id":0,"score":0.0,"value":"{\n    \"a\": [1,3,\"asdf\",true],\n    \"b\": {\n        \"Hello\": \"world\"\n    }\n}"},{"id":0,"score":0.0,"value":"import gzip\nimport json\n\ndata \u003d []\nfor i in range(N):\n    uid \u003d \"whatever%i\" % i\n    dv \u003d [1, 2, 3]\n    data.append({\n        \u0027what\u0027: uid,\n        \u0027where\u0027: dv\n    })                                           # 1. data\n\njson_str \u003d json.dumps(data) + \"\\n\"               # 2. string (i.e. JSON)\njson_bytes \u003d json_str.encode(\u0027utf-8\u0027)            # 3. bytes (i.e. UTF-8)\n\nwith gzip.open(jsonfilename, \u0027w\u0027) as fout:       # 4. fewer bytes (i.e. gzip)\n    fout.write(json_bytes)"},{"id":0,"score":0.0,"value":"with gzip.open(jsonfilename, \u0027r\u0027) as fin:        # 4. gzip\n    json_bytes \u003d fin.read()                      # 3. bytes (i.e. UTF-8)\n\njson_str \u003d json_bytes.decode(\u0027utf-8\u0027)            # 2. string (i.e. JSON)\ndata \u003d json.loads(json_str)                      # 1. data\n\nprint(data)"},{"id":0,"score":0.0,"value":"with gzip.open(jsonfilename, \u0027w\u0027) as fout:\n    fout.write(json.dumps(data).encode(\u0027utf-8\u0027))"},{"id":0,"score":0.0,"value":"with gzip.open(jsonfilename, \u0027r\u0027) as fin:\n    data \u003d json.loads(fin.read().decode(\u0027utf-8\u0027))"}]}],[{"query":"write json in `ret` to file `outfile`","hypotheses":[{"id":0,"score":0.0,"value":"import json\nwith open(\u0027data.json\u0027, \u0027w\u0027) as f:\n    json.dump(data, f)"},{"id":0,"score":0.0,"value":"import json\nwith open(\u0027data.json\u0027, \u0027w\u0027, encoding\u003d\u0027utf-8\u0027) as f:\n    json.dump(data, f, ensure_ascii\u003dFalse, indent\u003d4)"},{"id":0,"score":0.0,"value":"import io, json\nwith io.open(\u0027data.txt\u0027, \u0027w\u0027, encoding\u003d\u0027utf-8\u0027) as f:\n  f.write(json.dumps(data, ensure_ascii\u003dFalse))"},{"id":0,"score":0.0,"value":"import json\nwith open(\u0027data.txt\u0027, \u0027w\u0027) as f:\n  json.dump(data, f, ensure_ascii\u003dFalse)"},{"id":0,"score":0.0,"value":"import json, codecs\nwith open(\u0027data.txt\u0027, \u0027wb\u0027) as f:\n    json.dump(data, codecs.getwriter(\u0027utf-8\u0027)(f), ensure_ascii\u003dFalse)"},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e json.dumps({\u0027price\u0027: \u0027€10\u0027})\n\u0027{\"price\": \"\\\\u20ac10\"}\u0027\n\u003e\u003e\u003e json.dumps({\u0027price\u0027: \u0027€10\u0027}, ensure_ascii\u003dFalse)\n\u0027{\"price\": \"€10\"}\u0027\n\n\u003e\u003e\u003e len(json.dumps({\u0027абвгд\u0027: 1}))\n37\n\u003e\u003e\u003e len(json.dumps({\u0027абвгд\u0027: 1}, ensure_ascii\u003dFalse).encode(\u0027utf8\u0027))\n17"},{"id":0,"score":0.0,"value":"with open(\u0027data.txt\u0027, \u0027w\u0027) as outfile:\n     json.dump(jsonData, outfile, sort_keys \u003d True, indent \u003d 4,\n               ensure_ascii \u003d False)"}]},{"query":"write json in variable to file ","hypotheses":[{"id":0,"score":0.0,"value":"import json\nwith open(\u0027data.json\u0027, \u0027w\u0027) as f:\n    json.dump(data, f)"},{"id":0,"score":0.0,"value":"import json\nwith open(\u0027data.json\u0027, \u0027w\u0027, encoding\u003d\u0027utf-8\u0027) as f:\n    json.dump(data, f, ensure_ascii\u003dFalse, indent\u003d4)"},{"id":0,"score":0.0,"value":"import io, json\nwith io.open(\u0027data.txt\u0027, \u0027w\u0027, encoding\u003d\u0027utf-8\u0027) as f:\n  f.write(json.dumps(data, ensure_ascii\u003dFalse))"},{"id":0,"score":0.0,"value":"import json\nwith open(\u0027data.txt\u0027, \u0027w\u0027) as f:\n  json.dump(data, f, ensure_ascii\u003dFalse)"},{"id":0,"score":0.0,"value":"import json, codecs\nwith open(\u0027data.txt\u0027, \u0027wb\u0027) as f:\n    json.dump(data, codecs.getwriter(\u0027utf-8\u0027)(f), ensure_ascii\u003dFalse)"},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e json.dumps({\u0027price\u0027: \u0027€10\u0027})\n\u0027{\"price\": \"\\\\u20ac10\"}\u0027\n\u003e\u003e\u003e json.dumps({\u0027price\u0027: \u0027€10\u0027}, ensure_ascii\u003dFalse)\n\u0027{\"price\": \"€10\"}\u0027\n\n\u003e\u003e\u003e len(json.dumps({\u0027абвгд\u0027: 1}))\n37\n\u003e\u003e\u003e len(json.dumps({\u0027абвгд\u0027: 1}, ensure_ascii\u003dFalse).encode(\u0027utf8\u0027))\n17"},{"id":0,"score":0.0,"value":"with open(\u0027data.txt\u0027, \u0027w\u0027) as outfile:\n     json.dump(jsonData, outfile, sort_keys \u003d True, indent \u003d 4,\n               ensure_ascii \u003d False)"}]}],[{"query":"loop over a range of `count`","hypotheses":[{"id":0,"score":0.0,"value":"for idx,item in enumerate(list):"},{"id":0,"score":0.0,"value":"#count\u003d0\nfor idx, item in enumerate(list):\n    print item\n    #count +\u003d1\n    #if count % 10 \u003d\u003d 0:\n    if (idx+1) % 10 \u003d\u003d 0:\n        print \u0027did ten\u0027"},{"id":0,"score":0.0,"value":"rownum \u003d Range(\u0027A1\u0027).current_region.last_cell.row"},{"id":0,"score":0.0,"value":"for i in range(1, rownum + 1): # The indexing starts at 1\n    Range((i, 1)) \u003d ...    # Will select cell \u0027Ai\u0027"},{"id":0,"score":0.0,"value":"count \u003d 0"},{"id":0,"score":0.0,"value":"for count, item in enumerate(animals):\n    print(\"Animal number\", count + 1, \"in the list is\", item)"},{"id":0,"score":0.0,"value":"for key, group in groupby(column):\n    count \u003d sum(1 for item in group) # Thanks JBernardo\n    # the key is what is in the column, count is the number of items"}]},{"query":"loop over a range","hypotheses":[{"id":0,"score":0.0,"value":"1           0 LOAD_CONST               0 (0)\n            3 STORE_NAME               0 (i)\n\n2           6 SETUP_LOOP              28 (to 37)\n      \u003e\u003e    9 LOAD_NAME                0 (i)              # \u003c-\n           12 LOAD_CONST               1 (100000000)      # \u003c-\n           15 COMPARE_OP               0 (\u003c)              # \u003c-\n           18 JUMP_IF_FALSE           14 (to 35)          # \u003c-\n           21 POP_TOP                                     # \u003c-\n\n3          22 LOAD_NAME                0 (i)              # \u003c-\n           25 LOAD_CONST               2 (1)              # \u003c-\n           28 INPLACE_ADD                                 # \u003c-\n           29 STORE_NAME               0 (i)              # \u003c-\n           32 JUMP_ABSOLUTE            9                  # \u003c-\n      \u003e\u003e   35 POP_TOP\n           36 POP_BLOCK"},{"id":0,"score":0.0,"value":"1           0 SETUP_LOOP              23 (to 26)\n            3 LOAD_NAME                0 (range)\n            6 LOAD_CONST               0 (0)\n            9 LOAD_CONST               1 (100000000)\n           12 CALL_FUNCTION            2\n           15 GET_ITER\n      \u003e\u003e   16 FOR_ITER                 6 (to 25)        # \u003c-\n           19 STORE_NAME               1 (n)            # \u003c-\n\n2          22 JUMP_ABSOLUTE           16                # \u003c-\n      \u003e\u003e   25 POP_BLOCK\n      \u003e\u003e   26 LOAD_CONST               2 (None)\n           29 RETURN_VALUE"},{"id":0,"score":0.0,"value":"for (int number \u003d 1; number \u003c 101; number++) {\n  printf(\"%d\\n\", number);\n}"},{"id":0,"score":0.0,"value":"i +\u003d 1"},{"id":0,"score":0.0,"value":"i \u003d i + 1"},{"id":0,"score":0.0,"value":"i \u003d new int(i + 1)   # Using C++ or Java-ish syntax"},{"id":0,"score":0.0,"value":"variables \u003d [x0, x1, x2, x3, x4, x5, x6, x7, x8, x9]\nfor x in variables:\n    print x"}]}],[{"query":"randomly pick an item from `seq`","hypotheses":[{"id":0,"score":0.0,"value":"import random\n\nfoo \u003d [\u0027a\u0027, \u0027b\u0027, \u0027c\u0027, \u0027d\u0027, \u0027e\u0027]\nprint(random.choice(foo))"},{"id":0,"score":0.0,"value":"import secrets\n\nfoo \u003d [\u0027battery\u0027, \u0027correct\u0027, \u0027horse\u0027, \u0027staple\u0027]\nprint(secrets.choice(foo))"},{"id":0,"score":0.0,"value":"import random\n\nsecure_random \u003d random.SystemRandom()\nprint(secure_random.choice(foo))"},{"id":0,"score":0.0,"value":"import random\ngroup_of_items \u003d {\u0027a\u0027, \u0027b\u0027, \u0027c\u0027, \u0027d\u0027, \u0027e\u0027}  # a sequence or set will work here.\nnum_to_select \u003d 2                           # set the number to select here.\nlist_of_random_items \u003d random.sample(group_of_items, num_to_select)\nfirst_random_item \u003d list_of_random_items[0]\nsecond_random_item \u003d list_of_random_items[1]"},{"id":0,"score":0.0,"value":"import secrets                              # imports secure module.\nsecure_random \u003d secrets.SystemRandom()      # creates a secure random object.\ngroup_of_items \u003d {\u0027a\u0027, \u0027b\u0027, \u0027c\u0027, \u0027d\u0027, \u0027e\u0027}  # a sequence or set will work here.\nnum_to_select \u003d 2                           # set the number to select here.\nlist_of_random_items \u003d secure_random.sample(group_of_items, num_to_select)\nfirst_random_item \u003d list_of_random_items[0]\nsecond_random_item \u003d list_of_random_items[1]"},{"id":0,"score":0.0,"value":"import random\nfirst_random_item, second_random_item \u003d random.sample({\u0027a\u0027, \u0027b\u0027, \u0027c\u0027, \u0027d\u0027, \u0027e\u0027}, 2)"},{"id":0,"score":0.0,"value":"from random import randrange\nrandom_index \u003d randrange(len(foo))\nprint(foo[random_index])"}]},{"query":"randomly pick an item","hypotheses":[{"id":0,"score":0.0,"value":"import random\n\nfoo \u003d [\u0027a\u0027, \u0027b\u0027, \u0027c\u0027, \u0027d\u0027, \u0027e\u0027]\nprint(random.choice(foo))"},{"id":0,"score":0.0,"value":"import secrets\n\nfoo \u003d [\u0027battery\u0027, \u0027correct\u0027, \u0027horse\u0027, \u0027staple\u0027]\nprint(secrets.choice(foo))"},{"id":0,"score":0.0,"value":"import random\n\nsecure_random \u003d random.SystemRandom()\nprint(secure_random.choice(foo))"},{"id":0,"score":0.0,"value":"import random\nrandom.sample(set([1, 2, 3, 4, 5, 6]), 2)"},{"id":0,"score":0.0,"value":"import random\ngroup_of_items \u003d {\u0027a\u0027, \u0027b\u0027, \u0027c\u0027, \u0027d\u0027, \u0027e\u0027}  # a sequence or set will work here.\nnum_to_select \u003d 2                           # set the number to select here.\nlist_of_random_items \u003d random.sample(group_of_items, num_to_select)\nfirst_random_item \u003d list_of_random_items[0]\nsecond_random_item \u003d list_of_random_items[1]"},{"id":0,"score":0.0,"value":"import secrets                              # imports secure module.\nsecure_random \u003d secrets.SystemRandom()      # creates a secure random object.\ngroup_of_items \u003d {\u0027a\u0027, \u0027b\u0027, \u0027c\u0027, \u0027d\u0027, \u0027e\u0027}  # a sequence or set will work here.\nnum_to_select \u003d 2                           # set the number to select here.\nlist_of_random_items \u003d secure_random.sample(group_of_items, num_to_select)\nfirst_random_item \u003d list_of_random_items[0]\nsecond_random_item \u003d list_of_random_items[1]"},{"id":0,"score":0.0,"value":"import random\nfirst_random_item, second_random_item \u003d random.sample({\u0027a\u0027, \u0027b\u0027, \u0027c\u0027, \u0027d\u0027, \u0027e\u0027}, 2)"}]}],[{"query":"call `pick_with_replacement`","hypotheses":[{"id":0,"score":0.0,"value":"class Person:\n    @staticmethod\n    def call_person():\n        print \"hello person\"\n\n# Calling static methods works on classes as well as instances of that class\nPerson.call_person()  # calling on class\np \u003d Person()\np.call_person()       # calling on instance of class"},{"id":0,"score":0.0,"value":"class Person:\n    @classmethod\n    def call_person(cls):\n        print \"hello person\",cls\n\np \u003d Person().call_person() # using classmethod on instance\nPerson.call_person()       # using classmethod on class"},{"id":0,"score":0.0,"value":"import Person  # Person class is available as Person.Person\nPerson.Person.call_person() # this should work\nPerson.Person().call_person() # this should work as well"},{"id":0,"score":0.0,"value":"from Person import Person\nPerson.call_person()"},{"id":0,"score":0.0,"value":"# Person.py\ndef call_person():\n    print \"Hello person\""},{"id":0,"score":0.0,"value":"import Person\nPerson.call_person() # \u0027Hello person\u0027"},{"id":0,"score":0.0,"value":"np.random.choice(\n  [\u0027pooh\u0027, \u0027rabbit\u0027, \u0027piglet\u0027, \u0027Christopher\u0027], \n  5,\n  p\u003d[0.5, 0.1, 0.1, 0.3]\n)"}]},{"query":"call function","hypotheses":[{"id":0,"score":0.0,"value":"class MyClass(object):\n    def install(self):\n          print \"In install\"\n\nmethod_name \u003d \u0027install\u0027 # set by the command line options\nmy_cls \u003d MyClass()\n\nmethod \u003d None\ntry:\n    method \u003d getattr(my_cls, method_name)\nexcept AttributeError:\n    raise NotImplementedError(\"Class `{}` does not implement `{}`\".format(my_cls.__class__.__name__, method_name))\n\nmethod()"},{"id":0,"score":0.0,"value":"def install():\n       print \"In install\"\n\nmethod_name \u003d \u0027install\u0027 # set by the command line options\npossibles \u003d globals().copy()\npossibles.update(locals())\nmethod \u003d possibles.get(method_name)\nif not method:\n     raise NotImplementedError(\"Method %s not implemented\" % method_name)\nmethod()"},{"id":0,"score":0.0,"value":"def install():\n    print \"In install\"\n\nmethods \u003d {\u0027install\u0027: install}\n\nmethod_name \u003d \u0027install\u0027 # set by the command line options\nif method_name in methods:\n    methods[method_name]() # + argument list of course\nelse:\n    raise Exception(\"Method %s not implemented\" % method_name)"},{"id":0,"score":0.0,"value":"def install():\n    print \"In install\""},{"id":0,"score":0.0,"value":"def installWithOptions(var1, var2):\n    print \"In install with options \" + var1 + \" \" + var2"},{"id":0,"score":0.0,"value":"method_name1 \u003d \u0027install()\u0027\nmethod_name2 \u003d \u0027installWithOptions(\"a\",\"b\")\u0027\neval(method_name1)\neval(method_name2)"},{"id":0,"score":0.0,"value":"In install\nIn install with options a b"}]}],[{"query":"walk all nested files in the directory \"data\"","hypotheses":[{"id":0,"score":0.0,"value":"for path, subdirs, files in os.walk(root):\n    for name in files:\n        print(os.path.join(path, name))"},{"id":0,"score":0.0,"value":"pathlib.PurePath(path, name)"},{"id":0,"score":0.0,"value":"#!/usr/bin/python\n\nimport os\n\n# traverse root directory, and list directories as dirs and files as files\nfor root, dirs, files in os.walk(\".\"):\n    path \u003d root.split(os.sep)\n    print((len(path) - 1) * \u0027---\u0027, os.path.basename(root))\n    for file in files:\n        print(len(path) * \u0027---\u0027, file)"},{"id":0,"score":0.0,"value":"import os\n\ndef list_files(startpath):\n    for root, dirs, files in os.walk(startpath):\n        level \u003d root.replace(startpath, \u0027\u0027).count(os.sep)\n        indent \u003d \u0027 \u0027 * 4 * (level)\n        print(\u0027{}{}/\u0027.format(indent, os.path.basename(root)))\n        subindent \u003d \u0027 \u0027 * 4 * (level + 1)\n        for f in files:\n            print(\u0027{}{}\u0027.format(subindent, f))"},{"id":0,"score":0.0,"value":"list_of_files \u003d {}\nfor (dirpath, dirnames, filenames) in os.walk(path):\n    for filename in filenames:\n        if filename.endswith(\u0027.html\u0027): \n            list_of_files[filename] \u003d os.sep.join([dirpath, filename])"},{"id":0,"score":0.0,"value":"import os\nfrom fnmatch import fnmatch\n\nroot \u003d \u0027/some/directory\u0027\npattern \u003d \"*.py\"\n\nfor path, subdirs, files in os.walk(root):\n    for name in files:\n        if fnmatch(name, pattern):\n            print os.path.join(path, name)"},{"id":0,"score":0.0,"value":"from pathlib import Path\n\nclass DisplayablePath(object):\n    display_filename_prefix_middle \u003d \u0027├──\u0027\n    display_filename_prefix_last \u003d \u0027└──\u0027\n    display_parent_prefix_middle \u003d \u0027    \u0027\n    display_parent_prefix_last \u003d \u0027│   \u0027\n\n    def __init__(self, path, parent_path, is_last):\n        self.path \u003d Path(str(path))\n        self.parent \u003d parent_path\n        self.is_last \u003d is_last\n        if self.parent:\n            self.depth \u003d self.parent.depth + 1\n        else:\n            self.depth \u003d 0\n\n    @property\n    def displayname(self):\n        if self.path.is_dir():\n            return self.path.name + \u0027/\u0027\n        return self.path.name\n\n    @classmethod\n    def make_tree(cls, root, parent\u003dNone, is_last\u003dFalse, criteria\u003dNone):\n        root \u003d Path(str(root))\n        criteria \u003d criteria or cls._default_criteria\n\n        displayable_root \u003d cls(root, parent, is_last)\n        yield displayable_root\n\n        children \u003d sorted(list(path\n                               for path in root.iterdir()\n                               if criteria(path)),\n                          key\u003dlambda s: str(s).lower())\n        count \u003d 1\n        for path in children:\n            is_last \u003d count \u003d\u003d len(children)\n            if path.is_dir():\n                yield from cls.make_tree(path,\n                                         parent\u003ddisplayable_root,\n                                         is_last\u003dis_last,\n                                         criteria\u003dcriteria)\n            else:\n                yield cls(path, displayable_root, is_last)\n            count +\u003d 1\n\n    @classmethod\n    def _default_criteria(cls, path):\n        return True\n\n    @property\n    def displayname(self):\n        if self.path.is_dir():\n            return self.path.name + \u0027/\u0027\n        return self.path.name\n\n    def displayable(self):\n        if self.parent is None:\n            return self.displayname\n\n        _filename_prefix \u003d (self.display_filename_prefix_last\n                            if self.is_last\n                            else self.display_filename_prefix_middle)\n\n        parts \u003d [\u0027{!s} {!s}\u0027.format(_filename_prefix,\n                                    self.displayname)]\n\n        parent \u003d self.parent\n        while parent and parent.parent is not None:\n            parts.append(self.display_parent_prefix_middle\n                         if parent.is_last\n                         else self.display_parent_prefix_last)\n            parent \u003d parent.parent\n\n        return \u0027\u0027.join(reversed(parts))"}]},{"query":"walk all nested files in the directory","hypotheses":[{"id":0,"score":0.0,"value":"import os\nrootdir \u003d \u0027C:/Users/sid/Desktop/test\u0027\n\nfor subdir, dirs, files in os.walk(rootdir):\n    for file in files:\n        print os.path.join(subdir, file)"},{"id":0,"score":0.0,"value":"import os\nrootdir \u003d \u0027C:/Users/sid/Desktop/test\u0027\n\nfor subdir, dirs, files in os.walk(rootdir):\n    for file in files:\n        print(os.path.join(subdir, file))"},{"id":0,"score":0.0,"value":"for path, subdirs, files in os.walk(root):\n    for name in files:\n        print(os.path.join(path, name))"},{"id":0,"score":0.0,"value":"pathlib.PurePath(path, name)"},{"id":0,"score":0.0,"value":"#!/usr/bin/python\n\nimport os\n\n# traverse root directory, and list directories as dirs and files as files\nfor root, dirs, files in os.walk(\".\"):\n    path \u003d root.split(os.sep)\n    print((len(path) - 1) * \u0027---\u0027, os.path.basename(root))\n    for file in files:\n        print(len(path) * \u0027---\u0027, file)"},{"id":0,"score":0.0,"value":"p \u003d Path(r\u0027C:\\Users\\akrio\\Desktop\\Test\u0027).glob(\u0027**/*\u0027)\nfiles \u003d [x for x in p if x.is_file()]"},{"id":0,"score":0.0,"value":"list_of_files \u003d {}\nfor (dirpath, dirnames, filenames) in os.walk(path):\n    for filename in filenames:\n        if filename.endswith(\u0027.html\u0027): \n            list_of_files[filename] \u003d os.sep.join([dirpath, filename])"}]}],[{"query":"assign current date and time to `now`","hypotheses":[{"id":0,"score":0.0,"value":"\u003e\u003e\u003e import datetime\n\u003e\u003e\u003e datetime.datetime.now()\ndatetime.datetime(2009, 1, 6, 15, 8, 24, 78915)\n\n\u003e\u003e\u003e print(datetime.datetime.now())\n2009-01-06 15:08:24.789150"},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e datetime.datetime.now().time()\ndatetime.time(15, 8, 24, 78915)\n\n\u003e\u003e\u003e print(datetime.datetime.now().time())\n15:08:24.789150"},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e from datetime import datetime"},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e from time import gmtime, strftime\n\u003e\u003e\u003e strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())\n\u00272009-01-05 22:14:39\u0027"},{"id":0,"score":0.0,"value":"from datetime import datetime\ndatetime.now().strftime(\u0027%Y-%m-%d %H:%M:%S\u0027)"},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e from datetime import datetime\n\u003e\u003e\u003e str(datetime.now())\n\u00272011-05-03 17:45:35.177000\u0027"},{"id":0,"score":0.0,"value":"import time"}]},{"query":"assign current date and time to variable","hypotheses":[{"id":0,"score":0.0,"value":"\u003e\u003e\u003e pandas.to_datetime(\u0027today\u0027).normalize()\nTimestamp(\u00272015-10-14 00:00:00\u0027)"},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e import datetime\n# 05/10/09 18:00\n\u003e\u003e\u003e d \u003d datetime.datetime(2009, 10, 5, 18, 00)\n\u003e\u003e\u003e print d.year, d.month, d.day, d.hour, d.second\n2009 10 5 18 0\n\u003e\u003e\u003e print d.isoformat(\u0027 \u0027)\n2009-10-05 18:00:00\n\u003e\u003e\u003e"},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e dt.datetime.today().strftime(\"%m/%d/%Y\")\n                   # ^ note parentheses\n\u002702/12/2014\u0027"},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e parse(\"Thu Sep 25 2003\")\ndatetime.datetime(2003, 9, 25, 0, 0)\n\n\u003e\u003e\u003e parse(\"Sep 25 2003\")\ndatetime.datetime(2003, 9, 25, 0, 0)\n\n\u003e\u003e\u003e parse(\"Sep 2003\", default\u003dDEFAULT)\ndatetime.datetime(2003, 9, 25, 0, 0)\n\n\u003e\u003e\u003e parse(\"Sep\", default\u003dDEFAULT)\ndatetime.datetime(2003, 9, 25, 0, 0)\n\n\u003e\u003e\u003e parse(\"2003\", default\u003dDEFAULT)\ndatetime.datetime(2003, 9, 25, 0, 0)"},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e parse(\"10-09-2003\")\ndatetime.datetime(2003, 10, 9, 0, 0)\n\n\u003e\u003e\u003e parse(\"10-09-2003\", dayfirst\u003dTrue)\ndatetime.datetime(2003, 9, 10, 0, 0)\n\n\u003e\u003e\u003e parse(\"10-09-03\")\ndatetime.datetime(2003, 10, 9, 0, 0)\n\n\u003e\u003e\u003e parse(\"10-09-03\", yearfirst\u003dTrue)\ndatetime.datetime(2010, 9, 3, 0, 0)"},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e parse(\"Wed, July 10, \u002796\")\ndatetime.datetime(1996, 7, 10, 0, 0)\n\n\u003e\u003e\u003e parse(\"1996.07.10 AD at 15:08:56 PDT\", ignoretz\u003dTrue)\ndatetime.datetime(1996, 7, 10, 15, 8, 56)\n\n\u003e\u003e\u003e parse(\"Tuesday, April 12, 1952 AD 3:30:42pm PST\", ignoretz\u003dTrue)\ndatetime.datetime(1952, 4, 12, 15, 30, 42)\n\n\u003e\u003e\u003e parse(\"November 5, 1994, 8:15:30 am EST\", ignoretz\u003dTrue)\ndatetime.datetime(1994, 11, 5, 8, 15, 30)\n\n\u003e\u003e\u003e parse(\"3rd of May 2001\")\ndatetime.datetime(2001, 5, 3, 0, 0)\n\n\u003e\u003e\u003e parse(\"5:50 A.M. on June 13, 1990\")\ndatetime.datetime(1990, 6, 13, 5, 50)"},{"id":0,"score":0.0,"value":"def assign():\n    a \u003d int()\n    b \u003d float(a)"}]}],[{"query":"convert `week_date` to GMT timezone and assign to `GMT_week_date`","hypotheses":[{"id":0,"score":0.0,"value":"import pytz\neastern \u003d pytz.timezone(\u0027US/Eastern\u0027)\ndf.index \u003d df.index.tz_localize(pytz.utc).tz_convert(eastern)"},{"id":0,"score":0.0,"value":"import pandas as pd\nimport pytz\n\nindex \u003d pd.date_range(\u002720140101 21:55\u0027, freq\u003d\u002715S\u0027, periods\u003d5)\ndf \u003d pd.DataFrame(1, index\u003dindex, columns\u003d[\u0027X\u0027])\nprint(df)\n#                      X\n# 2014-01-01 21:55:00  1\n# 2014-01-01 21:55:15  1\n# 2014-01-01 21:55:30  1\n# 2014-01-01 21:55:45  1\n# 2014-01-01 21:56:00  1\n\n# [5 rows x 1 columns]\nprint(df.index)\n# \u003cclass \u0027pandas.tseries.index.DatetimeIndex\u0027\u003e\n# [2014-01-01 21:55:00, ..., 2014-01-01 21:56:00]\n# Length: 5, Freq: 15S, Timezone: None\n\neastern \u003d pytz.timezone(\u0027US/Eastern\u0027)\ndf.index \u003d df.index.tz_localize(pytz.utc).tz_convert(eastern)\nprint(df)\n#                            X\n# 2014-01-01 16:55:00-05:00  1\n# 2014-01-01 16:55:15-05:00  1\n# 2014-01-01 16:55:30-05:00  1\n# 2014-01-01 16:55:45-05:00  1\n# 2014-01-01 16:56:00-05:00  1\n\n# [5 rows x 1 columns]\n\nprint(df.index)\n# \u003cclass \u0027pandas.tseries.index.DatetimeIndex\u0027\u003e\n# [2014-01-01 16:55:00-05:00, ..., 2014-01-01 16:56:00-05:00]\n# Length: 5, Freq: 15S, Timezone: US/Eastern"},{"id":0,"score":0.0,"value":"In [11]: dat.index \u003d pd.to_datetime(dat.pop(\u0027datetime\u0027), utc\u003dTrue)\n\nIn [12]: dat\nOut[12]:\n                    label  value\ndatetime\n2011-07-19 07:00:00     a      0\n2011-07-19 08:00:00     a      1\n2011-07-19 09:00:00     a      2\n2011-07-19 07:00:00     b      3\n2011-07-19 08:00:00     b      4\n2011-07-19 09:00:00     b      5"},{"id":0,"score":0.0,"value":"In [12]: dat.index \u003d dat.index.tz_localize(\u0027UTC\u0027).tz_convert(\u0027US/Pacific\u0027)\n\nIn [13]: dat\nOut[13]:\n                          label  value\ndatetime\n2011-07-19 00:00:00-07:00     a      0\n2011-07-19 01:00:00-07:00     a      1\n2011-07-19 02:00:00-07:00     a      2\n2011-07-19 00:00:00-07:00     b      3\n2011-07-19 01:00:00-07:00     b      4\n2011-07-19 02:00:00-07:00     b      5"},{"id":0,"score":0.0,"value":"In [14]: dat.set_index(\u0027label\u0027, append\u003dTrue).swaplevel(0, 1)\nOut[14]:\n                           value\nlabel datetime\na     2011-07-19 07:00:00      0\n      2011-07-19 08:00:00      1\n      2011-07-19 09:00:00      2\nb     2011-07-19 07:00:00      3\n      2011-07-19 08:00:00      4\n      2011-07-19 09:00:00      5"},{"id":0,"score":0.0,"value":"In [15]: dat.index.levels[1] \u003d dat.index.get_level_values(1).tz_localize(\u0027UTC\u0027).tz_convert(\u0027US/Pacific\u0027)\n\nIn [16]: dat1\nOut[16]:\n                                 value\nlabel datetime\na     2011-07-19 00:00:00-07:00      0\n      2011-07-19 01:00:00-07:00      1\n      2011-07-19 02:00:00-07:00      2\nb     2011-07-19 00:00:00-07:00      3\n      2011-07-19 01:00:00-07:00      4\n      2011-07-19 02:00:00-07:00      5"},{"id":0,"score":0.0,"value":"df \u003d pd.DataFrame({\u0027Symbol\u0027: [\u0027EUR/USD\u0027] * 5,\n                  \u0027bid\u0027: [1.37622, 1.37624, 1.37619, 1.37616, 1.37616],\n                  \u0027ask\u0027: [1.37693, 1.37698, 1.37696, 1.37696, 1.37694]})\n\ndf.index \u003d pd.to_datetime([\u00272014-01-01 21:55:34.378000\u0027,\n                          \u00272014-01-01 21:55:40.410000\u0027,\n                          \u00272014-01-01 21:55:47.210000\u0027,\n                          \u00272014-01-01 21:55:57.963000\u0027,\n                          \u00272014-01-01 21:56:03.117000\u0027],\n                           utc\u003dTrue)"}]},{"query":"convert variable to GMT timezone and assign to another variable","hypotheses":[{"id":0,"score":0.0,"value":"from datetime import datetime\nfrom pytz import timezone    \n\nsouth_africa \u003d timezone(\u0027Africa/Johannesburg\u0027)\nsa_time \u003d datetime.now(south_africa)\nprint sa_time.strftime(\u0027%Y-%m-%d_%H-%M-%S\u0027)"},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e from datetime import datetime\n\u003e\u003e\u003e import pytz\n\u003e\u003e\u003e utc \u003d pytz.utc\n\u003e\u003e\u003e utc.zone\n\u0027UTC\u0027\n\u003e\u003e\u003e eastern \u003d pytz.timezone(\u0027US/Eastern\u0027)\n\u003e\u003e\u003e eastern.zone\n\u0027US/Eastern\u0027\n\u003e\u003e\u003e amsterdam \u003d pytz.timezone(\u0027Europe/Amsterdam\u0027)\n\u003e\u003e\u003e fmt \u003d \u0027%Y-%m-%d %H:%M:%S %Z%z\u0027\n\n\u003e\u003e\u003e loc_dt \u003d eastern.localize(datetime(2002, 10, 27, 6, 0, 0))\n\u003e\u003e\u003e print loc_dt.strftime(fmt)\n2002-10-27 06:00:00 EST-0500\n\n\u003e\u003e\u003e ams_dt \u003d loc_dt.astimezone(amsterdam)\n\u003e\u003e\u003e ams_dt.strftime(fmt)\n\u00272002-10-27 12:00:00 CET+0100\u0027"},{"id":0,"score":0.0,"value":"pytz.utc.localize(utc_time, is_dst\u003dNone).astimezone(tz)"},{"id":0,"score":0.0,"value":"tz.fromutc(utc_time)"},{"id":0,"score":0.0,"value":"#!/usr/bin/env python\nfrom datetime import datetime \nimport pytz # $ pip install pytz\n\ntz \u003d pytz.timezone(\"US/Pacific\")\naware \u003d tz.localize(datetime(2011, 2, 11, 20), is_dst\u003dNone)"},{"id":0,"score":0.0,"value":"timestamp \u003d (aware - datetime(1970, 1, 1, tzinfo\u003dpytz.utc)).total_seconds()"},{"id":0,"score":0.0,"value":"#XXX: WRONG (for any timezone with a non-fixed utc offset), DON\u0027T DO IT\ndatetime(2011,2,11,20,0,0,0,pacific).astimezone(utc).strftime(\"%s\")"}]}],[{"query":"display `week_date` in format mm-dd-yyyy hh:mm ","hypotheses":[{"id":0,"score":0.0,"value":"\u003e\u003e\u003e from datetime import datetime\n\u003e\u003e\u003e datetime.today().strftime(\u0027%Y-%m-%d\u0027)\n\u00272021-01-26\u0027"},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e datetime.today().strftime(\u0027%Y-%m-%d-%H:%M:%S\u0027)\n\u00272021-01-26-16:50:03\u0027"},{"id":0,"score":0.0,"value":"from datetime import date\ntoday \u003d str(date.today())\nprint(today)   # \u00272017-12-26\u0027"},{"id":0,"score":0.0,"value":"import datetime\n\ndatetime.datetime.strptime(\"21/12/2008\", \"%d/%m/%Y\").strftime(\"%Y-%m-%d\")"},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e from datetime import datetime\n\u003e\u003e\u003e inDate \u003d \"29-Apr-2013-15:59:02\"\n\u003e\u003e\u003e d \u003d datetime.strptime(inDate, \"%d-%b-%Y-%H:%M:%S\")\n\u003e\u003e\u003e d\ndatetime.datetime(2013, 4, 29, 15, 59, 2)\n\u003e\u003e\u003e d.strftime(\"YYYYMMDD HH:mm:ss (%Y%m%d %H:%M:%S)\")\n\u0027YYYYMMDD HH:mm:ss (20130429 15:59:02)\u0027"},{"id":0,"score":0.0,"value":"time.strftime(\u0027%m/%d/%Y\u0027, time.gmtime(os.path.getmtime(file)))"},{"id":0,"score":0.0,"value":"from datetime import date    \ntoday \u003d date.today().isoformat()\nprint(today)  # \u00272018-12-05\u0027"}]},{"query":"display datetime in format mm-dd-yyyy hh:mm ","hypotheses":[{"id":0,"score":0.0,"value":"\u003e\u003e\u003e from datetime import datetime\n\u003e\u003e\u003e inDate \u003d \"29-Apr-2013-15:59:02\"\n\u003e\u003e\u003e d \u003d datetime.strptime(inDate, \"%d-%b-%Y-%H:%M:%S\")\n\u003e\u003e\u003e d\ndatetime.datetime(2013, 4, 29, 15, 59, 2)\n\u003e\u003e\u003e d.strftime(\"YYYYMMDD HH:mm:ss (%Y%m%d %H:%M:%S)\")\n\u0027YYYYMMDD HH:mm:ss (20130429 15:59:02)\u0027"},{"id":0,"score":0.0,"value":"value \u003d datetime.datetime.strptime(\"2014-06-23 13:56:30\", \"%Y-%m-%d %H:%M:%S\")\ncell \u003d ws[\u0027A1\u0027]\ncell.value \u003d value\ncell.number_format \u003d \u0027YYYY MMM DD\u0027"},{"id":0,"score":0.0,"value":"from openpyxl.styles import NamedStyle\n\ndate_style \u003d NamedStyle(name\u003d\u0027datetime\u0027, number_format\u003d\u0027DD/MM/YYYY HH:MM:MM\u0027)\nws[\u0027A1\u0027].style \u003d date_style"},{"id":0,"score":0.0,"value":"from openpyxl.styles import NamedStyle\n\nNamedStyle(name\u003d\u0027custom_datetime\u0027, number_format\u003d\u0027DD/MM/YYYY HH:MM:MM\u0027)\nws[\u0027A1\u0027].style \u003d \u0027custom_datetime\u0027"},{"id":0,"score":0.0,"value":"now \u003d datetime.now().strftime(\"%Y-%m-%d %H:%M[:%S[.%f]]\")"},{"id":0,"score":0.0,"value":"now \u003d datetime.now().strftime(\"%Y-%m-%d %H:%M\")"},{"id":0,"score":0.0,"value":"now \u003d datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")"}]}],[{"query":"change datetime format of `week_date` to mm-dd-yyyy hh:mm","hypotheses":[{"id":0,"score":0.0,"value":"\u003e\u003e\u003e from datetime import datetime\n\u003e\u003e\u003e datetime.today().strftime(\u0027%Y-%m-%d\u0027)\n\u00272021-01-26\u0027"},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e datetime.today().strftime(\u0027%Y-%m-%d-%H:%M:%S\u0027)\n\u00272021-01-26-16:50:03\u0027"},{"id":0,"score":0.0,"value":"from datetime import date\ntoday \u003d str(date.today())\nprint(today)   # \u00272017-12-26\u0027"},{"id":0,"score":0.0,"value":"from datetime import date    \ntoday \u003d date.today().isoformat()\nprint(today)  # \u00272018-12-05\u0027"},{"id":0,"score":0.0,"value":"from datetime import datetime\nnow \u003d datetime.today().isoformat()\nprint(now)  # \u00272018-12-05T11:15:55.126382\u0027"},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e import arrow\n\u003e\u003e\u003e arrow.now().format(\u0027YYYY-MM-DD\u0027)\n\u00272017-02-17\u0027"},{"id":0,"score":0.0,"value":"import time\ntoday \u003d time.strftime(\"%Y-%m-%d\")\n# 2021-05-02"}]},{"query":"change datetime format to mm-dd-yyyy hh:mm","hypotheses":[{"id":0,"score":0.0,"value":"import datetime\n\ndatetime.datetime.strptime(\"21/12/2008\", \"%d/%m/%Y\").strftime(\"%Y-%m-%d\")"},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e import datetime\n\u003e\u003e\u003e d \u003d datetime.datetime.strptime(\u00272011-06-09\u0027, \u0027%Y-%m-%d\u0027)\n\u003e\u003e\u003e d.strftime(\u0027%b %d,%Y\u0027)\n\u0027Jun 09,2011\u0027"},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e from datetime import datetime\n\u003e\u003e\u003e inDate \u003d \"29-Apr-2013-15:59:02\"\n\u003e\u003e\u003e d \u003d datetime.strptime(inDate, \"%d-%b-%Y-%H:%M:%S\")\n\u003e\u003e\u003e d\ndatetime.datetime(2013, 4, 29, 15, 59, 2)\n\u003e\u003e\u003e d.strftime(\"YYYYMMDD HH:mm:ss (%Y%m%d %H:%M:%S)\")\n\u0027YYYYMMDD HH:mm:ss (20130429 15:59:02)\u0027"},{"id":0,"score":0.0,"value":"lastconnection \u003d datetime.strptime(\"21/12/2008\", \"%d/%m/%Y\").strftime(\u0027%Y-%m-%d\u0027)"},{"id":0,"score":0.0,"value":"now \u003d datetime.now().strftime(\"%Y-%m-%d %H:%M[:%S[.%f]]\")"},{"id":0,"score":0.0,"value":"now \u003d datetime.now().strftime(\"%Y-%m-%d %H:%M\")"},{"id":0,"score":0.0,"value":"now \u003d datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")"}]}],[{"query":"read csv file \"data.csv\"","hypotheses":[{"id":0,"score":0.0,"value":"with open(\u0027some.csv\u0027, newline\u003d\u0027\u0027) as f:\n  reader \u003d csv.reader(f)\n  row1 \u003d next(reader)  # gets the first line\n  # now do something here \n  # if first row is the header, then you can do one more next() to get the next row:\n  # row2 \u003d next(f)"},{"id":0,"score":0.0,"value":"with open(\u0027some.csv\u0027, newline\u003d\u0027\u0027) as f:\n  reader \u003d csv.reader(f)\n  for row in reader:\n    # do something here with `row`\n    break"},{"id":0,"score":0.0,"value":"Data \u003d namedtuple(\"Data\", next(reader))"},{"id":0,"score":0.0,"value":"next(reader)"},{"id":0,"score":0.0,"value":"import csv\nfrom collections import namedtuple\nfrom itertools import imap\n\nwith open(\"data_file.txt\", mode\u003d\"rb\") as infile:\n    reader \u003d csv.reader(infile)\n    Data \u003d namedtuple(\"Data\", next(reader))  # get names from column headers\n    for data in imap(Data._make, reader):\n        print data.foo\n        # ...further processing of a line..."},{"id":0,"score":0.0,"value":"import csv\nfrom collections import namedtuple\n\nwith open(\"data_file.txt\", newline\u003d\"\") as infile:\n    reader \u003d csv.reader(infile)\n    Data \u003d namedtuple(\"Data\", next(reader))  # get names from column headers\n    for data in map(Data._make, reader):\n        print(data.foo)\n        # ...further processing of a line..."},{"id":0,"score":0.0,"value":"with open(\u0027some.csv\u0027, newline\u003d\u0027\u0027) as f:\n  csv_reader \u003d csv.reader(f)\n  csv_headings \u003d next(csv_reader)\n  first_line \u003d next(csv_reader)"}]},{"query":"read csv file","hypotheses":[{"id":0,"score":0.0,"value":"import csv\n\ndef getstuff(filename, criterion):\n    with open(filename, \"rb\") as csvfile:\n        datareader \u003d csv.reader(csvfile)\n        yield next(datareader)  # yield the header row\n        count \u003d 0\n        for row in datareader:\n            if row[3] \u003d\u003d criterion:\n                yield row\n                count +\u003d 1\n            elif count:\n                # done when having read a consecutive series of rows \n                return"},{"id":0,"score":0.0,"value":"import csv\nfrom itertools import dropwhile, takewhile\n\ndef getstuff(filename, criterion):\n    with open(filename, \"rb\") as csvfile:\n        datareader \u003d csv.reader(csvfile)\n        yield next(datareader)  # yield the header row\n        # first row, plus any subsequent rows that match, then stop\n        # reading altogether\n        # Python 2: use `for row in takewhile(...): yield row` instead\n        # instead of `yield from takewhile(...)`.\n        yield from takewhile(\n            lambda r: r[3] \u003d\u003d criterion,\n            dropwhile(lambda r: r[3] !\u003d criterion, datareader))\n        return"},{"id":0,"score":0.0,"value":"def getdata(filename, criteria):\n    for criterion in criteria:\n        for row in getstuff(filename, criterion):\n            yield row"},{"id":0,"score":0.0,"value":"for row in getdata(somefilename, sequence_of_criteria):\n    # process row"},{"id":0,"score":0.0,"value":"import csv\n\nwith open(\"test.csv\", \"r\") as f:\n    reader \u003d csv.reader(f, delimiter\u003d\"\\t\")\n    for i, line in enumerate(reader):\n        print \u0027line[{}] \u003d {}\u0027.format(i, line)"},{"id":0,"score":0.0,"value":"line[0] \u003d [\u0027Year:\u0027, \u0027Dec:\u0027, \u0027Jan:\u0027]\nline[1] \u003d [\u00271\u0027, \u002750\u0027, \u002760\u0027]\nline[2] \u003d [\u00272\u0027, \u002725\u0027, \u002750\u0027]\nline[3] \u003d [\u00273\u0027, \u002730\u0027, \u002730\u0027]\nline[4] \u003d [\u00274\u0027, \u002740\u0027, \u002720\u0027]\nline[5] \u003d [\u00275\u0027, \u002710\u0027, \u002710\u0027]"},{"id":0,"score":0.0,"value":"import pandas as pd\nimport zipfile\n\nzf \u003d zipfile.ZipFile(\u0027C:/Users/Desktop/THEZIPFILE.zip\u0027) \ndf \u003d pd.read_csv(zf.open(\u0027intfile.csv\u0027))"}]}],[{"query":"write csv `output_f` to file \"output/output.csv\"","hypotheses":[{"id":0,"score":0.0,"value":"import pandas as pd\nimport os\nimport sys\n\noutput \u003d pd.DataFrame(columns\u003d[\u0027col1\u0027, \u0027col2\u0027])\n\nfor root, dirs, files in os.walk(\"sourcefolder\", topdown\u003dFalse):\n\n    for name in files:\n\n        data \u003d pd.read_csv(os.path.join(root, name), usecols\u003d[1], skiprows\u003d1)\n        output \u003d output.append(data)\n\noutput_df.to_csv(\"output.csv\", index\u003dFalse, encoding\u003d\u0027utf8\u0027)"},{"id":0,"score":0.0,"value":"import pandas as pd\nimport os\nimport sys\n\noutput \u003d pd.DataFrame(columns\u003d[\u0027col1\u0027, \u0027col2\u0027])\n\nfor root, dirs, files in os.walk(\"sourcefolder\", topdown\u003dFalse):\n\n    for name in files:\n\n        data \u003d pd.read_csv(os.path.join(root, name), usecols\u003d[1], skiprows\u003d1)\n        output \u003d pd.concat([output, data], columns\u003doutput.columns)\n\noutput_df.to_csv(\"output.csv\", index\u003dFalse, encoding\u003d\u0027utf8\u0027)"},{"id":0,"score":0.0,"value":"import csv\n\n# ...\n\ndef event_handler_quote_update(message):\n    # print(f\"quote update {message}\")\n    token \u003d message[\u0027token\u0027]\n    ltp   \u003d message[\u0027ltp\u0027]\n    date  \u003d message[\u0027exchange_time_stamp\u0027]\n    with open(\u0027results.csv\u0027, \u0027a+\u0027) as csvfile:\n        writer \u003d csv.writer(csvfile)\n        writer.writerow([token, ltp, date])"},{"id":0,"score":0.0,"value":"import csv\n\n# ...\n\ndef event_handler_quote_update(message, writer):\n    # print(f\"quote update {message}\")\n    token \u003d message[\u0027token\u0027]\n    ltp   \u003d message[\u0027ltp\u0027]\n    date  \u003d message[\u0027exchange_time_stamp\u0027]\n    writer.writerow([token, ltp, date])\n\n# ...\n\nif __name__ \u003d\u003d \u0027__main__\u0027:\n    # whatever else you have here\n    csvfile \u003d open(\u0027results.csv\u0027, \u0027w\u0027)\n    writer \u003d csv.writer(csvfile)\n\n    # ... whatever else your program needs to do\n\n    csvfile.close()"},{"id":0,"score":0.0,"value":"writer.writerow([message[x] for x in (\u0027token\u0027, \u0027ltp\u0027, \u0027exchange_time_stamp\u0027)])"},{"id":0,"score":0.0,"value":"from contextlib import ExitStack\nfrom csv import writer\n\ndef calc(line):\n    # Ingest a line, do some calculations on it.\n    # This is the function you wrote.\n\ninput_files \u003d [\u0027file1.txt\u0027, \u0027file2.txt\u0027, ...]\n\ndef calculator(file):\n    \"\"\"\n    A generator function that will lazily apply the calculation\n    to each line of the file it is initialized with.\n    \"\"\"\n    for line in file:\n        yield calc(line)\n\nwith open(\u0027output.csv\u0027, \u0027w\u0027) as output, ExitStack() as input_stack:\n    inputs \u003d [calculator(input_stack.enter_context(open(file))) for file in input_files]\n    output_csv \u003d writer(output)\n    output_csv.wite_row(input_files)  # Write heading based on input files\n    for row in zip(*inputs):\n        output_csv.write_row(row)"},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e this_morning \u003d datetime.datetime(2009, 12, 2, 9, 30)\n\u003e\u003e\u003e last_night \u003d datetime.datetime(2009, 12, 1, 20, 0)\n\u003e\u003e\u003e this_morning.time() \u003c last_night.time()"}]},{"query":"write csv to file filename","hypotheses":[{"id":0,"score":0.0,"value":"import os, csv\n\nf\u003dopen(\"C:/Users/Amber/weights.csv\",\u0027r+\u0027)\nw\u003dcsv.writer(f)\nfor path, dirs, files in os.walk(\"C:/Users/Amber/Creator\"):\n    for filename in files:\n        w.writerow([filename])"},{"id":0,"score":0.0,"value":"import os, csv\n\nwith open(\"C:/Users/Amber/weights.csv\", \u0027w\u0027) as f:\n    writer \u003d csv.writer(f)\n    for path, dirs, files in os.walk(\"C:/Users/Amber/Creator\"):\n        for filename in files:\n            writer.writerow([filename])"},{"id":0,"score":0.0,"value":"df1 \u003d pandas.DataFrame(numpy.random.randn(3, 4), columns\u003d[[\"day\", \"number\", \"id\", \"recordDay\"]])\ndf2 \u003d pandas.DataFrame(numpy.random.randn(3, 4), columns\u003d[[\"day\", \"number\", \"id\", \"recordDay\"]])\ndf3 \u003d pandas.DataFrame(numpy.random.randn(3, 4), columns\u003d[[\"day\", \"number\", \"id\", \"recordDay\"]])\n\ndf_dict\u003d{\"data_frame1\":df1, \"data_frame2\": df2, \"data_frame3\": df3}\n\nfor name, df in df_dict.items():\n    #get the id and recordDay values from each df\n    df_id\u003ddf[\u0027id\u0027].iloc[0]\n    df_record_day\u003ddf[\u0027recordDay\u0027].iloc[0]\n\n    #generate a unique file name based on the id and record\n    file_name\u003d\"id_\"+str(df_id)+\"_\"+str(df_record_day)+\".csv\"\n\n    #create the CSV\n    df.to_csv(file_name, index \u003d False, data_format \u003d \u0027%Y-%m-%d\u0027)"},{"id":0,"score":0.0,"value":"df_list\u003d[df1, df2, df3]\n\nfor df in df_list:\n    #get the id and recordDay values from each df\n    df_id\u003ddf[\u0027id\u0027].iloc[0]\n    df_record_day\u003ddf[\u0027recordDay\u0027].iloc[0]\n\n    #generate a unique file name based on the id and record\n    file_name\u003d\"id_\"+str(df_id)+\"_\"+str(df_record_day)+\".csv\"\n\n    #create the CSV\n    df.to_csv(file_name, index \u003d False, data_format \u003d \u0027%Y-%m-%d\u0027)"},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e import time\n\u003e\u003e\u003e fname \u003d lambda : \"mycsvfile{}.csv\".format(time.strftime(\"%Y%m%d-%H.%M.%S\"))\n\u003e\u003e\u003e \n\u003e\u003e\u003e fname()\n\u0027mycsvfile20171012-17.24.59.csv\u0027\n\n\u003e\u003e\u003e with open(fname()) as f:\n\u003e\u003e\u003e    pass"},{"id":0,"score":0.0,"value":"csv_file \u003d \u0027myfile_\u0027 + str(datetime.now().strftime(\u0027%Y_%m_%d_%H_%M_%S\u0027)) + \u0027.csv\u0027"},{"id":0,"score":0.0,"value":"from elasticsearch import Elasticsearch\nimport csv\n\nes \u003d Elasticsearch([\"9200\"])\n\n# Replace the following Query with your own Elastic Search Query\nres \u003d es.search(index\u003d\"search\", body\u003d\n                {\n                    \"_source\": [\"DTDT\", \"TRDT\", \"SPLE\", \"RPLE\"],\n                    \"query\": {\n                        \"bool\": {\n                            \"should\": [\n                                {\"wildcard\": {\"CN\": \"TEST1\"}}\n\n                            ]\n                        }\n                    }\n}, size\u003d10)\n\nfrom datetime import datetime\nimport os\n\nfile_path \u003d \u003cPASS YOUR FILE HERE\u003e\n\ncsv_file \u003d \u0027myfile_\u0027 + str(datetime.now().strftime(\u0027%Y_%m_%d_%H_%M_%S\u0027)) + \u0027.csv\u0027\n\ncsv_file_full \u003d os.path.join(file_path, os.sep, csv_file)\n\nheader_names \u003d { \u0027DTDT\u0027: \u0027DATE\u0027, \u0027TRDT\u0027: \u0027TIME\u0027, ...}\n\nwith open(csv_file_full, \u0027w\u0027) as f:  # Just use \u0027w\u0027 mode in 3.x\n    header_present  \u003d False\n    for doc in res[\u0027hits\u0027][\u0027hits\u0027]:\n        my_dict \u003d doc[\u0027_source\u0027]\n        if not header_present:\n            w \u003d csv.DictWriter(f, my_dict.keys())\n            w.writerow(header_names)  # will write DATE, TIME, ... in correct place\n            header_present \u003d True\n\n\n        w.writerow(my_dict)"}]}],[{"query":"if directory \"output\" exists","hypotheses":[{"id":0,"score":0.0,"value":"with open(filename, \u0027a+\u0027) as f:\n    f.write(...)"},{"id":0,"score":0.0,"value":"import os\nplayer \u003d \u0027bob\u0027\n\nfilename \u003d player+\u0027.txt\u0027\n\nif os.path.exists(filename):\n    append_write \u003d \u0027a\u0027 # append if already exists\nelse:\n    append_write \u003d \u0027w\u0027 # make a new file if not\n\nhighscore \u003d open(filename,append_write)\nhighscore.write(\"Username: \" + player + \u0027\\n\u0027)\nhighscore.close()"},{"id":0,"score":0.0,"value":"import os, os.path\nimport errno\n\n# Taken from https://stackoverflow.com/a/600612/119527\ndef mkdir_p(path):\n    try:\n        os.makedirs(path)\n    except OSError as exc: # Python \u003e2.5\n        if exc.errno \u003d\u003d errno.EEXIST and os.path.isdir(path):\n            pass\n        else: raise\n\ndef safe_open_w(path):\n    \u0027\u0027\u0027 Open \"path\" for writing, creating any parent directories as needed.\n    \u0027\u0027\u0027\n    mkdir_p(os.path.dirname(path))\n    return open(path, \u0027w\u0027)\n\nwith safe_open_w(\u0027/Users/bill/output/output-text.txt\u0027) as f:\n    f.write(...)"},{"id":0,"score":0.0,"value":"for fname in os.listdir(\u0027.\u0027):\n    if fname.endswith(\u0027.true\u0027):\n        # do stuff on the file\n        break\nelse:\n    # do stuff if a file .true doesn\u0027t exist."},{"id":0,"score":0.0,"value":"if not any(fname.endswith(\u0027.true\u0027) for fname in os.listdir(\u0027.\u0027)):\n    # do stuff if a file .true doesn\u0027t exist"},{"id":0,"score":0.0,"value":"import glob\n# stuff\nif not glob.glob(\u0027*.true\u0027)`:\n    # do stuff if no file ending in .true exists"},{"id":0,"score":0.0,"value":"with open(filename, \u0027a\u0027) as f:\n    f.write(...)"}]},{"query":"if directory exists","hypotheses":[{"id":0,"score":0.0,"value":"\u003e\u003e\u003e import os\n\u003e\u003e\u003e os.path.isdir(\u0027new_folder\u0027)\nTrue\n\u003e\u003e\u003e os.path.exists(os.path.join(os.getcwd(), \u0027new_folder\u0027, \u0027file.txt\u0027))\nFalse"},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e from pathlib import Path\n \u003e\u003e\u003e Path(\u0027new_folder\u0027).is_dir()\n True\n \u003e\u003e\u003e (Path.cwd() / \u0027new_folder\u0027 / \u0027file.txt\u0027).exists()\n False"},{"id":0,"score":0.0,"value":"In [1]: from pathlib import Path\n\nIn [2]: p \u003d Path(\u0027/usr\u0027)\n\nIn [3]: p.exists()\nOut[3]: True\n\nIn [4]: p.is_dir()\nOut[4]: True"},{"id":0,"score":0.0,"value":"In [5]: q \u003d p / \u0027bin\u0027 / \u0027vim\u0027\n\nIn [6]: q\nOut[6]: PosixPath(\u0027/usr/bin/vim\u0027) \n\nIn [7]: q.exists()\nOut[7]: True\n\nIn [8]: q.is_dir()\nOut[8]: False"},{"id":0,"score":0.0,"value":"import os\nimport shutil\n\ndirpath \u003d os.path.join(\u0027dataset3\u0027, \u0027dataset\u0027)\nif os.path.exists(dirpath) and os.path.isdir(dirpath):\n    shutil.rmtree(dirpath)"},{"id":0,"score":0.0,"value":"from pathlib import Path\nimport shutil\n\ndirpath \u003d Path(\u0027dataset3\u0027) / \u0027dataset\u0027\nif dirpath.exists() and dirpath.is_dir():\n    shutil.rmtree(dirpath)"},{"id":0,"score":0.0,"value":"os.path.isdir(\"directory\")"}]}],[{"query":"check if file `output_file` exists","hypotheses":[{"id":0,"score":0.0,"value":"import os.path\nos.path.isfile(fname)"},{"id":0,"score":0.0,"value":"from pathlib import Path\n\nmy_file \u003d Path(\"/path/to/file\")\nif my_file.is_file():\n    # file exists"},{"id":0,"score":0.0,"value":"if my_file.is_dir():\n    # directory exists"},{"id":0,"score":0.0,"value":"if my_file.exists():\n    # path exists"},{"id":0,"score":0.0,"value":"try:\n    my_abs_path \u003d my_file.resolve(strict\u003dTrue)\nexcept FileNotFoundError:\n    # doesn\u0027t exist\nelse:\n    # exists"},{"id":0,"score":0.0,"value":"import os.path\nos.path.exists(file_path)"},{"id":0,"score":0.0,"value":"os.path.isfile(file_path)"}]},{"query":"check if file exists","hypotheses":[{"id":0,"score":0.0,"value":"import os.path\nos.path.isfile(fname)"},{"id":0,"score":0.0,"value":"from pathlib import Path\n\nmy_file \u003d Path(\"/path/to/file\")\nif my_file.is_file():\n    # file exists"},{"id":0,"score":0.0,"value":"if my_file.is_dir():\n    # directory exists"},{"id":0,"score":0.0,"value":"if my_file.exists():\n    # path exists"},{"id":0,"score":0.0,"value":"try:\n    my_abs_path \u003d my_file.resolve(strict\u003dTrue)\nexcept FileNotFoundError:\n    # doesn\u0027t exist\nelse:\n    # exists"},{"id":0,"score":0.0,"value":"import os.path\nos.path.exists(file_path)"},{"id":0,"score":0.0,"value":"os.path.isfile(file_path)"}]}],[{"query":"GET request to \"https://jsonplaceholder.typicode.com/posts\" with argument userId","hypotheses":[{"id":0,"score":0.0,"value":"import getpass\ngetpass.getuser()\n\u0027kostya\u0027"},{"id":0,"score":0.0,"value":"\u003cinput type\u003d\"text\" name\u003d\"username\"\u003e"},{"id":0,"score":0.0,"value":"import cgi\nform \u003d cgi.FieldStorage()\nprint form[\"username\"]"},{"id":0,"score":0.0,"value":"print request.GET[\u0027username\u0027] # for GET form method\nprint request.POST[\u0027username\u0027] # for POST form method"},{"id":0,"score":0.0,"value":"from cherrypy import request\nprint request.params[\u0027username\u0027]"},{"id":0,"score":0.0,"value":"form \u003d web.input()\nprint form.username"},{"id":0,"score":0.0,"value":"print request.form[\u0027username\u0027]"}]},{"query":"GET request to url with argument","hypotheses":[{"id":0,"score":0.0,"value":"import urlparse\nurl \u003d \u0027http://foo.appspot.com/abc?def\u003dghi\u0027\nparsed \u003d urlparse.urlparse(url)\nprint urlparse.parse_qs(parsed.query)[\u0027def\u0027]"},{"id":0,"score":0.0,"value":"import urllib.parse as urlparse\nfrom urllib.parse import parse_qs\nurl \u003d \u0027http://foo.appspot.com/abc?def\u003dghi\u0027\nparsed \u003d urlparse.urlparse(url)\nprint(parse_qs(parsed.query)[\u0027def\u0027])"},{"id":0,"score":0.0,"value":"request.GET.get(\u0027variable_name\u0027)"},{"id":0,"score":0.0,"value":"import urlparse\nurl \u003d \u0027http://example.com/?q\u003dabc\u0026p\u003d123\u0027\npar \u003d urlparse.parse_qs(urlparse.urlparse(url).query)\n\nprint par[\u0027q\u0027][0], par[\u0027p\u0027][0]"},{"id":0,"score":0.0,"value":"try:\n    # Python 3\n    from urllib.parse import urlparse, parse_qs\nexcept ImportError:\n    # Python 2\n    from urlparse import urlparse, parse_qs\n\no \u003d urlparse(url)\nquery \u003d parse_qs(o.query)\n# extract the URL without query parameters\nurl \u003d o._replace(query\u003dNone).geturl()\n\nif \u0027token\u0027 in query:\n    query[\u0027token\u0027] \u003d \u0027NEW_TOKEN\u0027\n\nrequests.get(url, params\u003dquery)"},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e from urllib.parse import urlparse, parse_qs\n\u003e\u003e\u003e url \u003d \"http://httpbin.org/get?token\u003dTOKEN_TO_REPLACE\u0026param2\u003dc\"\n\u003e\u003e\u003e o \u003d urlparse(url)\n\u003e\u003e\u003e query \u003d parse_qs(o.query)\n\u003e\u003e\u003e url \u003d o._replace(query\u003dNone).geturl()\n\u003e\u003e\u003e if \u0027token\u0027 in query:\n...     query[\u0027token\u0027] \u003d \u0027NEW_TOKEN\u0027\n... \n\u003e\u003e\u003e response \u003d requests.get(url, params\u003dquery)\n\u003e\u003e\u003e print(response.text)\n{\n  \"args\": {\n    \"param2\": \"c\", \n    \"token\": \"NEW_TOKEN\"\n  }, \n  \"headers\": {\n    \"Accept\": \"*/*\", \n    \"Accept-Encoding\": \"gzip, deflate\", \n    \"Host\": \"httpbin.org\", \n    \"User-Agent\": \"python-requests/2.5.1 CPython/3.4.2 Darwin/14.1.0\"\n  }, \n  \"origin\": \"188.29.165.245\", \n  \"url\": \"http://httpbin.org/get?token\u003dNEW_TOKEN\u0026param2\u003dc\"\n}"},{"id":0,"score":0.0,"value":"from urllib import parse\nurl \u003d \u0027http://foo.appspot.com/abc?def\u003dghi\u0027\nquery_def\u003dparse.parse_qs(parse.urlparse(url).query)[\u0027def\u0027][0]"}]}],[{"query":"change directory to \"data\"","hypotheses":[{"id":0,"score":0.0,"value":"# some_file.py\nimport sys\n# insert at 1, 0 is the script path (or \u0027\u0027 in REPL)\nsys.path.insert(1, \u0027/path/to/application/app/folder\u0027)\n\nimport file"},{"id":0,"score":0.0,"value":"from application.app.folder.file import func_name"},{"id":0,"score":0.0,"value":"import os\nos.chdir(\"/home/udi/foo\")"},{"id":0,"score":0.0,"value":"import os\n\nabspath \u003d os.path.abspath(__file__)\ndname \u003d os.path.dirname(abspath)\nos.chdir(dname)"},{"id":0,"score":0.0,"value":"application/app2/some_folder/some_file.py\napplication/app2/another_folder/another_file.py"},{"id":0,"score":0.0,"value":"import sys\nsys.path.append(\u0027../\u0027)"},{"id":0,"score":0.0,"value":"project/\n    foo/\n        __init__.py\n        data/\n            resource1/\n                foo.txt"}]},{"query":"change directory to another","hypotheses":[{"id":0,"score":0.0,"value":"import os\n\nos.chdir(path)"},{"id":0,"score":0.0,"value":"pip install --target\u003dd:\\somewhere\\other\\than\\the\\default package_name"},{"id":0,"score":0.0,"value":"pip install -U pip"},{"id":0,"score":0.0,"value":"python -m pip install -U pip"},{"id":0,"score":0.0,"value":"pip install --install-option\u003d\"--prefix\u003d$PREFIX_PATH\" package_name"},{"id":0,"score":0.0,"value":"import os\n\nclass cd:\n    \"\"\"Context manager for changing the current working directory\"\"\"\n    def __init__(self, newPath):\n        self.newPath \u003d os.path.expanduser(newPath)\n\n    def __enter__(self):\n        self.savedPath \u003d os.getcwd()\n        os.chdir(self.newPath)\n\n    def __exit__(self, etype, value, traceback):\n        os.chdir(self.savedPath)"},{"id":0,"score":0.0,"value":"import subprocess # just to call an arbitrary command e.g. \u0027ls\u0027\n\n# enter the directory like this:\nwith cd(\"~/Library\"):\n   # we are in ~/Library\n   subprocess.call(\"ls\")\n\n# outside the context manager we are back wherever we started."}]}],[{"query":"pair characters in `characters` and numbers in `numbers`","hypotheses":[{"id":0,"score":0.0,"value":"print [ord(char) - 96 for char in raw_input(\u0027Write Text: \u0027).lower()]"},{"id":0,"score":0.0,"value":"input \u003d raw_input(\u0027Write Text: \u0027)\ninput \u003d input.lower()\noutput \u003d []\nfor character in input:\n    number \u003d ord(character) - 96\n    output.append(number)\nprint output"},{"id":0,"score":0.0,"value":"chr(ord(\u0027x\u0027)) \u003d\u003d \u0027x\u0027 # for any character, not just x."},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e chr(97)\n\u0027a\u0027\n\u003e\u003e\u003e ord(\u0027a\u0027)\n97"},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e char1 \u003d [\u0027a\u0027\u0027b\u0027\u0027c\u0027\u0027d\u0027\u0027e\u0027\u0027f\u0027\u0027g\u0027\u0027h\u0027\u0027i\u0027\u0027j\u0027\u0027k\u0027\u0027l\u0027\n             \u0027m\u0027\u0027n\u0027\u0027o\u0027\u0027p\u0027\u0027q\u0027\u0027r\u0027\u0027s\u0027\u0027t\u0027\u0027u\u0027\u0027v\u0027\u0027w\u0027\u0027x\u0027\u0027y\u0027\u0027z\u0027]"},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e char2 \u003d [\u0027a\u0027,\u0027b\u0027,\u0027c\u0027,\u0027d\u0027,\u0027e\u0027,\u0027f\u0027,\u0027g\u0027,\u0027h\u0027,\u0027i\u0027,\u0027j\u0027,\u0027k\u0027,\u0027l\u0027,\n               \u0027m\u0027,\u0027n\u0027,\u0027o\u0027,\u0027p\u0027,\u0027q\u0027,\u0027r\u0027,\u0027s\u0027,\u0027t\u0027,\u0027u\u0027,\u0027v\u0027,\u0027w\u0027,\u0027x\u0027,\u0027y\u0027,\u0027z\u0027]"},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e print char1, len(char1), len(char1[0])\n[\u0027abcdefghijklmnopqrstuvwxyz\u0027] 1 26\n\u003e\u003e\u003e print char2, len(char2), len(char2[0])\n[\u0027a\u0027, \u0027b\u0027, \u0027c\u0027, \u0027d\u0027, \u0027e\u0027, \u0027f\u0027, \u0027g\u0027, \u0027h\u0027, \u0027i\u0027, \u0027j\u0027, \u0027k\u0027, \u0027l\u0027, \n\u0027m\u0027, \u0027n\u0027, \u0027o\u0027, \u0027p\u0027, \u0027q\u0027,\u0027r\u0027, \u0027s\u0027, \u0027t\u0027, \u0027u\u0027, \u0027v\u0027, \u0027w\u0027, \u0027x\u0027, \u0027y\u0027, \u0027z\u0027] 26 1"}]},{"query":"pair characters in list and numbers in list","hypotheses":[{"id":0,"score":0.0,"value":"matt@stanley:~$ python\nPython 2.6.5 (r265:79063, Apr 16 2010, 13:57:41) \n[GCC 4.4.3] on linux2\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n\u003e\u003e\u003e import itertools\n\u003e\u003e\u003e list(itertools.combinations(range(6), 2))\n[(0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (1, 2), (1, 3), (1, 4), (1, 5), (2, 3), (2, 4), (2, 5), (3, 4), (3, 5), (4, 5)]"},{"id":0,"score":0.0,"value":"from itertools import izip\n\ndef pairwise(t):\n    it \u003d iter(t)\n    return izip(it,it)\n\n# for \"pairs\" of any length\ndef chunkwise(t, size\u003d2):\n    it \u003d iter(t)\n    return izip(*[it]*size)"},{"id":0,"score":0.0,"value":"from itertools import izip_longest\ndef blockwise(t, size\u003d2, fillvalue\u003dNone):\n    it \u003d iter(t)\n    return izip_longest(*[it]*size, fillvalue\u003dfillvalue)"},{"id":0,"score":0.0,"value":"import itertools\ndef all_pairs(lst):\n    for p in itertools.permutations(lst):\n        i \u003d iter(p)\n        yield zip(i,i)"},{"id":0,"score":0.0,"value":"def all_pairs(lst):\n    if len(lst) \u003c 2:\n        yield []\n        return\n    if len(lst) % 2 \u003d\u003d 1:\n        # Handle odd length list\n        for i in range(len(lst)):\n            for result in all_pairs(lst[:i] + lst[i+1:]):\n                yield result\n    else:\n        a \u003d lst[0]\n        for i in range(1,len(lst)):\n            pair \u003d (a,lst[i])\n            for rest in all_pairs(lst[1:i]+lst[i+1:]):\n                yield [pair] + rest"},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e t \u003d [1,2,3,4,5]\n\u003e\u003e\u003e t.append(None)\n\u003e\u003e\u003e zip(t[::2], t[1::2])\n[(1, 2), (3, 4), (5, None)]\n\u003e\u003e\u003e t \u003d [1,2,3,4,5,6]\n\u003e\u003e\u003e t.append(None)\n\u003e\u003e\u003e zip(t[::2], t[1::2])\n[(1, 2), (3, 4), (5, 6)]"},{"id":0,"score":0.0,"value":"items \u003d [\"me\", \"you\", \"him\"]\n[(items[i],items[j]) for i in range(len(items)) for j in range(i+1, len(items))]\n\n[(\u0027me\u0027, \u0027you\u0027), (\u0027me\u0027, \u0027him\u0027), (\u0027you\u0027, \u0027him\u0027)]"}]}],[{"query":"copy files and directories under `data` directory","hypotheses":[{"id":0,"score":0.0,"value":"from distutils.dir_util import copy_tree\n\n# copy subdirectory example\nfromDirectory \u003d \"/a/b/c\"\ntoDirectory \u003d \"/x/y/z\"\n\ncopy_tree(fromDirectory, toDirectory)"},{"id":0,"score":0.0,"value":"import shutil, errno\n\ndef copyanything(src, dst):\n    try:\n        shutil.copytree(src, dst)\n    except OSError as exc: # python \u003e2.5\n        if exc.errno \u003d\u003d errno.ENOTDIR:\n            shutil.copy(src, dst)\n        else: raise"},{"id":0,"score":0.0,"value":"import os\nimport shutil\nsrc_files \u003d os.listdir(src)\nfor file_name in src_files:\n    full_file_name \u003d os.path.join(src, file_name)\n    if os.path.isfile(full_file_name):\n        shutil.copy(full_file_name, dest)"},{"id":0,"score":0.0,"value":"import os\nimport shutil\n\nsrcfile \u003d \u0027a/long/long/path/to/file.py\u0027\ndstroot \u003d \u0027/home/myhome/new_folder\u0027\n\n\nassert not os.path.isabs(srcfile)\ndstdir \u003d  os.path.join(dstroot, os.path.dirname(srcfile))\n\nos.makedirs(dstdir) # create all directories, raise an error if it already exists\nshutil.copy(srcfile, dstdir)"},{"id":0,"score":0.0,"value":"import shutil\nimport os\n\ndef copy_and_overwrite(from_path, to_path):\n    if os.path.exists(to_path):\n        shutil.rmtree(to_path)\n    shutil.copytree(from_path, to_path)"},{"id":0,"score":0.0,"value":"import os\nfrom shutil import *\ndef copytree(src, dst, symlinks\u003dFalse, ignore\u003dNone):\n    names \u003d os.listdir(src)\n    if ignore is not None:\n        ignored_names \u003d ignore(src, names)\n    else:\n        ignored_names \u003d set()\n\n    if not os.path.isdir(dst): # This one line does the trick\n        os.makedirs(dst)\n    errors \u003d []\n    for name in names:\n        if name in ignored_names:\n            continue\n        srcname \u003d os.path.join(src, name)\n        dstname \u003d os.path.join(dst, name)\n        try:\n            if symlinks and os.path.islink(srcname):\n                linkto \u003d os.readlink(srcname)\n                os.symlink(linkto, dstname)\n            elif os.path.isdir(srcname):\n                copytree(srcname, dstname, symlinks, ignore)\n            else:\n                # Will raise a SpecialFileError for unsupported file types\n                copy2(srcname, dstname)\n        # catch the Error from the recursive copytree so that we can\n        # continue with other files\n        except Error, err:\n            errors.extend(err.args[0])\n        except EnvironmentError, why:\n            errors.append((srcname, dstname, str(why)))\n    try:\n        copystat(src, dst)\n    except OSError, why:\n        if WindowsError is not None and isinstance(why, WindowsError):\n            # Copying file access times may fail on Windows\n            pass\n        else:\n            errors.extend((src, dst, str(why)))\n    if errors:\n        raise Error, errors"},{"id":0,"score":0.0,"value":"for filename in glob.glob(os.path.join(source_dir, \u0027*.*\u0027)):\n    shutil.copy(filename, dest_dir)"}]},{"query":"copy files and directories under given directory","hypotheses":[{"id":0,"score":0.0,"value":"from distutils.dir_util import copy_tree\ncopy_tree(\"/a/b/c\", \"/x/y/z\")"},{"id":0,"score":0.0,"value":"import os, shutil\ndef copytree(src, dst, symlinks\u003dFalse, ignore\u003dNone):\n    for item in os.listdir(src):\n        s \u003d os.path.join(src, item)\n        d \u003d os.path.join(dst, item)\n        if os.path.isdir(s):\n            shutil.copytree(s, d, symlinks, ignore)\n        else:\n            shutil.copy2(s, d)"},{"id":0,"score":0.0,"value":"from distutils.dir_util import copy_tree\n\n# copy subdirectory example\nfromDirectory \u003d \"/a/b/c\"\ntoDirectory \u003d \"/x/y/z\"\n\ncopy_tree(fromDirectory, toDirectory)"},{"id":0,"score":0.0,"value":"import shutil, errno\n\ndef copyanything(src, dst):\n    try:\n        shutil.copytree(src, dst)\n    except OSError as exc: # python \u003e2.5\n        if exc.errno \u003d\u003d errno.ENOTDIR:\n            shutil.copy(src, dst)\n        else: raise"},{"id":0,"score":0.0,"value":"import os\nimport shutil\nsrc_files \u003d os.listdir(src)\nfor file_name in src_files:\n    full_file_name \u003d os.path.join(src, file_name)\n    if os.path.isfile(full_file_name):\n        shutil.copy(full_file_name, dest)"},{"id":0,"score":0.0,"value":"def copytree(src, dst, symlinks\u003dFalse, ignore\u003dNone):\n    if not os.path.exists(dst):\n        os.makedirs(dst)\n    for item in os.listdir(src):\n        s \u003d os.path.join(src, item)\n        d \u003d os.path.join(dst, item)\n        if os.path.isdir(s):\n            copytree(s, d, symlinks, ignore)\n        else:\n            if not os.path.exists(d) or os.stat(s).st_mtime - os.stat(d).st_mtime \u003e 1:\n                shutil.copy2(s, d)"},{"id":0,"score":0.0,"value":"import shutil\n\nshutil.copytree(\u0027bar\u0027, \u0027foo\u0027)\nshutil.copytree(\u0027baz\u0027, \u0027foo\u0027, dirs_exist_ok\u003dTrue)"}]}],[{"query":"create list \"a_list\"","hypotheses":[{"id":0,"score":0.0,"value":"def doAppend( size\u003d10000 ):\n    result \u003d []\n    for i in range(size):\n        message\u003d \"some unique object %d\" % ( i, )\n        result.append(message)\n    return result\n\ndef doAllocate( size\u003d10000 ):\n    result\u003dsize*[None]\n    for i in range(size):\n        message\u003d \"some unique object %d\" % ( i, )\n        result[i]\u003d message\n    return result"},{"id":0,"score":0.0,"value":"simple append 0.0102\npre-allocate  0.0098"},{"id":0,"score":0.0,"value":"l \u003d [None] * 1000 # Make a list of 1000 None\u0027s\nfor i in xrange(1000):\n    # baz\n    l[i] \u003d bar\n    # qux"},{"id":0,"score":0.0,"value":"def my_things():\n    while foo:\n        #baz\n        yield bar\n        #qux\n\nfor thing in my_things():\n    # do something with thing"},{"id":0,"score":0.0,"value":"pre_allocated_list \u003d [None] * size"},{"id":0,"score":0.0,"value":"import time\nimport copy\n\ndef print_timing (func):\n  def wrapper (*arg):\n    t1 \u003d time.time()\n    res \u003d func (*arg)\n    t2 \u003d time.time ()\n    print (\"{} took {} ms\".format (func.__name__, (t2 - t1) * 1000.0))\n    return res\n\n  return wrapper\n\n@print_timing\ndef prealloc_array (size, init \u003d None, cp \u003d True, cpmethod \u003d copy.deepcopy, cpargs \u003d (), use_num \u003d False):\n  result \u003d [None] * size\n  if init is not None:\n    if cp:\n      for i in range (size):\n          result[i] \u003d init\n    else:\n      if use_num:\n        for i in range (size):\n            result[i] \u003d cpmethod (i)\n      else:\n        for i in range (size):\n            result[i] \u003d cpmethod (cpargs)\n  return result\n\n@print_timing\ndef prealloc_array_by_appending (size):\n  result \u003d []\n  for i in range (size):\n    result.append (None)\n  return result\n\n@print_timing\ndef prealloc_array_by_extending (size):\n  result \u003d []\n  none_list \u003d [None]\n  for i in range (size):\n    result.extend (none_list)\n  return result\n\ndef main ():\n  n \u003d 1000000\n  x \u003d prealloc_array_by_appending(n)\n  y \u003d prealloc_array_by_extending(n)\n  a \u003d prealloc_array(n, None)\n  b \u003d prealloc_array(n, \"content\", True)\n  c \u003d prealloc_array(n, \"content\", False, \"some object {}\".format, (\"blah\"), False)\n  d \u003d prealloc_array(n, \"content\", False, \"some object {}\".format, None, True)\n  e \u003d prealloc_array(n, \"content\", False, copy.deepcopy, \"a\", False)\n  f \u003d prealloc_array(n, \"content\", False, copy.deepcopy, (), False)\n  g \u003d prealloc_array(n, \"content\", False, copy.deepcopy, [], False)\n\n  print (\"x[5] \u003d {}\".format (x[5]))\n  print (\"y[5] \u003d {}\".format (y[5]))\n  print (\"a[5] \u003d {}\".format (a[5]))\n  print (\"b[5] \u003d {}\".format (b[5]))\n  print (\"c[5] \u003d {}\".format (c[5]))\n  print (\"d[5] \u003d {}\".format (d[5]))\n  print (\"e[5] \u003d {}\".format (e[5]))\n  print (\"f[5] \u003d {}\".format (f[5]))\n  print (\"g[5] \u003d {}\".format (g[5]))\n\nif __name__ \u003d\u003d \u0027__main__\u0027:\n  main()"},{"id":0,"score":0.0,"value":"prealloc_array_by_appending took 118.00003051757812 ms\nprealloc_array_by_extending took 102.99992561340332 ms\nprealloc_array took 3.000020980834961 ms\nprealloc_array took 49.00002479553223 ms\nprealloc_array took 316.9999122619629 ms\nprealloc_array took 473.00004959106445 ms\nprealloc_array took 1677.9999732971191 ms\nprealloc_array took 2729.999780654907 ms\nprealloc_array took 3001.999855041504 ms\nx[5] \u003d None\ny[5] \u003d None\na[5] \u003d None\nb[5] \u003d content\nc[5] \u003d some object blah\nd[5] \u003d some object 5\ne[5] \u003d a\nf[5] \u003d []\ng[5] \u003d ()"}]},{"query":"create list","hypotheses":[{"id":0,"score":0.0,"value":"d \u003d [[] for x in xrange(n)]"},{"id":0,"score":0.0,"value":"from itertools import repeat\nd \u003d [[] for i in repeat(None, n)]"},{"id":0,"score":0.0,"value":"d \u003d numpy.empty((n, 0)).tolist()"},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e from timeit import timeit\n\u003e\u003e\u003e\n\u003e\u003e\u003e # Test 1\n\u003e\u003e\u003e test \u003d \"\"\"\n... my_list \u003d []\n... for i in xrange(50):\n...     my_list.append(0)\n... \"\"\"\n\u003e\u003e\u003e timeit(test)\n22.384258893239178\n\u003e\u003e\u003e\n\u003e\u003e\u003e # Test 2\n\u003e\u003e\u003e test \u003d \"\"\"\n... my_list \u003d []\n... for i in xrange(50):\n...     my_list +\u003d [0]\n... \"\"\"\n\u003e\u003e\u003e timeit(test)\n34.494779364416445\n\u003e\u003e\u003e\n\u003e\u003e\u003e # Test 3\n\u003e\u003e\u003e test \u003d \"my_list \u003d [0 for i in xrange(50)]\"\n\u003e\u003e\u003e timeit(test)\n9.490926919482774\n\u003e\u003e\u003e\n\u003e\u003e\u003e # Test 4\n\u003e\u003e\u003e test \u003d \"my_list \u003d [0] * 50\"\n\u003e\u003e\u003e timeit(test)\n1.5340533503559755\n\u003e\u003e\u003e"},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e lst \u003d [[]] * 3\n\u003e\u003e\u003e lst\n[[], [], []]\n\u003e\u003e\u003e # The ids of the items in `lst` are the same\n\u003e\u003e\u003e id(lst[0])\n28734408\n\u003e\u003e\u003e id(lst[1])\n28734408\n\u003e\u003e\u003e id(lst[2])\n28734408\n\u003e\u003e\u003e"},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e lst \u003d [[] for _ in xrange(3)]\n\u003e\u003e\u003e lst\n[[], [], []]\n\u003e\u003e\u003e # The ids of the items in `lst` are different\n\u003e\u003e\u003e id(lst[0])\n28796688\n\u003e\u003e\u003e id(lst[1])\n28796648\n\u003e\u003e\u003e id(lst[2])\n28736168\n\u003e\u003e\u003e"},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e l \u003d []\n\u003e\u003e\u003e l.append([1,2,3])\n\u003e\u003e\u003e l.append([4,5,6])\n\u003e\u003e\u003e l\n[[1, 2, 3], [4, 5, 6]]"}]}],[{"query":"copy column from \"data.csv\" file to another \"output.csv\"","hypotheses":[{"id":0,"score":0.0,"value":"import csv\nfrom itertools import izip\na \u003d izip(*csv.reader(open(\"input.csv\", \"rb\")))\ncsv.writer(open(\"output.csv\", \"wb\")).writerows(a)"},{"id":0,"score":0.0,"value":"a \u003d [(1, 2, 3),\n     (4, 5, 6),\n     (7, 8, 9)]\nzip(*a)\n# [(1, 4, 7),\n#  (2, 5, 8),\n#  (3, 6, 9)]"},{"id":0,"score":0.0,"value":"import pandas as pd\npd.read_csv(\u0027input.csv\u0027, header\u003dNone).T.to_csv(\u0027output.csv\u0027, header\u003dFalse, index\u003dFalse)"},{"id":0,"score":0.0,"value":"csvfile \u003d \u0027filename\u0027\nwith open(csvfile, \u0027r\u0027) as fin, open(\u0027new_\u0027+csvfile, \u0027w\u0027) as fout:\n    reader \u003d csv.reader(fin, newline\u003d\u0027\u0027, lineterminator\u003d\u0027\\n\u0027)\n    writer \u003d csv.writer(fout, newline\u003d\u0027\u0027, lineterminator\u003d\u0027\\n\u0027)\n    if you_have_headers:\n        writer.writerow(next(reader) + [new_heading])\n    for row, val in zip(reader, data)\n        writer.writerow(row + [data])"},{"id":0,"score":0.0,"value":"import os\nos.remove(csvfile) # not needed on unix\nos.rename(\u0027new_\u0027+csvfile, csvfile)"},{"id":0,"score":0.0,"value":"import csv\nreader \u003d csv.reader(open(\u0027output.csv\u0027, \u0027rb\u0027))\nreader1 \u003d csv.reader(open(\u0027output1.csv\u0027, \u0027rb\u0027))\nwriter \u003d csv.writer(open(\u0027appended_output.csv\u0027, \u0027wb\u0027))\nfor row in reader:\n    row1 \u003d reader1.next()\n    writer.writerow(row + row1)"},{"id":0,"score":0.0,"value":"from csv import reader, writer \nwith open(\u0027source.csv\u0027) as f, open(\u0027destination.csv\u0027, \u0027w\u0027) as fw: \n    writer(fw, delimiter\u003d\u0027,\u0027).writerows(zip(*reader(f, delimiter\u003d\u0027,\u0027)))"}]},{"query":"copy column from csv file to another csv file","hypotheses":[{"id":0,"score":0.0,"value":"with open(\u0027book1.csv\u0027, \u0027r\u0027) as book1:\n    with open(\u0027book2.csv\u0027, \u0027r\u0027) as book2:\n        reader1 \u003d csv.reader(book1, delimiter\u003d\u0027,\u0027)\n        reader2 \u003d csv.reader(book2, delimiter\u003d\u0027,\u0027)\n\n        both \u003d []\n        fields \u003d reader1.next() # read header row\n        reader2.next() # read and ignore header row\n        for row1, row2 in zip(reader1, reader2):\n            row2.append(row1[-1])\n            both.append(row2)\n\n        with open(\u0027output.csv\u0027, \u0027w\u0027) as output:\n            writer \u003d csv.writer(output, delimiter\u003d\u0027,\u0027)\n            writer.writerow(fields) # write a header row\n            writer.writerows(both)"},{"id":0,"score":0.0,"value":"# Load Pandas\nfrom pandas import DataFrame\n\n# Load each file into a pandas dataframe, this is based on a numpy array\ndata1 \u003d DataFrame.from_csv(\u0027csv1.csv\u0027,sep\u003d\u0027,\u0027,parse_dates\u003dFalse)\ndata2 \u003d DataFrame.from_csv(\u0027csv2.csv\u0027,sep\u003d\u0027,\u0027,parse_dates\u003dFalse)\n\n#Now add \u0027header5\u0027 from data1 to data2\ndata2[\u0027header5\u0027] \u003d data1[\u0027header5\u0027]\n\n#Save it back to csv\ndata2.to_csv(\u0027output.csv\u0027)"},{"id":0,"score":0.0,"value":"import csv\n# Open the two input files, which I\u0027ve renamed to be more descriptive,\n# and also an output file that we\u0027ll be creating\nwith open(\"four_col.csv\", mode\u003d\u0027r\u0027) as four_col, \\\n     open(\"five_col.csv\", mode\u003d\u0027r\u0027) as five_col, \\\n     open(\"five_output.csv\", mode\u003d\u0027w\u0027, newline\u003d\u0027\u0027) as outfile:\n  four_reader \u003d csv.reader(four_col)\n  five_reader \u003d csv.reader(five_col)\n  five_writer \u003d csv.writer(outfile)\n  _ \u003d next(four_reader) # Ignore headers for the 4-column file\n  headers \u003d next(five_reader)\n  five_writer.writerow(headers)\n  for four_row, five_row in zip(four_reader, five_reader):\n    last_col \u003d five_row[-1] # # Or use five_row[4]\n    four_row.append(last_col)\n    five_writer.writerow(four_row)"},{"id":0,"score":0.0,"value":"writer.writerow([row[1]])"},{"id":0,"score":0.0,"value":"$\u003e cat 1.csv \na b c d f\n1  3  5\n e  t\n5  4  6"},{"id":0,"score":0.0,"value":"import csv\npath1\u003d\u00271.csv\u0027\npath2\u003d\u00272.csv\u0027\noutdata \u003d []\ninput_file \u003d open(path1,\u0027rb\u0027)\noutput \u003d open (path2,\u0027wb\u0027)\n\nreader\u003dcsv.reader(input_file, delimiter\u003d\u0027 \u0027)\nwriter\u003dcsv.writer(output,delimiter\u003d\u0027 \u0027)\nfor row in reader:\n    print(\"row: \", row)\n    outdata.append([row[0], row[1]])\nprint(outdata)\nwriter.writerows(outdata)"},{"id":0,"score":0.0,"value":"$\u003e cat 2.csv\n(\u0027row: \u0027, [\u0027a\u0027, \u0027b\u0027, \u0027c\u0027, \u0027d\u0027, \u0027f\u0027])\n(\u0027row: \u0027, [\u00271\u0027, \u0027\u0027, \u00273\u0027, \u0027\u0027, \u00275\u0027])\n(\u0027row: \u0027, [\u0027\u0027, \u0027e\u0027, \u0027\u0027, \u0027t\u0027])\n(\u0027row: \u0027, [\u00275\u0027, \u0027\u0027, \u00274\u0027, \u0027\u0027, \u00276\u0027])\n[[\u0027a\u0027, \u0027b\u0027], [\u00271\u0027, \u0027\u0027], [\u0027\u0027, \u0027e\u0027], [\u00275\u0027, \u0027\u0027]]\na b\n1 \n e\n5"}]}],[{"query":"copy column from \"data.csv\" to \"output.csv\"","hypotheses":[{"id":0,"score":0.0,"value":"import csv\nfrom itertools import izip\na \u003d izip(*csv.reader(open(\"input.csv\", \"rb\")))\ncsv.writer(open(\"output.csv\", \"wb\")).writerows(a)"},{"id":0,"score":0.0,"value":"a \u003d [(1, 2, 3),\n     (4, 5, 6),\n     (7, 8, 9)]\nzip(*a)\n# [(1, 4, 7),\n#  (2, 5, 8),\n#  (3, 6, 9)]"},{"id":0,"score":0.0,"value":"import pandas as pd\npd.read_csv(\u0027input.csv\u0027, header\u003dNone).T.to_csv(\u0027output.csv\u0027, header\u003dFalse, index\u003dFalse)"},{"id":0,"score":0.0,"value":"csvfile \u003d \u0027filename\u0027\nwith open(csvfile, \u0027r\u0027) as fin, open(\u0027new_\u0027+csvfile, \u0027w\u0027) as fout:\n    reader \u003d csv.reader(fin, newline\u003d\u0027\u0027, lineterminator\u003d\u0027\\n\u0027)\n    writer \u003d csv.writer(fout, newline\u003d\u0027\u0027, lineterminator\u003d\u0027\\n\u0027)\n    if you_have_headers:\n        writer.writerow(next(reader) + [new_heading])\n    for row, val in zip(reader, data)\n        writer.writerow(row + [data])"},{"id":0,"score":0.0,"value":"import os\nos.remove(csvfile) # not needed on unix\nos.rename(\u0027new_\u0027+csvfile, csvfile)"},{"id":0,"score":0.0,"value":"import csv\nreader \u003d csv.reader(open(\u0027output.csv\u0027, \u0027rb\u0027))\nreader1 \u003d csv.reader(open(\u0027output1.csv\u0027, \u0027rb\u0027))\nwriter \u003d csv.writer(open(\u0027appended_output.csv\u0027, \u0027wb\u0027))\nfor row in reader:\n    row1 \u003d reader1.next()\n    writer.writerow(row + row1)"},{"id":0,"score":0.0,"value":"from csv import reader, writer \nwith open(\u0027source.csv\u0027) as f, open(\u0027destination.csv\u0027, \u0027w\u0027) as fw: \n    writer(fw, delimiter\u003d\u0027,\u0027).writerows(zip(*reader(f, delimiter\u003d\u0027,\u0027)))"}]},{"query":"copy column from csv file to csv file","hypotheses":[{"id":0,"score":0.0,"value":"for row in reader:\n    content \u003d list(row[i] for i in included_cols)\nprint content"},{"id":0,"score":0.0,"value":"for row in reader:\n        content \u003d list(row[i] for i in included_cols)\n        print content"},{"id":0,"score":0.0,"value":"import pandas as pd\ndf \u003d pd.read_csv(csv_file)\nsaved_column \u003d df.column_name #you can also use df[\u0027column_name\u0027]"},{"id":0,"score":0.0,"value":"names \u003d df.Names"},{"id":0,"score":0.0,"value":"import csv\nfrom collections import defaultdict\n\ncolumns \u003d defaultdict(list) # each value in each column is appended to a list\n\nwith open(\u0027file.txt\u0027) as f:\n    reader \u003d csv.DictReader(f) # read rows into a dictionary format\n    for row in reader: # read a row as {column1: value1, column2: value2,...}\n        for (k,v) in row.items(): # go over each column name and value \n            columns[k].append(v) # append the value into the appropriate list\n                                 # based on column name k\n\nprint(columns[\u0027name\u0027])\nprint(columns[\u0027phone\u0027])\nprint(columns[\u0027street\u0027])"},{"id":0,"score":0.0,"value":"name,phone,street\nBob,0893,32 Silly\nJames,000,400 McHilly\nSmithers,4442,23 Looped St."},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e \n[\u0027Bob\u0027, \u0027James\u0027, \u0027Smithers\u0027]\n[\u00270893\u0027, \u0027000\u0027, \u00274442\u0027]\n[\u002732 Silly\u0027, \u0027400 McHilly\u0027, \u002723 Looped St.\u0027]"}]}],[{"query":"Given list `letters` and `integers`, create a dicitonary such that the values in `letters` are keys and values in `integers` are values","hypotheses":[{"id":0,"score":0.0,"value":"{key: value for (key, value) in iterable}"},{"id":0,"score":0.0,"value":"dict((key, func(key)) for key in keys)"},{"id":0,"score":0.0,"value":"1) consumed from any iterable yielding pairs of keys/vals\ndict(pairs)\n\n2) \"zip\u0027ped\" from two separate iterables of keys/vals\ndict(zip(list_of_keys, list_of_values))"},{"id":0,"score":0.0,"value":"a \u003d [1,2,3,2,1,5,6,5,5,5]\n\nimport collections\nprint([item for item, count in collections.Counter(a).items() if count \u003e 1])\n\n## [1, 2, 5]"},{"id":0,"score":0.0,"value":"seen \u003d set()\nuniq \u003d []\nfor x in a:\n    if x not in seen:\n        uniq.append(x)\n        seen.add(x)"},{"id":0,"score":0.0,"value":"seen \u003d set()\nuniq \u003d [x for x in a if x in seen or seen.add(x)]"},{"id":0,"score":0.0,"value":"seen \u003d {}\ndupes \u003d []\n\nfor x in a:\n    if x not in seen:\n        seen[x] \u003d 1\n    else:\n        if seen[x] \u003d\u003d 1:\n            dupes.append(x)\n        seen[x] +\u003d 1"}]},{"query":"Given 2 list, create a dicitonary such that the values in one are keys and values in another are values","hypotheses":[{"id":0,"score":0.0,"value":"\u003e\u003e\u003e range(11, 17)\n[11, 12, 13, 14, 15, 16]"},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e list(range(11, 17))\n[11, 12, 13, 14, 15, 16]"},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e import numpy as np\n\u003e\u003e\u003e np.arange(11, 17, 0.5).tolist()\n\n[11.0, 11.5, 12.0, 12.5, 13.0, 13.5,\n 14.0, 14.5, 15.0, 15.5, 16.0, 16.5]"},{"id":0,"score":0.0,"value":"d.values()"},{"id":0,"score":0.0,"value":"list(d.values())"},{"id":0,"score":0.0,"value":"from collections import defaultdict\n\ndata_dict \u003d defaultdict(list)"},{"id":0,"score":0.0,"value":"data_dict[regNumber] \u003d details"}]}],[{"query":"print `dic` sorted by keys","hypotheses":[{"id":0,"score":0.0,"value":"In [1]: import collections\n\nIn [2]: d \u003d {2:3, 1:89, 4:5, 3:0}\n\nIn [3]: od \u003d collections.OrderedDict(sorted(d.items()))\n\nIn [4]: od\nOut[4]: OrderedDict([(1, 89), (2, 3), (3, 0), (4, 5)])"},{"id":0,"score":0.0,"value":"In [11]: od[1]\nOut[11]: 89\n\nIn [12]: od[3]\nOut[12]: 0\n\nIn [13]: for k, v in od.iteritems(): print k, v\n   ....: \n1 89\n2 3\n3 0\n4 5"},{"id":0,"score":0.0,"value":"In [13]: for k, v in od.items(): print(k, v)\n   ....: \n1 89\n2 3\n3 0\n4 5"},{"id":0,"score":0.0,"value":"mydict \u003d {\u0027carl\u0027:40,\n          \u0027alan\u0027:2,\n          \u0027bob\u0027:1,\n          \u0027danny\u0027:3}\n\nfor key in sorted(mydict):\n    print \"%s: %s\" % (key, mydict[key])"},{"id":0,"score":0.0,"value":"alan: 2\nbob: 1\ncarl: 40\ndanny: 3"},{"id":0,"score":0.0,"value":"keylist \u003d mydict.keys()\nkeylist.sort()\nfor key in keylist:\n    print \"%s: %s\" % (key, mydict[key])"},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e d \u003d {2:3, 1:89, 4:5, 3:0}\n\u003e\u003e\u003e dict(sorted(d.items()))\n{1: 89, 2: 3, 3: 0, 4: 5}"}]},{"query":"print dict sorted by keys","hypotheses":[{"id":0,"score":0.0,"value":"In [1]: import collections\n\nIn [2]: d \u003d {2:3, 1:89, 4:5, 3:0}\n\nIn [3]: od \u003d collections.OrderedDict(sorted(d.items()))\n\nIn [4]: od\nOut[4]: OrderedDict([(1, 89), (2, 3), (3, 0), (4, 5)])"},{"id":0,"score":0.0,"value":"In [11]: od[1]\nOut[11]: 89\n\nIn [12]: od[3]\nOut[12]: 0\n\nIn [13]: for k, v in od.iteritems(): print k, v\n   ....: \n1 89\n2 3\n3 0\n4 5"},{"id":0,"score":0.0,"value":"In [13]: for k, v in od.items(): print(k, v)\n   ....: \n1 89\n2 3\n3 0\n4 5"},{"id":0,"score":0.0,"value":"mydict \u003d {\u0027carl\u0027:40,\n          \u0027alan\u0027:2,\n          \u0027bob\u0027:1,\n          \u0027danny\u0027:3}\n\nfor key in sorted(mydict):\n    print \"%s: %s\" % (key, mydict[key])"},{"id":0,"score":0.0,"value":"alan: 2\nbob: 1\ncarl: 40\ndanny: 3"},{"id":0,"score":0.0,"value":"keylist \u003d mydict.keys()\nkeylist.sort()\nfor key in keylist:\n    print \"%s: %s\" % (key, mydict[key])"},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e d \u003d {2:3, 1:89, 4:5, 3:0}\n\u003e\u003e\u003e dict(sorted(d.items()))\n{1: 89, 2: 3, 3: 0, 4: 5}"}]}],[{"query":"open a csv file `data.csv` and read the data","hypotheses":[{"id":0,"score":0.0,"value":"for row in reader:\n    content \u003d list(row[i] for i in included_cols)\nprint content"},{"id":0,"score":0.0,"value":"for row in reader:\n        content \u003d list(row[i] for i in included_cols)\n        print content"},{"id":0,"score":0.0,"value":"import pandas as pd\ndf \u003d pd.read_csv(csv_file)\nsaved_column \u003d df.column_name #you can also use df[\u0027column_name\u0027]"},{"id":0,"score":0.0,"value":"names \u003d df.Names"},{"id":0,"score":0.0,"value":"import csv\n\ndef getstuff(filename, criterion):\n    with open(filename, \"rb\") as csvfile:\n        datareader \u003d csv.reader(csvfile)\n        yield next(datareader)  # yield the header row\n        count \u003d 0\n        for row in datareader:\n            if row[3] \u003d\u003d criterion:\n                yield row\n                count +\u003d 1\n            elif count:\n                # done when having read a consecutive series of rows \n                return"},{"id":0,"score":0.0,"value":"import csv\nfrom itertools import dropwhile, takewhile\n\ndef getstuff(filename, criterion):\n    with open(filename, \"rb\") as csvfile:\n        datareader \u003d csv.reader(csvfile)\n        yield next(datareader)  # yield the header row\n        # first row, plus any subsequent rows that match, then stop\n        # reading altogether\n        # Python 2: use `for row in takewhile(...): yield row` instead\n        # instead of `yield from takewhile(...)`.\n        yield from takewhile(\n            lambda r: r[3] \u003d\u003d criterion,\n            dropwhile(lambda r: r[3] !\u003d criterion, datareader))\n        return"},{"id":0,"score":0.0,"value":"def getdata(filename, criteria):\n    for criterion in criteria:\n        for row in getstuff(filename, criterion):\n            yield row"}]},{"query":"open a csv file and read the data","hypotheses":[{"id":0,"score":0.0,"value":"for row in reader:\n    content \u003d list(row[i] for i in included_cols)\nprint content"},{"id":0,"score":0.0,"value":"for row in reader:\n        content \u003d list(row[i] for i in included_cols)\n        print content"},{"id":0,"score":0.0,"value":"import pandas as pd\ndf \u003d pd.read_csv(csv_file)\nsaved_column \u003d df.column_name #you can also use df[\u0027column_name\u0027]"},{"id":0,"score":0.0,"value":"names \u003d df.Names"},{"id":0,"score":0.0,"value":"import csv\nfrom collections import defaultdict\n\ncolumns \u003d defaultdict(list) # each value in each column is appended to a list\n\nwith open(\u0027file.txt\u0027) as f:\n    reader \u003d csv.DictReader(f) # read rows into a dictionary format\n    for row in reader: # read a row as {column1: value1, column2: value2,...}\n        for (k,v) in row.items(): # go over each column name and value \n            columns[k].append(v) # append the value into the appropriate list\n                                 # based on column name k\n\nprint(columns[\u0027name\u0027])\nprint(columns[\u0027phone\u0027])\nprint(columns[\u0027street\u0027])"},{"id":0,"score":0.0,"value":"name,phone,street\nBob,0893,32 Silly\nJames,000,400 McHilly\nSmithers,4442,23 Looped St."},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e \n[\u0027Bob\u0027, \u0027James\u0027, \u0027Smithers\u0027]\n[\u00270893\u0027, \u0027000\u0027, \u00274442\u0027]\n[\u002732 Silly\u0027, \u0027400 McHilly\u0027, \u002723 Looped St.\u0027]"}]}],[{"query":"delete first row from dataframe `df`","hypotheses":[{"id":0,"score":0.0,"value":"df \u003d df.iloc[3:]"},{"id":0,"score":0.0,"value":"df.drop(label)"},{"id":0,"score":0.0,"value":"df.drop(label, inplace\u003dTrue)"},{"id":0,"score":0.0,"value":"df.drop(df.index[:3], inplace\u003dTrue)"},{"id":0,"score":0.0,"value":"df.drop(df.head(3).index, inplace\u003dTrue)"},{"id":0,"score":0.0,"value":"In [425]:\n\ndf \u003d pd.DataFrame({\u0027a\u0027:np.random.randn(5), \u0027b\u0027:np.random.randn(5)})\ndf\nOut[425]:\n          a         b\n0 -1.348112  0.583603\n1  0.174836  1.211774\n2 -2.054173  0.148201\n3 -0.589193 -0.369813\n4 -1.156423 -0.967516\nIn [426]:\n\nfor index, row in df.iterrows():\n    if row[\u0027a\u0027] \u003e 0:\n        df.drop(index, inplace\u003dTrue)\nIn [427]:\n\ndf\nOut[427]:\n          a         b\n0 -1.348112  0.583603\n2 -2.054173  0.148201\n3 -0.589193 -0.369813\n4 -1.156423 -0.967516"},{"id":0,"score":0.0,"value":"df[df[\u0027a\u0027] \u003c\u003d0]"}]},{"query":"delete first row from dataframe","hypotheses":[{"id":0,"score":0.0,"value":"df \u003d df.iloc[3:]"},{"id":0,"score":0.0,"value":"df.drop(label)"},{"id":0,"score":0.0,"value":"df.drop(label, inplace\u003dTrue)"},{"id":0,"score":0.0,"value":"df.drop(df.index[:3], inplace\u003dTrue)"},{"id":0,"score":0.0,"value":"df.drop(df.head(3).index, inplace\u003dTrue)"},{"id":0,"score":0.0,"value":"In [11]:\nd[\u0027Report Number\u0027] \u003d d[\u0027Report Number\u0027].str[3:]\nd\n\nOut[11]:\n     Name Report Number\n0  George       1234567\n1    Bill       9876543\n2   Sally       4434555"},{"id":0,"score":0.0,"value":"header \u003d rdd.first()\nrdd.filter(lambda line: line !\u003d header)"}]}],[{"query":"delete first and last row from the dataframe `df`","hypotheses":[{"id":0,"score":0.0,"value":"df \u003d df.iloc[3:]"},{"id":0,"score":0.0,"value":"df.drop(df.tail(n).index,inplace\u003dTrue) # drop last n rows"},{"id":0,"score":0.0,"value":"df.drop(df.head(n).index,inplace\u003dTrue) # drop first n rows"},{"id":0,"score":0.0,"value":"df \u003d pd.DataFrame({\u0027a\u0027:range(1,5), \u0027b\u0027:[\u0027a\u0027,\u0027b\u0027,\u0027c\u0027,\u0027d\u0027]})\ndf2 \u003d df.iloc[[0, -1]]\n\nprint df2\n\n   a  b\n0  1  a\n3  4  d"},{"id":0,"score":0.0,"value":"DF[:-n]"},{"id":0,"score":0.0,"value":"DF \u003d DF[:-1]"},{"id":0,"score":0.0,"value":"df.drop(label)"}]},{"query":"delete first and last row from the dataframe","hypotheses":[{"id":0,"score":0.0,"value":"df \u003d df.iloc[3:]"},{"id":0,"score":0.0,"value":"df.drop(df.tail(n).index,inplace\u003dTrue) # drop last n rows"},{"id":0,"score":0.0,"value":"df.drop(df.head(n).index,inplace\u003dTrue) # drop first n rows"},{"id":0,"score":0.0,"value":"df \u003d pd.DataFrame({\u0027a\u0027:range(1,5), \u0027b\u0027:[\u0027a\u0027,\u0027b\u0027,\u0027c\u0027,\u0027d\u0027]})\ndf2 \u003d df.iloc[[0, -1]]\n\nprint df2\n\n   a  b\n0  1  a\n3  4  d"},{"id":0,"score":0.0,"value":"DF[:-n]"},{"id":0,"score":0.0,"value":"DF \u003d DF[:-1]"},{"id":0,"score":0.0,"value":"df.drop(label)"}]}],[{"query":"save `df` to a file `output.csv` in a new directory `example_output`","hypotheses":[{"id":0,"score":0.0,"value":"import os.path\n\nsave_path \u003d \u0027C:/example/\u0027\n\nname_of_file \u003d raw_input(\"What is the name of the file: \")\n\ncompleteName \u003d os.path.join(save_path, name_of_file+\".txt\")         \n\nfile1 \u003d open(completeName, \"w\")\n\ntoFile \u003d raw_input(\"Write what you want into the field\")\n\nfile1.write(toFile)\n\nfile1.close()"},{"id":0,"score":0.0,"value":"import numpy as np\nnp.savetxt(\u0027data.csv\u0027, (col1_array, col2_array, col3_array), delimiter\u003d\u0027,\u0027)"},{"id":0,"score":0.0,"value":"names \u003d [\u0027Player Name\u0027, \u0027Foo\u0027, \u0027Bar\u0027]\nscores \u003d [\u0027Score\u0027, 250, 500]"},{"id":0,"score":0.0,"value":"np.savetxt(\u0027scores.csv\u0027, [p for p in zip(names, scores)], delimiter\u003d\u0027,\u0027, fmt\u003d\u0027%s\u0027)"},{"id":0,"score":0.0,"value":"Player Name,Score\nFoo,250\nBar,500"},{"id":0,"score":0.0,"value":"import csv\n\nwith open(\u0027thefile.csv\u0027, \u0027rb\u0027) as f:\n  data \u003d list(csv.reader(f))\n\nimport collections\ncounter \u003d collections.defaultdict(int)\nfor row in data:\n    counter[row[0]] +\u003d 1\n\n\nwriter \u003d csv.writer(open(\"/path/to/my/csv/file\", \u0027w\u0027))\nfor row in data:\n    if counter[row[0]] \u003e\u003d 4:\n        writer.writerow(row)"},{"id":0,"score":0.0,"value":"import os\nwith open(os.path.join(\u0027/path/to/Documents\u0027,completeName), \"w\") as file1:\n    toFile \u003d raw_input(\"Write what you want into the field\")\n    file1.write(toFile)"}]},{"query":"save dataframe to a csv file in a new directory","hypotheses":[{"id":0,"score":0.0,"value":"root \u003d \u0027MonthlyDataSplit\u0027\nfor gp in g:\n    filename \u003d gp[0] + \u0027.csv\u0027\n    print(filename)\n    gp[1].to_csv(root + \u0027/\u0027 + filename)"},{"id":0,"score":0.0,"value":"In [3]:\nimport os\nroot \u003d \u0027MonthlyDataSplit\u0027\nos.path.join(root, \u0027some_file.csv\u0027)\n\nOut[3]:\n\u0027MonthlyDataSplit\\\\some_file.csv\u0027"},{"id":0,"score":0.0,"value":"In [8]:\nimport os\nroot \u003d \u0027MonthlyDataSplit\u0027\nday \u003d \u0027Day\u0027\nsubdir \u003d os.path.join(root, day)\nfinal_path \u003d os.path.join(subdir, \u0027some_file_name\u0027)\nfinal_path\n\nOut[8]:\n\u0027MonthlyDataSplit\\\\Day\\\\some_file_name\u0027"},{"id":0,"score":0.0,"value":"...\n\ndef Rho (df): \n    if  (X1\u003e65 and X2\u003e65 and X3\u003e65 and X4\u003e65):\n        df.to_csv(path\u003d\u0027D:\\My_Path\\High.csv\u0027)\n    elif (X1\u003c55 and X2\u003c55 and X3\u003c55 and X4\u003c55):\n        df.to_csv(path\u003d\u0027D:\\My_Path\\Low.csv\u0027)        \n    else:\n        print(\"Ignore\")       \n..."},{"id":0,"score":0.0,"value":"f \u003d open(\u0027workfile\u0027, \u0027r+\u0027)\nf.write(\u00270123456789abcdef\u0027)"},{"id":0,"score":0.0,"value":"import csv\nwith open(\u0027pathtofile\u0027,\u0027wb\u0027) as csvFile: #EDIT - because comment.\n    writer \u003d csv.writer(csvFile)\n    writer.writerows(csvstff)"},{"id":0,"score":0.0,"value":"directory\u003d\u0027C:\\Users\\Documents\\pyth\\tweet_sentiment.csv\u0027"}]}],[{"query":"visit the url `url`","hypotheses":[{"id":0,"score":0.0,"value":"import urllib.request\ncontents \u003d urllib.request.urlopen(\"http://example.com/foo/bar\").read()"},{"id":0,"score":0.0,"value":"import urllib2\ncontents \u003d urllib2.urlopen(\"http://example.com/foo/bar\").read()"},{"id":0,"score":0.0,"value":"import requests\nr \u003d requests.get(\"http://example.com/foo/bar\")"},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e print(r.status_code)\n\u003e\u003e\u003e print(r.headers)\n\u003e\u003e\u003e print(r.content)"},{"id":0,"score":0.0,"value":"import webbrowser\n\nwebbrowser.open(\u0027http://example.com\u0027)  # Go to example.com"},{"id":0,"score":0.0,"value":"import urllib\n\nlink \u003d \"http://www.somesite.com/details.pl?urn\u003d2344\"\nf \u003d urllib.urlopen(link)\nmyfile \u003d f.read()\nprint(myfile)"},{"id":0,"score":0.0,"value":"import requests\n\nlink \u003d \"http://www.somesite.com/details.pl?urn\u003d2344\"\nf \u003d requests.get(link)\nprint(f.text)"}]},{"query":"visit the url","hypotheses":[{"id":0,"score":0.0,"value":"import urllib.request\ncontents \u003d urllib.request.urlopen(\"http://example.com/foo/bar\").read()"},{"id":0,"score":0.0,"value":"import urllib2\ncontents \u003d urllib2.urlopen(\"http://example.com/foo/bar\").read()"},{"id":0,"score":0.0,"value":"import requests\nr \u003d requests.get(\"http://example.com/foo/bar\")"},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e print(r.status_code)\n\u003e\u003e\u003e print(r.headers)\n\u003e\u003e\u003e print(r.content)"},{"id":0,"score":0.0,"value":"import webbrowser\n\nwebbrowser.open(\u0027http://example.com\u0027)  # Go to example.com"},{"id":0,"score":0.0,"value":"import urllib\n\nlink \u003d \"http://www.somesite.com/details.pl?urn\u003d2344\"\nf \u003d urllib.urlopen(link)\nmyfile \u003d f.read()\nprint(myfile)"},{"id":0,"score":0.0,"value":"import requests\n\nlink \u003d \"http://www.somesite.com/details.pl?urn\u003d2344\"\nf \u003d requests.get(link)\nprint(f.text)"}]}],[{"query":"parse all hyperlinks from `r` using bs4","hypotheses":[{"id":0,"score":0.0,"value":"from bs4 import BeautifulSoup, SoupStrainer\nimport requests\n\nurl \u003d \"http://stackoverflow.com/\"\n\npage \u003d requests.get(url)    \ndata \u003d page.text\nsoup \u003d BeautifulSoup(data)\n\nfor link in soup.find_all(\u0027a\u0027):\n    print(link.get(\u0027href\u0027))"},{"id":0,"score":0.0,"value":"links \u003d soup.find_all(\u0027a\u0027)"},{"id":0,"score":0.0,"value":"link \u003d links[0]          # get the first link in the entire page\nurl  \u003d link[\u0027href\u0027]      # get value of the href attribute\nurl  \u003d link.get(\u0027href\u0027)  # or like this"},{"id":0,"score":0.0,"value":"links \u003d soup.find_all(\u0027a\u0027)"},{"id":0,"score":0.0,"value":"links \u003d [a.get(\u0027href\u0027) for a in soup.find_all(\u0027a\u0027, href\u003dTrue)]"},{"id":0,"score":0.0,"value":"import requests\nfrom bs4 import BeautifulSoup\n\nurl \u003d \u0027http://www.fortwiki.com/Battery_Adair\u0027\nr \u003d requests.get(url)\nsoup \u003d BeautifulSoup(r.text, \"html.parser\")\n\nb \u003d soup.find(\u0027b\u0027, text\u003d\u0027Maps \u0026 Images\u0027)\nif b:\n    lat_long \u003d b.find_next().text"},{"id":0,"score":0.0,"value":"class AllSpider(scrapy.Spider):\n    name \u003d \u0027all\u0027\n\n    start_urls \u003d [\u0027https://yourgithub.com\u0027]\n\n    def __init__(self):\n        self.links\u003d[]\n\n    def parse(self, response):\n        self.links.append(response.url)\n        for href in response.css(\u0027a::attr(href)\u0027):\n            yield response.follow(href, self.parse)"}]},{"query":"parse all hyperlinks using bs4","hypotheses":[{"id":0,"score":0.0,"value":"import httplib2\nfrom bs4 import BeautifulSoup, SoupStrainer\n\nhttp \u003d httplib2.Http()\nstatus, response \u003d http.request(\u0027http://www.nytimes.com\u0027)\n\nfor link in BeautifulSoup(response, parse_only\u003dSoupStrainer(\u0027a\u0027)):\n    if link.has_attr(\u0027href\u0027):\n        print(link[\u0027href\u0027])"},{"id":0,"score":0.0,"value":"from BeautifulSoup import BeautifulSoup\nimport urllib2\nimport re\n\nhtml_page \u003d urllib2.urlopen(\"http://www.yourwebsite.com\")\nsoup \u003d BeautifulSoup(html_page)\nfor link in soup.findAll(\u0027a\u0027):\n    print link.get(\u0027href\u0027)"},{"id":0,"score":0.0,"value":"soup.findAll(\u0027a\u0027, attrs\u003d{\u0027href\u0027: re.compile(\"^http://\")})"},{"id":0,"score":0.0,"value":"from bs4 import BeautifulSoup\nimport urllib.request\n\nhtml_page \u003d urllib.request.urlopen(\"http://www.yourwebsite.com\")\nsoup \u003d BeautifulSoup(html_page, \"html.parser\")\nfor link in soup.findAll(\u0027a\u0027):\n    print(link.get(\u0027href\u0027))"},{"id":0,"score":0.0,"value":"from bs4 import BeautifulSoup\nimport urllib.request\n\nparser \u003d \u0027html.parser\u0027  # or \u0027lxml\u0027 (preferred) or \u0027html5lib\u0027, if installed\nresp \u003d urllib.request.urlopen(\"http://www.gpsbasecamp.com/national-parks\")\nsoup \u003d BeautifulSoup(resp, parser, from_encoding\u003dresp.info().get_param(\u0027charset\u0027))\n\nfor link in soup.find_all(\u0027a\u0027, href\u003dTrue):\n    print(link[\u0027href\u0027])"},{"id":0,"score":0.0,"value":"from bs4 import BeautifulSoup\nimport urllib2\n\nparser \u003d \u0027html.parser\u0027  # or \u0027lxml\u0027 (preferred) or \u0027html5lib\u0027, if installed\nresp \u003d urllib2.urlopen(\"http://www.gpsbasecamp.com/national-parks\")\nsoup \u003d BeautifulSoup(resp, parser, from_encoding\u003dresp.info().getparam(\u0027charset\u0027))\n\nfor link in soup.find_all(\u0027a\u0027, href\u003dTrue):\n    print link[\u0027href\u0027]"},{"id":0,"score":0.0,"value":"from bs4 import BeautifulSoup\nfrom bs4.dammit import EncodingDetector\nimport requests\n\nparser \u003d \u0027html.parser\u0027  # or \u0027lxml\u0027 (preferred) or \u0027html5lib\u0027, if installed\nresp \u003d requests.get(\"http://www.gpsbasecamp.com/national-parks\")\nhttp_encoding \u003d resp.encoding if \u0027charset\u0027 in resp.headers.get(\u0027content-type\u0027, \u0027\u0027).lower() else None\nhtml_encoding \u003d EncodingDetector.find_declared_encoding(resp.content, is_html\u003dTrue)\nencoding \u003d html_encoding or http_encoding\nsoup \u003d BeautifulSoup(resp.content, parser, from_encoding\u003dencoding)\n\nfor link in soup.find_all(\u0027a\u0027, href\u003dTrue):\n    print(link[\u0027href\u0027])"}]}],[{"query":"visit the given url `url` and extract all hrefs from there","hypotheses":[{"id":0,"score":0.0,"value":"from BeautifulSoup import BeautifulSoup\n\nhtml \u003d \u0027\u0027\u0027\u003ca href\u003d\"some_url\"\u003enext\u003c/a\u003e\n\u003cspan class\u003d\"class\"\u003e\u003ca href\u003d\"another_url\"\u003elater\u003c/a\u003e\u003c/span\u003e\u0027\u0027\u0027\n\nsoup \u003d BeautifulSoup(html)\n\nfor a in soup.find_all(\u0027a\u0027, href\u003dTrue):\n    print \"Found the URL:\", a[\u0027href\u0027]"},{"id":0,"score":0.0,"value":"Found the URL: some_url\nFound the URL: another_url"},{"id":0,"score":0.0,"value":"href_tags \u003d soup.find_all(href\u003dTrue)"},{"id":0,"score":0.0,"value":"import urllib\n\nlink \u003d \"http://www.somesite.com/details.pl?urn\u003d2344\"\nf \u003d urllib.urlopen(link)\nmyfile \u003d f.read()\nprint(myfile)"},{"id":0,"score":0.0,"value":"import requests\n\nlink \u003d \"http://www.somesite.com/details.pl?urn\u003d2344\"\nf \u003d requests.get(link)\nprint(f.text)"},{"id":0,"score":0.0,"value":"elems \u003d driver.find_elements_by_xpath(\"//a[@href]\")\nfor elem in elems:\n    print(elem.get_attribute(\"href\"))"},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e import urlparse\n\u003e\u003e\u003e path \u003d urlparse.urlparse(\u0027http://www.example.com/hithere/something/else\u0027).path\n\u003e\u003e\u003e path\n\u0027/hithere/something/else\u0027"}]},{"query":"visit the given url and extract all hrefs from there","hypotheses":[{"id":0,"score":0.0,"value":"from BeautifulSoup import BeautifulSoup\n\nhtml \u003d \u0027\u0027\u0027\u003ca href\u003d\"some_url\"\u003enext\u003c/a\u003e\n\u003cspan class\u003d\"class\"\u003e\u003ca href\u003d\"another_url\"\u003elater\u003c/a\u003e\u003c/span\u003e\u0027\u0027\u0027\n\nsoup \u003d BeautifulSoup(html)\n\nfor a in soup.find_all(\u0027a\u0027, href\u003dTrue):\n    print \"Found the URL:\", a[\u0027href\u0027]"},{"id":0,"score":0.0,"value":"Found the URL: some_url\nFound the URL: another_url"},{"id":0,"score":0.0,"value":"href_tags \u003d soup.find_all(href\u003dTrue)"},{"id":0,"score":0.0,"value":"elems \u003d driver.find_elements_by_xpath(\"//a[@href]\")\nfor elem in elems:\n    print(elem.get_attribute(\"href\"))"},{"id":0,"score":0.0,"value":"#!/usr/bin/env python\n\nimport requests\nfrom bs4 import BeautifulSoup\n\nurl \u003d \"http://www.python.org\"\nresponse \u003d requests.get(url)\n# parse html\npage \u003d str(BeautifulSoup(response.content))\n\n\ndef getURL(page):\n    \"\"\"\n\n    :param page: html of web page (here: Python home page) \n    :return: urls in that page \n    \"\"\"\n    start_link \u003d page.find(\"a href\")\n    if start_link \u003d\u003d -1:\n        return None, 0\n    start_quote \u003d page.find(\u0027\"\u0027, start_link)\n    end_quote \u003d page.find(\u0027\"\u0027, start_quote + 1)\n    url \u003d page[start_quote + 1: end_quote]\n    return url, end_quote\n\nwhile True:\n    url, n \u003d getURL(page)\n    page \u003d page[n:]\n    if url:\n        print(url)\n    else:\n        break"},{"id":0,"score":0.0,"value":"/\n#left-hand-navigation\n#content-body\n/search\n/about/\n/news/\n/doc/\n/download/\n/getit/\n/community/\n/psf/\nhttp://docs.python.org/devguide/\n/about/help/\nhttp://pypi.python.org/pypi\n/download/releases/2.7.3/\nhttp://docs.python.org/2/\n/ftp/python/2.7.3/python-2.7.3.msi\n/ftp/python/2.7.3/Python-2.7.3.tar.bz2\n/download/releases/3.3.0/\nhttp://docs.python.org/3/\n/ftp/python/3.3.0/python-3.3.0.msi\n/ftp/python/3.3.0/Python-3.3.0.tar.bz2\n/community/jobs/\n/community/merchandise/\n/psf/donations/\nhttp://wiki.python.org/moin/Languages\nhttp://wiki.python.org/moin/Languages\nhttp://www.google.com/calendar/ical/b6v58qvojllt0i6ql654r1vh00%40group.calendar.google.com/public/basic.ics\nhttp://www.google.com/calendar/ical/j7gov1cmnqr9tvg14k621j7t5c%40group.calendar.google.com/public/basic.ics\nhttp://pycon.org/#calendar\nhttp://www.google.com/calendar/ical/3haig2m9msslkpf2tn1h56nn9g%40group.calendar.google.com/public/basic.ics\nhttp://pycon.org/#calendar\nhttp://www.psfmember.org"},{"id":0,"score":0.0,"value":"from bs4 import BeautifulSoup, SoupStrainer\nimport requests\n\nurl \u003d \"http://stackoverflow.com/\"\n\npage \u003d requests.get(url)    \ndata \u003d page.text\nsoup \u003d BeautifulSoup(data)\n\nfor link in soup.find_all(\u0027a\u0027):\n    print(link.get(\u0027href\u0027))"}]}],[{"query":"visit `url` and extract hrefs using bs4","hypotheses":[{"id":0,"score":0.0,"value":"from BeautifulSoup import BeautifulSoup\n\nhtml \u003d \u0027\u0027\u0027\u003ca href\u003d\"some_url\"\u003enext\u003c/a\u003e\n\u003cspan class\u003d\"class\"\u003e\u003ca href\u003d\"another_url\"\u003elater\u003c/a\u003e\u003c/span\u003e\u0027\u0027\u0027\n\nsoup \u003d BeautifulSoup(html)\n\nfor a in soup.find_all(\u0027a\u0027, href\u003dTrue):\n    print \"Found the URL:\", a[\u0027href\u0027]"},{"id":0,"score":0.0,"value":"Found the URL: some_url\nFound the URL: another_url"},{"id":0,"score":0.0,"value":"href_tags \u003d soup.find_all(href\u003dTrue)"},{"id":0,"score":0.0,"value":"from BeautifulSoup import BeautifulSoup\nimport urllib2\nimport re\n\nhtml_page \u003d urllib2.urlopen(\"http://www.yourwebsite.com\")\nsoup \u003d BeautifulSoup(html_page)\nfor link in soup.findAll(\u0027a\u0027):\n    print link.get(\u0027href\u0027)"},{"id":0,"score":0.0,"value":"soup.findAll(\u0027a\u0027, attrs\u003d{\u0027href\u0027: re.compile(\"^http://\")})"},{"id":0,"score":0.0,"value":"from bs4 import BeautifulSoup\nimport urllib.request\n\nhtml_page \u003d urllib.request.urlopen(\"http://www.yourwebsite.com\")\nsoup \u003d BeautifulSoup(html_page, \"html.parser\")\nfor link in soup.findAll(\u0027a\u0027):\n    print(link.get(\u0027href\u0027))"},{"id":0,"score":0.0,"value":"from HTMLParser import HTMLParser\n\nclass MyHTMLParser(HTMLParser):\n\n    def handle_starttag(self, tag, attrs):\n        # Only parse the \u0027anchor\u0027 tag.\n        if tag \u003d\u003d \"a\":\n           # Check the list of defined attributes.\n           for name, value in attrs:\n               # If href is defined, print it.\n               if name \u003d\u003d \"href\":\n                   print name, \"\u003d\", value\n\n\nparser \u003d MyHTMLParser()\nparser.feed(your_html_string)"}]},{"query":"visit url and extract hrefs using bs4","hypotheses":[{"id":0,"score":0.0,"value":"from BeautifulSoup import BeautifulSoup\n\nhtml \u003d \u0027\u0027\u0027\u003ca href\u003d\"some_url\"\u003enext\u003c/a\u003e\n\u003cspan class\u003d\"class\"\u003e\u003ca href\u003d\"another_url\"\u003elater\u003c/a\u003e\u003c/span\u003e\u0027\u0027\u0027\n\nsoup \u003d BeautifulSoup(html)\n\nfor a in soup.find_all(\u0027a\u0027, href\u003dTrue):\n    print \"Found the URL:\", a[\u0027href\u0027]"},{"id":0,"score":0.0,"value":"Found the URL: some_url\nFound the URL: another_url"},{"id":0,"score":0.0,"value":"href_tags \u003d soup.find_all(href\u003dTrue)"},{"id":0,"score":0.0,"value":"from BeautifulSoup import BeautifulSoup\nimport urllib2\nimport re\n\nhtml_page \u003d urllib2.urlopen(\"http://www.yourwebsite.com\")\nsoup \u003d BeautifulSoup(html_page)\nfor link in soup.findAll(\u0027a\u0027):\n    print link.get(\u0027href\u0027)"},{"id":0,"score":0.0,"value":"soup.findAll(\u0027a\u0027, attrs\u003d{\u0027href\u0027: re.compile(\"^http://\")})"},{"id":0,"score":0.0,"value":"from bs4 import BeautifulSoup\nimport urllib.request\n\nhtml_page \u003d urllib.request.urlopen(\"http://www.yourwebsite.com\")\nsoup \u003d BeautifulSoup(html_page, \"html.parser\")\nfor link in soup.findAll(\u0027a\u0027):\n    print(link.get(\u0027href\u0027))"},{"id":0,"score":0.0,"value":"from HTMLParser import HTMLParser\n\nclass MyHTMLParser(HTMLParser):\n\n    def handle_starttag(self, tag, attrs):\n        # Only parse the \u0027anchor\u0027 tag.\n        if tag \u003d\u003d \"a\":\n           # Check the list of defined attributes.\n           for name, value in attrs:\n               # If href is defined, print it.\n               if name \u003d\u003d \"href\":\n                   print name, \"\u003d\", value\n\n\nparser \u003d MyHTMLParser()\nparser.feed(your_html_string)"}]}],[{"query":"find all hrefs from `soup`","hypotheses":[{"id":0,"score":0.0,"value":"from BeautifulSoup import BeautifulSoup\n\nhtml \u003d \u0027\u0027\u0027\u003ca href\u003d\"some_url\"\u003enext\u003c/a\u003e\n\u003cspan class\u003d\"class\"\u003e\u003ca href\u003d\"another_url\"\u003elater\u003c/a\u003e\u003c/span\u003e\u0027\u0027\u0027\n\nsoup \u003d BeautifulSoup(html)\n\nfor a in soup.find_all(\u0027a\u0027, href\u003dTrue):\n    print \"Found the URL:\", a[\u0027href\u0027]"},{"id":0,"score":0.0,"value":"Found the URL: some_url\nFound the URL: another_url"},{"id":0,"score":0.0,"value":"href_tags \u003d soup.find_all(href\u003dTrue)"},{"id":0,"score":0.0,"value":"from BeautifulSoup import BeautifulSoup\nimport urllib2\nimport re\n\nhtml_page \u003d urllib2.urlopen(\"http://www.yourwebsite.com\")\nsoup \u003d BeautifulSoup(html_page)\nfor link in soup.findAll(\u0027a\u0027):\n    print link.get(\u0027href\u0027)"},{"id":0,"score":0.0,"value":"soup.findAll(\u0027a\u0027, attrs\u003d{\u0027href\u0027: re.compile(\"^http://\")})"},{"id":0,"score":0.0,"value":"from bs4 import BeautifulSoup\nimport urllib.request\n\nhtml_page \u003d urllib.request.urlopen(\"http://www.yourwebsite.com\")\nsoup \u003d BeautifulSoup(html_page, \"html.parser\")\nfor link in soup.findAll(\u0027a\u0027):\n    print(link.get(\u0027href\u0027))"},{"id":0,"score":0.0,"value":"In [39]: from bs4 import BeautifulSoup\n\nIn [40]: s \u003d \"\"\"\\\n   ....: \u003ca href\u003d\"http://example.com\"\u003eTEXT\u003c/a\u003e\n   ....: \u003ca href\u003d\"http://example.com/link\"\u003eTEXT\u003c/a\u003e\n   ....: \u003ca href\u003d\"http://example.com/page\"\u003eTEXT\u003c/a\u003e\n   ....: \u003ca href\u003d\"http://dontmatchme.com/page\"\u003eWRONGTEXT\u003c/a\u003e\"\"\"\n\nIn [41]: soup \u003d BeautifulSoup(s)\n\nIn [42]: for link in soup.findAll(\u0027a\u0027, href\u003dTrue, text\u003d\u0027TEXT\u0027):\n   ....:     print link[\u0027href\u0027]\n   ....:\n   ....:\nhttp://example.com\nhttp://example.com/link\nhttp://example.com/page"}]},{"query":"find all hrefs from beautifulsoup","hypotheses":[{"id":0,"score":0.0,"value":"from BeautifulSoup import BeautifulSoup\n\nhtml \u003d \u0027\u0027\u0027\u003ca href\u003d\"some_url\"\u003enext\u003c/a\u003e\n\u003cspan class\u003d\"class\"\u003e\u003ca href\u003d\"another_url\"\u003elater\u003c/a\u003e\u003c/span\u003e\u0027\u0027\u0027\n\nsoup \u003d BeautifulSoup(html)\n\nfor a in soup.find_all(\u0027a\u0027, href\u003dTrue):\n    print \"Found the URL:\", a[\u0027href\u0027]"},{"id":0,"score":0.0,"value":"Found the URL: some_url\nFound the URL: another_url"},{"id":0,"score":0.0,"value":"href_tags \u003d soup.find_all(href\u003dTrue)"},{"id":0,"score":0.0,"value":"from BeautifulSoup import BeautifulSoup\nimport urllib2\nimport re\n\nhtml_page \u003d urllib2.urlopen(\"http://www.yourwebsite.com\")\nsoup \u003d BeautifulSoup(html_page)\nfor link in soup.findAll(\u0027a\u0027):\n    print link.get(\u0027href\u0027)"},{"id":0,"score":0.0,"value":"soup.findAll(\u0027a\u0027, attrs\u003d{\u0027href\u0027: re.compile(\"^http://\")})"},{"id":0,"score":0.0,"value":"from bs4 import BeautifulSoup\nimport urllib.request\n\nhtml_page \u003d urllib.request.urlopen(\"http://www.yourwebsite.com\")\nsoup \u003d BeautifulSoup(html_page, \"html.parser\")\nfor link in soup.findAll(\u0027a\u0027):\n    print(link.get(\u0027href\u0027))"},{"id":0,"score":0.0,"value":"soup.select(\"a[href*\u003dlocation]\")"}]}],[{"query":"find all bold text from html `soup`","hypotheses":[{"id":0,"score":0.0,"value":"\u003e\u003e\u003e from bs4 import BeautifulSoup\n\u003e\u003e\u003e\n\u003e\u003e\u003e html \u003d \"\"\"\u003cdiv\u003esomething\u003c/div\u003e\n... \u003cdiv\u003esomething else\u003c/div\u003e\n... \u003cdiv class\u003d\u0027magical\u0027\u003ehi there\u003c/div\u003e\n... \u003cp\u003eok\u003c/p\u003e\"\"\"\n\u003e\u003e\u003e soup \u003d BeautifulSoup(html, \"html.parser\")\n\u003e\u003e\u003e [tag.name for tag in soup.find_all()]\n[u\u0027div\u0027, u\u0027div\u0027, u\u0027div\u0027, u\u0027p\u0027]\n\u003e\u003e\u003e [str(tag) for tag in soup.find_all()]\n[\u0027\u003cdiv\u003esomething\u003c/div\u003e\u0027, \u0027\u003cdiv\u003esomething else\u003c/div\u003e\u0027, \u0027\u003cdiv class\u003d\"magical\"\u003ehi there\u003c/div\u003e\u0027, \u0027\u003cp\u003eok\u003c/p\u003e\u0027]"},{"id":0,"score":0.0,"value":"import BeautifulSoup\nimport re\n\ncolumns \u003d soup.findAll(\u0027td\u0027, text \u003d re.compile(\u0027your regex here\u0027), attrs \u003d {\u0027class\u0027 : \u0027pos\u0027})"},{"id":0,"score":0.0,"value":"curl https://gist.githubusercontent.com/RichardBronosky/4060082/raw/test.py | python"},{"id":0,"score":0.0,"value":"# Taken from https://gist.github.com/4060082\nfrom BeautifulSoup import BeautifulSoup\nfrom urllib2 import urlopen\nfrom pprint import pprint\nimport re\n\nsoup \u003d BeautifulSoup(urlopen(\u0027https://gist.githubusercontent.com/RichardBronosky/4060082/raw/test.html\u0027).read())\n# I\u0027m going to assume that Peter knew that re.compile is meant to cache a computation result for a performance benefit. However, I\u0027m going to do that explicitly here to be very clear.\npattern \u003d re.compile(\u0027Fixed text\u0027)\n\n# Peter\u0027s suggestion here returns a list of what appear to be strings\ncolumns \u003d soup.findAll(\u0027td\u0027, text\u003dpattern, attrs\u003d{\u0027class\u0027 : \u0027pos\u0027})\n# ...but it is actually a BeautifulSoup.NavigableString\nprint type(columns[0])\n#\u003e\u003e \u003cclass \u0027BeautifulSoup.NavigableString\u0027\u003e\n\n# you can reach the tag using one of the convenience attributes seen here\npprint(columns[0].__dict__)\n#\u003e\u003e {\u0027next\u0027: \u003cbr /\u003e,\n#\u003e\u003e  \u0027nextSibling\u0027: \u003cbr /\u003e,\n#\u003e\u003e  \u0027parent\u0027: \u003ctd class\u003d\"pos\"\u003e\\n\n#\u003e\u003e       \"Fixed text:\"\\n\n#\u003e\u003e       \u003cbr /\u003e\\n\n#\u003e\u003e       \u003cstrong\u003etext I am looking for\u003c/strong\u003e\\n\n#\u003e\u003e   \u003c/td\u003e,\n#\u003e\u003e  \u0027previous\u0027: \u003ctd class\u003d\"pos\"\u003e\\n\n#\u003e\u003e       \"Fixed text:\"\\n\n#\u003e\u003e       \u003cbr /\u003e\\n\n#\u003e\u003e       \u003cstrong\u003etext I am looking for\u003c/strong\u003e\\n\n#\u003e\u003e   \u003c/td\u003e,\n#\u003e\u003e  \u0027previousSibling\u0027: None}\n\n# I feel that \u0027parent\u0027 is safer to use than \u0027previous\u0027 based on http://www.crummy.com/software/BeautifulSoup/bs4/doc/#method-names\n# So, if you want to find the \u0027text\u0027 in the \u0027strong\u0027 element...\npprint([t.parent.find(\u0027strong\u0027).text for t in soup.findAll(\u0027td\u0027, text\u003dpattern, attrs\u003d{\u0027class\u0027 : \u0027pos\u0027})])\n#\u003e\u003e [u\u0027text I am looking for\u0027]\n\n# Here is what we have learned:\nprint soup.find(\u0027strong\u0027)\n#\u003e\u003e \u003cstrong\u003esome value\u003c/strong\u003e\nprint soup.find(\u0027strong\u0027, text\u003d\u0027some value\u0027)\n#\u003e\u003e u\u0027some value\u0027\nprint soup.find(\u0027strong\u0027, text\u003d\u0027some value\u0027).parent\n#\u003e\u003e \u003cstrong\u003esome value\u003c/strong\u003e\nprint soup.find(\u0027strong\u0027, text\u003d\u0027some value\u0027) \u003d\u003d soup.find(\u0027strong\u0027)\n#\u003e\u003e False\nprint soup.find(\u0027strong\u0027, text\u003d\u0027some value\u0027) \u003d\u003d soup.find(\u0027strong\u0027).text\n#\u003e\u003e True\nprint soup.find(\u0027strong\u0027, text\u003d\u0027some value\u0027).parent \u003d\u003d soup.find(\u0027strong\u0027)\n#\u003e\u003e True"},{"id":0,"score":0.0,"value":"for el in soup.find_all(\u0027div\u0027, attrs\u003d{\u0027class\u0027: \u0027fm_linkeSpalte\u0027}):\n        print el.get_text()"},{"id":0,"score":0.0,"value":"from bs4 import BeautifulSoup\nhtml \u003d \u0027\u0027\u0027\n\u003ctr\u003e\n  \u003ctd class\u003d\"pos\"\u003e\\n\n      \"Some text:\"\\n\n      \u003cbr\u003e\\n\n      \u003cstrong\u003esome value\u003c/strong\u003e\\n\n  \u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n  \u003ctd class\u003d\"pos\"\u003e\\n\n      \"Fixed text:\"\\n\n      \u003cbr\u003e\\n\n      \u003cstrong\u003etext I am looking for\u003c/strong\u003e\\n\n  \u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n  \u003ctd class\u003d\"pos\"\u003e\\n\n      \"Some other text:\"\\n\n      \u003cbr\u003e\\n\n      \u003cstrong\u003esome other value\u003c/strong\u003e\\n\n  \u003c/td\u003e\n\u003c/tr\u003e\u0027\u0027\u0027\nsoup \u003d bs(html, \u0027lxml\u0027)\nprint(soup.select_one(\u0027td:contains(\"Fixed text:\")\u0027))"},{"id":0,"score":0.0,"value":"soup.find_all(\"td\", string\u003d\"Elsie\")"}]},{"query":"find all bold text from html beautifulsoup","hypotheses":[{"id":0,"score":0.0,"value":"\u003e\u003e\u003e from bs4 import BeautifulSoup\n\u003e\u003e\u003e\n\u003e\u003e\u003e html \u003d \"\"\"\u003cdiv\u003esomething\u003c/div\u003e\n... \u003cdiv\u003esomething else\u003c/div\u003e\n... \u003cdiv class\u003d\u0027magical\u0027\u003ehi there\u003c/div\u003e\n... \u003cp\u003eok\u003c/p\u003e\"\"\"\n\u003e\u003e\u003e soup \u003d BeautifulSoup(html, \"html.parser\")\n\u003e\u003e\u003e [tag.name for tag in soup.find_all()]\n[u\u0027div\u0027, u\u0027div\u0027, u\u0027div\u0027, u\u0027p\u0027]\n\u003e\u003e\u003e [str(tag) for tag in soup.find_all()]\n[\u0027\u003cdiv\u003esomething\u003c/div\u003e\u0027, \u0027\u003cdiv\u003esomething else\u003c/div\u003e\u0027, \u0027\u003cdiv class\u003d\"magical\"\u003ehi there\u003c/div\u003e\u0027, \u0027\u003cp\u003eok\u003c/p\u003e\u0027]"},{"id":0,"score":0.0,"value":"for el in soup.find_all(\u0027div\u0027, attrs\u003d{\u0027class\u0027: \u0027fm_linkeSpalte\u0027}):\n        print el.get_text()"},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e from bs4 import BeautifulSoup\n\u003e\u003e\u003e import calendar\n\u003e\u003e\u003e\n\u003e\u003e\u003e html_cal \u003d calendar.HTMLCalendar().formatmonth(2020, 1)\n\u003e\u003e\u003e set(tag.name for tag in BeautifulSoup(html_cal, \u0027html.parser\u0027).find_all())\n{\u0027table\u0027, \u0027td\u0027, \u0027th\u0027, \u0027tr\u0027}"},{"id":0,"score":0.0,"value":"data\u003d[b.string for b in main_div.findAll(\u0027b\u0027)]"},{"id":0,"score":0.0,"value":"import BeautifulSoup\n\nhtml \u003d \u0027\u0027\u0027\u003cdiv class\u003d\"txt\"\u003e\u003cbr\u003e \n\\nPower: \u003cb\u003eOn\u003c/b\u003e\u003cbr\u003e\u003cbr\u003e\n\\nSource: \u003cb\u003eDVI\u003c/b\u003e\u003cbr\u003e\u003cbr\u003e\n\\nLamp runtime: \u003cb\u003e396\u003c/b\u003e hours\u003cbr\u003e\n\\nLamp remaining: \u003cb\u003e2035\u003c/b\u003e hours\u003cbr\u003e\n\\nTotal operation: \u003cb\u003e2551\u003c/b\u003e hours\u003cbr\u003e\n\\n\u003c/div\u003e\u0027\u0027\u0027\n\nsoup \u003d BeautifulSoup.BeautifulSoup(html)\nbTags \u003d [] \n\nfor i in soup.findAll(\u0027b\u0027):\n    bTags.append(i.text)"},{"id":0,"score":0.0,"value":"[u\u0027On\u0027, u\u0027DVI\u0027, u\u0027396\u0027, u\u00272035\u0027, u\u00272551\u0027]"},{"id":0,"score":0.0,"value":"from bs4 import BeautifulSoup\n\nhtml \u003d \"\"\"\u003cfont color\u003d\"#000000\"\u003eText I want to extract\u003c/font\u003e\"\"\"\n\nsoup \u003d BeautifulSoup(html, \u0027html.parser\u0027)\n\nresult1 \u003d soup.find(\u0027font\u0027).text  # not specifying the color attribute\nresult2 \u003d soup.find(\u0027font\u0027, {\u0027color\u0027:\u0027#000000\u0027}).text  # specifying the color attribute\n\nprint result1  # prints \u0027Text I want to extract\u0027\nprint result2  # prints \u0027Text I want to extract\u0027"}]}],[{"query":"find all red colored text from html `soup`","hypotheses":[{"id":0,"score":0.0,"value":"result \u003d soup.find_all(lambda tag: tag.name \u003d\u003d \u0027div\u0027 and \n                                   tag.get(\u0027class\u0027) \u003d\u003d [\u0027product\u0027])"},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e from bs4 import BeautifulSoup\n\u003e\u003e\u003e text \u003d \"\"\"\n... \u003cbody\u003e\n...     \u003cdiv class\u003d\"product\"\u003eProduct 1\u003c/div\u003e\n...     \u003cdiv class\u003d\"product\"\u003eProduct 2\u003c/div\u003e\n...     \u003cdiv class\u003d\"product special\"\u003eProduct 3\u003c/div\u003e\n...     \u003cdiv class\u003d\"product special\"\u003eProduct 4\u003c/div\u003e\n... \u003c/body\u003e\"\"\"\n\u003e\u003e\u003e soup \u003d BeautifulSoup(text)\n\u003e\u003e\u003e soup.find_all(lambda tag: tag.name \u003d\u003d \u0027div\u0027 and tag.get(\u0027class\u0027) \u003d\u003d [\u0027product\u0027])\n[\u003cdiv class\u003d\"product\"\u003eProduct 1\u003c/div\u003e, \u003cdiv class\u003d\"product\"\u003eProduct 2\u003c/div\u003e]"},{"id":0,"score":0.0,"value":"# The HTML standard defines these attributes as containing a\n# space-separated list of values, not a single value. That is,\n# class\u003d\"foo bar\" means that the \u0027class\u0027 attribute has two values,\n# \u0027foo\u0027 and \u0027bar\u0027, not the single value \u0027foo bar\u0027.  When we\n# encounter one of these attributes, we will parse its value into\n# a list of values if possible. Upon output, the list will be\n# converted back into a string.\ncdata_list_attributes \u003d {\n    \"*\" : [\u0027class\u0027, \u0027accesskey\u0027, \u0027dropzone\u0027],\n    \"a\" : [\u0027rel\u0027, \u0027rev\u0027],\n    \"link\" :  [\u0027rel\u0027, \u0027rev\u0027],\n    \"td\" : [\"headers\"],\n    \"th\" : [\"headers\"],\n    \"td\" : [\"headers\"],\n    \"form\" : [\"accept-charset\"],\n    \"object\" : [\"archive\"],\n\n    # These are HTML5 specific, as are *.accesskey and *.dropzone above.\n    \"area\" : [\"rel\"],\n    \"icon\" : [\"sizes\"],\n    \"iframe\" : [\"sandbox\"],\n    \"output\" : [\"for\"],\n    }"},{"id":0,"score":0.0,"value":"import BeautifulSoup\nimport re\n\ncolumns \u003d soup.findAll(\u0027td\u0027, text \u003d re.compile(\u0027your regex here\u0027), attrs \u003d {\u0027class\u0027 : \u0027pos\u0027})"},{"id":0,"score":0.0,"value":"curl https://gist.githubusercontent.com/RichardBronosky/4060082/raw/test.py | python"},{"id":0,"score":0.0,"value":"# Taken from https://gist.github.com/4060082\nfrom BeautifulSoup import BeautifulSoup\nfrom urllib2 import urlopen\nfrom pprint import pprint\nimport re\n\nsoup \u003d BeautifulSoup(urlopen(\u0027https://gist.githubusercontent.com/RichardBronosky/4060082/raw/test.html\u0027).read())\n# I\u0027m going to assume that Peter knew that re.compile is meant to cache a computation result for a performance benefit. However, I\u0027m going to do that explicitly here to be very clear.\npattern \u003d re.compile(\u0027Fixed text\u0027)\n\n# Peter\u0027s suggestion here returns a list of what appear to be strings\ncolumns \u003d soup.findAll(\u0027td\u0027, text\u003dpattern, attrs\u003d{\u0027class\u0027 : \u0027pos\u0027})\n# ...but it is actually a BeautifulSoup.NavigableString\nprint type(columns[0])\n#\u003e\u003e \u003cclass \u0027BeautifulSoup.NavigableString\u0027\u003e\n\n# you can reach the tag using one of the convenience attributes seen here\npprint(columns[0].__dict__)\n#\u003e\u003e {\u0027next\u0027: \u003cbr /\u003e,\n#\u003e\u003e  \u0027nextSibling\u0027: \u003cbr /\u003e,\n#\u003e\u003e  \u0027parent\u0027: \u003ctd class\u003d\"pos\"\u003e\\n\n#\u003e\u003e       \"Fixed text:\"\\n\n#\u003e\u003e       \u003cbr /\u003e\\n\n#\u003e\u003e       \u003cstrong\u003etext I am looking for\u003c/strong\u003e\\n\n#\u003e\u003e   \u003c/td\u003e,\n#\u003e\u003e  \u0027previous\u0027: \u003ctd class\u003d\"pos\"\u003e\\n\n#\u003e\u003e       \"Fixed text:\"\\n\n#\u003e\u003e       \u003cbr /\u003e\\n\n#\u003e\u003e       \u003cstrong\u003etext I am looking for\u003c/strong\u003e\\n\n#\u003e\u003e   \u003c/td\u003e,\n#\u003e\u003e  \u0027previousSibling\u0027: None}\n\n# I feel that \u0027parent\u0027 is safer to use than \u0027previous\u0027 based on http://www.crummy.com/software/BeautifulSoup/bs4/doc/#method-names\n# So, if you want to find the \u0027text\u0027 in the \u0027strong\u0027 element...\npprint([t.parent.find(\u0027strong\u0027).text for t in soup.findAll(\u0027td\u0027, text\u003dpattern, attrs\u003d{\u0027class\u0027 : \u0027pos\u0027})])\n#\u003e\u003e [u\u0027text I am looking for\u0027]\n\n# Here is what we have learned:\nprint soup.find(\u0027strong\u0027)\n#\u003e\u003e \u003cstrong\u003esome value\u003c/strong\u003e\nprint soup.find(\u0027strong\u0027, text\u003d\u0027some value\u0027)\n#\u003e\u003e u\u0027some value\u0027\nprint soup.find(\u0027strong\u0027, text\u003d\u0027some value\u0027).parent\n#\u003e\u003e \u003cstrong\u003esome value\u003c/strong\u003e\nprint soup.find(\u0027strong\u0027, text\u003d\u0027some value\u0027) \u003d\u003d soup.find(\u0027strong\u0027)\n#\u003e\u003e False\nprint soup.find(\u0027strong\u0027, text\u003d\u0027some value\u0027) \u003d\u003d soup.find(\u0027strong\u0027).text\n#\u003e\u003e True\nprint soup.find(\u0027strong\u0027, text\u003d\u0027some value\u0027).parent \u003d\u003d soup.find(\u0027strong\u0027)\n#\u003e\u003e True"},{"id":0,"score":0.0,"value":"from bs4 import BeautifulSoup\nhtml \u003d \u0027\u0027\u0027\n\u003ctr\u003e\n  \u003ctd class\u003d\"pos\"\u003e\\n\n      \"Some text:\"\\n\n      \u003cbr\u003e\\n\n      \u003cstrong\u003esome value\u003c/strong\u003e\\n\n  \u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n  \u003ctd class\u003d\"pos\"\u003e\\n\n      \"Fixed text:\"\\n\n      \u003cbr\u003e\\n\n      \u003cstrong\u003etext I am looking for\u003c/strong\u003e\\n\n  \u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n  \u003ctd class\u003d\"pos\"\u003e\\n\n      \"Some other text:\"\\n\n      \u003cbr\u003e\\n\n      \u003cstrong\u003esome other value\u003c/strong\u003e\\n\n  \u003c/td\u003e\n\u003c/tr\u003e\u0027\u0027\u0027\nsoup \u003d bs(html, \u0027lxml\u0027)\nprint(soup.select_one(\u0027td:contains(\"Fixed text:\")\u0027))"}]},{"query":"find all red colored text from html beautifulsoup","hypotheses":[{"id":0,"score":0.0,"value":"from bs4 import BeautifulSoup\nfrom bs4.element import Comment\nimport urllib.request\n\n\ndef tag_visible(element):\n    if element.parent.name in [\u0027style\u0027, \u0027script\u0027, \u0027head\u0027, \u0027title\u0027, \u0027meta\u0027, \u0027[document]\u0027]:\n        return False\n    if isinstance(element, Comment):\n        return False\n    return True\n\n\ndef text_from_html(body):\n    soup \u003d BeautifulSoup(body, \u0027html.parser\u0027)\n    texts \u003d soup.findAll(text\u003dTrue)\n    visible_texts \u003d filter(tag_visible, texts)  \n    return u\" \".join(t.strip() for t in visible_texts)\n\nhtml \u003d urllib.request.urlopen(\u0027http://www.nytimes.com/2009/12/21/us/21storm.html\u0027).read()\nprint(text_from_html(html))"},{"id":0,"score":0.0,"value":"for strong_tag in soup.find_all(\u0027strong\u0027):\n    print(strong_tag.text, strong_tag.next_sibling)"},{"id":0,"score":0.0,"value":"from bs4 import BeautifulSoup\n\nhtml \u003d \u0027\u0027\u0027\n\u003cp\u003e\n  \u003cstrong class\u003d\"offender\"\u003eYOB:\u003c/strong\u003e 1987\u003cbr /\u003e\n  \u003cstrong class\u003d\"offender\"\u003eRACE:\u003c/strong\u003e WHITE\u003cbr /\u003e\n  \u003cstrong class\u003d\"offender\"\u003eGENDER:\u003c/strong\u003e FEMALE\u003cbr /\u003e\n  \u003cstrong class\u003d\"offender\"\u003eHEIGHT:\u003c/strong\u003e 5\u002705\u0027\u0027\u003cbr /\u003e\n  \u003cstrong class\u003d\"offender\"\u003eWEIGHT:\u003c/strong\u003e 118\u003cbr /\u003e\n  \u003cstrong class\u003d\"offender\"\u003eEYE COLOR:\u003c/strong\u003e GREEN\u003cbr /\u003e\n  \u003cstrong class\u003d\"offender\"\u003eHAIR COLOR:\u003c/strong\u003e BROWN\u003cbr /\u003e\n\u003c/p\u003e\n\u0027\u0027\u0027\n\nsoup \u003d BeautifulSoup(html)\n\nfor strong_tag in soup.find_all(\u0027strong\u0027):\n    print(strong_tag.text, strong_tag.next_sibling)"},{"id":0,"score":0.0,"value":"YOB:  1987\nRACE:  WHITE\nGENDER:  FEMALE\nHEIGHT:  5\u002705\u0027\u0027\nWEIGHT:  118\nEYE COLOR:  GREEN\nHAIR COLOR:  BROWN"},{"id":0,"score":0.0,"value":"soup.find_all(\"a\", string\u003d\"Elsie\")\n# [\u003ca href\u003d\"http://example.com/elsie\" class\u003d\"sister\" id\u003d\"link1\"\u003eElsie\u003c/a\u003e]"},{"id":0,"score":0.0,"value":"title_tag.string\n# u\u0027The Dormouse\u0027s story\u0027"},{"id":0,"score":0.0,"value":"print(soup.html.string)\n# None"}]}],[{"query":"create a dictionary with keys `random_letters` and values `random_numbers`","hypotheses":[{"id":0,"score":0.0,"value":"random.choice([k for k in d for x in d[k]])"},{"id":0,"score":0.0,"value":"#!/usr/bin/python\n\nimport random\n\ndef select_weighted( d ):\n   # calculate total\n   total \u003d 0\n   for key in d:\n      total \u003d total + len(d[key])\n   accept_prob \u003d float( 1.0 / total )\n\n   # pick a weighted value from d\n   n_seen \u003d 0\n   for key in d:\n      current_key \u003d key\n      for val in d[key]:\n         dice_roll \u003d random.random()\n         accept_prob \u003d float( 1.0 / ( total - n_seen ) )\n         n_seen \u003d n_seen + 1\n         if dice_roll \u003c\u003d accept_prob:\n            return current_key\n\ndict \u003d {\n   \u0027a\u0027: [1, 3, 2],\n   \u0027b\u0027: [6],\n   \u0027c\u0027: [0, 0]\n}\n\ncounts \u003d {}\nfor key in dict:\n   counts[key] \u003d 0\n\nfor s in range(1,100000):\n   k \u003d select_weighted(dict)\n   counts[k] \u003d counts[k] + 1\n\nprint counts"},{"id":0,"score":0.0,"value":"{\u0027a\u0027: 49801, \u0027c\u0027: 33548, \u0027b\u0027: 16650}"},{"id":0,"score":0.0,"value":"{\u0027a\u0027: 0.5, \u0027c\u0027: 0.33333333333333331, \u0027b\u0027: 0.16666666666666666}"},{"id":0,"score":0.0,"value":"def select_weighted(d):\n   offset \u003d random.randint(0, sum(d.itervalues())-1)\n   for k, v in d.iteritems():\n      if offset \u003c v:\n         return k\n      offset -\u003d v"},{"id":0,"score":0.0,"value":"{k: random.random() for k in range(100)}"},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e import string\n\u003e\u003e\u003e dict(zip(string.ascii_lowercase, range(1,27)))\n{\u0027a\u0027: 1, \u0027c\u0027: 3, \u0027b\u0027: 2, \u0027e\u0027: 5, \u0027d\u0027: 4, \u0027g\u0027: 7, \u0027f\u0027: 6, \u0027i\u0027: 9, \u0027h\u0027: 8, \u0027k\u0027: 11, \u0027j\u0027: 10, \u0027m\u0027: 13, \u0027l\u0027: 12, \u0027o\u0027: 15, \u0027n\u0027: 14, \u0027q\u0027: 17, \u0027p\u0027: 16, \u0027s\u0027: 19, \u0027r\u0027: 18, \u0027u\u0027: 21, \u0027t\u0027: 20, \u0027w\u0027: 23, \u0027v\u0027: 22, \u0027y\u0027: 25, \u0027x\u0027: 24, \u0027z\u0027: 26}"}]},{"query":"create a dictionary with keys and values","hypotheses":[{"id":0,"score":0.0,"value":"dic.setdefault(key,[]).append(value)"},{"id":0,"score":0.0,"value":"setdefault(...)\n        D.setdefault(k[,d]) -\u003e D.get(k,d), also set D[k]\u003dd if k not in D"},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e keys \u003d [1,2,3,5,6,7]\n\u003e\u003e\u003e {key: None for key in keys}\n{1: None, 2: None, 3: None, 5: None, 6: None, 7: None}"},{"id":0,"score":0.0,"value":"area_dict \u003d dict(zip(lakes.area, lakes.count))"},{"id":0,"score":0.0,"value":"d \u003d dict.fromkeys(a, 0)"},{"id":0,"score":0.0,"value":"empty_dict \u003d dict.fromkeys([\u0027apple\u0027,\u0027ball\u0027])"},{"id":0,"score":0.0,"value":"empty_dict \u003d {\u0027apple\u0027: None, \u0027ball\u0027: None}"}]}],[{"query":"print `dic` sorted by keys","hypotheses":[{"id":0,"score":0.0,"value":"In [1]: import collections\n\nIn [2]: d \u003d {2:3, 1:89, 4:5, 3:0}\n\nIn [3]: od \u003d collections.OrderedDict(sorted(d.items()))\n\nIn [4]: od\nOut[4]: OrderedDict([(1, 89), (2, 3), (3, 0), (4, 5)])"},{"id":0,"score":0.0,"value":"In [11]: od[1]\nOut[11]: 89\n\nIn [12]: od[3]\nOut[12]: 0\n\nIn [13]: for k, v in od.iteritems(): print k, v\n   ....: \n1 89\n2 3\n3 0\n4 5"},{"id":0,"score":0.0,"value":"In [13]: for k, v in od.items(): print(k, v)\n   ....: \n1 89\n2 3\n3 0\n4 5"},{"id":0,"score":0.0,"value":"mydict \u003d {\u0027carl\u0027:40,\n          \u0027alan\u0027:2,\n          \u0027bob\u0027:1,\n          \u0027danny\u0027:3}\n\nfor key in sorted(mydict):\n    print \"%s: %s\" % (key, mydict[key])"},{"id":0,"score":0.0,"value":"alan: 2\nbob: 1\ncarl: 40\ndanny: 3"},{"id":0,"score":0.0,"value":"keylist \u003d mydict.keys()\nkeylist.sort()\nfor key in keylist:\n    print \"%s: %s\" % (key, mydict[key])"},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e d \u003d {2:3, 1:89, 4:5, 3:0}\n\u003e\u003e\u003e dict(sorted(d.items()))\n{1: 89, 2: 3, 3: 0, 4: 5}"}]},{"query":"print dict sorted by keys","hypotheses":[{"id":0,"score":0.0,"value":"In [1]: import collections\n\nIn [2]: d \u003d {2:3, 1:89, 4:5, 3:0}\n\nIn [3]: od \u003d collections.OrderedDict(sorted(d.items()))\n\nIn [4]: od\nOut[4]: OrderedDict([(1, 89), (2, 3), (3, 0), (4, 5)])"},{"id":0,"score":0.0,"value":"In [11]: od[1]\nOut[11]: 89\n\nIn [12]: od[3]\nOut[12]: 0\n\nIn [13]: for k, v in od.iteritems(): print k, v\n   ....: \n1 89\n2 3\n3 0\n4 5"},{"id":0,"score":0.0,"value":"In [13]: for k, v in od.items(): print(k, v)\n   ....: \n1 89\n2 3\n3 0\n4 5"},{"id":0,"score":0.0,"value":"mydict \u003d {\u0027carl\u0027:40,\n          \u0027alan\u0027:2,\n          \u0027bob\u0027:1,\n          \u0027danny\u0027:3}\n\nfor key in sorted(mydict):\n    print \"%s: %s\" % (key, mydict[key])"},{"id":0,"score":0.0,"value":"alan: 2\nbob: 1\ncarl: 40\ndanny: 3"},{"id":0,"score":0.0,"value":"keylist \u003d mydict.keys()\nkeylist.sort()\nfor key in keylist:\n    print \"%s: %s\" % (key, mydict[key])"},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e d \u003d {2:3, 1:89, 4:5, 3:0}\n\u003e\u003e\u003e dict(sorted(d.items()))\n{1: 89, 2: 3, 3: 0, 4: 5}"}]}],[{"query":"print `dic` keys sorted","hypotheses":[{"id":0,"score":0.0,"value":"In [1]: import collections\n\nIn [2]: d \u003d {2:3, 1:89, 4:5, 3:0}\n\nIn [3]: od \u003d collections.OrderedDict(sorted(d.items()))\n\nIn [4]: od\nOut[4]: OrderedDict([(1, 89), (2, 3), (3, 0), (4, 5)])"},{"id":0,"score":0.0,"value":"In [11]: od[1]\nOut[11]: 89\n\nIn [12]: od[3]\nOut[12]: 0\n\nIn [13]: for k, v in od.iteritems(): print k, v\n   ....: \n1 89\n2 3\n3 0\n4 5"},{"id":0,"score":0.0,"value":"In [13]: for k, v in od.items(): print(k, v)\n   ....: \n1 89\n2 3\n3 0\n4 5"},{"id":0,"score":0.0,"value":"mydict \u003d {\u0027carl\u0027:40,\n          \u0027alan\u0027:2,\n          \u0027bob\u0027:1,\n          \u0027danny\u0027:3}\n\nfor key in sorted(mydict):\n    print \"%s: %s\" % (key, mydict[key])"},{"id":0,"score":0.0,"value":"alan: 2\nbob: 1\ncarl: 40\ndanny: 3"},{"id":0,"score":0.0,"value":"keylist \u003d mydict.keys()\nkeylist.sort()\nfor key in keylist:\n    print \"%s: %s\" % (key, mydict[key])"},{"id":0,"score":0.0,"value":"for key, value in mydic.iteritems() :\n    print key, value"}]},{"query":"print dict keys sorted","hypotheses":[{"id":0,"score":0.0,"value":"In [1]: import collections\n\nIn [2]: d \u003d {2:3, 1:89, 4:5, 3:0}\n\nIn [3]: od \u003d collections.OrderedDict(sorted(d.items()))\n\nIn [4]: od\nOut[4]: OrderedDict([(1, 89), (2, 3), (3, 0), (4, 5)])"},{"id":0,"score":0.0,"value":"In [11]: od[1]\nOut[11]: 89\n\nIn [12]: od[3]\nOut[12]: 0\n\nIn [13]: for k, v in od.iteritems(): print k, v\n   ....: \n1 89\n2 3\n3 0\n4 5"},{"id":0,"score":0.0,"value":"In [13]: for k, v in od.items(): print(k, v)\n   ....: \n1 89\n2 3\n3 0\n4 5"},{"id":0,"score":0.0,"value":"mydict \u003d {\u0027carl\u0027:40,\n          \u0027alan\u0027:2,\n          \u0027bob\u0027:1,\n          \u0027danny\u0027:3}\n\nfor key in sorted(mydict):\n    print \"%s: %s\" % (key, mydict[key])"},{"id":0,"score":0.0,"value":"alan: 2\nbob: 1\ncarl: 40\ndanny: 3"},{"id":0,"score":0.0,"value":"keylist \u003d mydict.keys()\nkeylist.sort()\nfor key in keylist:\n    print \"%s: %s\" % (key, mydict[key])"},{"id":0,"score":0.0,"value":"for key, value in mydic.iteritems() :\n    print key, value"}]}],[{"query":"print `dic` keys on each line","hypotheses":[{"id":0,"score":0.0,"value":"for key, value in mydic.iteritems() :\n    print key, value"},{"id":0,"score":0.0,"value":"for key, value in mydic.items() :\n    print (key, value)"},{"id":0,"score":0.0,"value":"for i in d:\n    print i, d[i]"},{"id":0,"score":0.0,"value":"for k, v in d.iteritems():\n    print k, v"},{"id":0,"score":0.0,"value":"for k, v in d.items():\n    print(k, v)"},{"id":0,"score":0.0,"value":"for x in cars:\n    print (x)\n    for y in cars[x]:\n        print (y,\u0027:\u0027,cars[x][y])"},{"id":0,"score":0.0,"value":"A\ncolor : 2\nspeed : 70\nB\ncolor : 3\nspeed : 60"}]},{"query":"print dict keys on each line","hypotheses":[{"id":0,"score":0.0,"value":"for key, value in mydic.iteritems() :\n    print key, value"},{"id":0,"score":0.0,"value":"for key, value in mydic.items() :\n    print (key, value)"},{"id":0,"score":0.0,"value":"for i in d:\n    print i, d[i]"},{"id":0,"score":0.0,"value":"for k, v in d.iteritems():\n    print k, v"},{"id":0,"score":0.0,"value":"for k, v in d.items():\n    print(k, v)"},{"id":0,"score":0.0,"value":"for x in cars:\n    print (x)\n    for y in cars[x]:\n        print (y,\u0027:\u0027,cars[x][y])"},{"id":0,"score":0.0,"value":"A\ncolor : 2\nspeed : 70\nB\ncolor : 3\nspeed : 60"}]}],[{"query":"read \"data.csv\" file","hypotheses":[{"id":0,"score":0.0,"value":"with open(\u0027some.csv\u0027, newline\u003d\u0027\u0027) as f:\n  reader \u003d csv.reader(f)\n  row1 \u003d next(reader)  # gets the first line\n  # now do something here \n  # if first row is the header, then you can do one more next() to get the next row:\n  # row2 \u003d next(f)"},{"id":0,"score":0.0,"value":"with open(\u0027some.csv\u0027, newline\u003d\u0027\u0027) as f:\n  reader \u003d csv.reader(f)\n  for row in reader:\n    # do something here with `row`\n    break"},{"id":0,"score":0.0,"value":"Data \u003d namedtuple(\"Data\", next(reader))"},{"id":0,"score":0.0,"value":"next(reader)"},{"id":0,"score":0.0,"value":"import csv\nfrom collections import namedtuple\nfrom itertools import imap\n\nwith open(\"data_file.txt\", mode\u003d\"rb\") as infile:\n    reader \u003d csv.reader(infile)\n    Data \u003d namedtuple(\"Data\", next(reader))  # get names from column headers\n    for data in imap(Data._make, reader):\n        print data.foo\n        # ...further processing of a line..."},{"id":0,"score":0.0,"value":"import csv\nfrom collections import namedtuple\n\nwith open(\"data_file.txt\", newline\u003d\"\") as infile:\n    reader \u003d csv.reader(infile)\n    Data \u003d namedtuple(\"Data\", next(reader))  # get names from column headers\n    for data in map(Data._make, reader):\n        print(data.foo)\n        # ...further processing of a line..."},{"id":0,"score":0.0,"value":"with open(\u0027some.csv\u0027, newline\u003d\u0027\u0027) as f:\n  csv_reader \u003d csv.reader(f)\n  csv_headings \u003d next(csv_reader)\n  first_line \u003d next(csv_reader)"}]},{"query":"read csv file","hypotheses":[{"id":0,"score":0.0,"value":"import csv\n\ndef getstuff(filename, criterion):\n    with open(filename, \"rb\") as csvfile:\n        datareader \u003d csv.reader(csvfile)\n        yield next(datareader)  # yield the header row\n        count \u003d 0\n        for row in datareader:\n            if row[3] \u003d\u003d criterion:\n                yield row\n                count +\u003d 1\n            elif count:\n                # done when having read a consecutive series of rows \n                return"},{"id":0,"score":0.0,"value":"import csv\nfrom itertools import dropwhile, takewhile\n\ndef getstuff(filename, criterion):\n    with open(filename, \"rb\") as csvfile:\n        datareader \u003d csv.reader(csvfile)\n        yield next(datareader)  # yield the header row\n        # first row, plus any subsequent rows that match, then stop\n        # reading altogether\n        # Python 2: use `for row in takewhile(...): yield row` instead\n        # instead of `yield from takewhile(...)`.\n        yield from takewhile(\n            lambda r: r[3] \u003d\u003d criterion,\n            dropwhile(lambda r: r[3] !\u003d criterion, datareader))\n        return"},{"id":0,"score":0.0,"value":"def getdata(filename, criteria):\n    for criterion in criteria:\n        for row in getstuff(filename, criterion):\n            yield row"},{"id":0,"score":0.0,"value":"for row in getdata(somefilename, sequence_of_criteria):\n    # process row"},{"id":0,"score":0.0,"value":"import csv\n\nwith open(\"test.csv\", \"r\") as f:\n    reader \u003d csv.reader(f, delimiter\u003d\"\\t\")\n    for i, line in enumerate(reader):\n        print \u0027line[{}] \u003d {}\u0027.format(i, line)"},{"id":0,"score":0.0,"value":"line[0] \u003d [\u0027Year:\u0027, \u0027Dec:\u0027, \u0027Jan:\u0027]\nline[1] \u003d [\u00271\u0027, \u002750\u0027, \u002760\u0027]\nline[2] \u003d [\u00272\u0027, \u002725\u0027, \u002750\u0027]\nline[3] \u003d [\u00273\u0027, \u002730\u0027, \u002730\u0027]\nline[4] \u003d [\u00274\u0027, \u002740\u0027, \u002720\u0027]\nline[5] \u003d [\u00275\u0027, \u002710\u0027, \u002710\u0027]"},{"id":0,"score":0.0,"value":"import pandas as pd\nimport zipfile\n\nzf \u003d zipfile.ZipFile(\u0027C:/Users/Desktop/THEZIPFILE.zip\u0027) \ndf \u003d pd.read_csv(zf.open(\u0027intfile.csv\u0027))"}]}],[{"query":"read csv file \"data.csv\"","hypotheses":[{"id":0,"score":0.0,"value":"with open(\u0027some.csv\u0027, newline\u003d\u0027\u0027) as f:\n  reader \u003d csv.reader(f)\n  row1 \u003d next(reader)  # gets the first line\n  # now do something here \n  # if first row is the header, then you can do one more next() to get the next row:\n  # row2 \u003d next(f)"},{"id":0,"score":0.0,"value":"with open(\u0027some.csv\u0027, newline\u003d\u0027\u0027) as f:\n  reader \u003d csv.reader(f)\n  for row in reader:\n    # do something here with `row`\n    break"},{"id":0,"score":0.0,"value":"Data \u003d namedtuple(\"Data\", next(reader))"},{"id":0,"score":0.0,"value":"next(reader)"},{"id":0,"score":0.0,"value":"import csv\nfrom collections import namedtuple\nfrom itertools import imap\n\nwith open(\"data_file.txt\", mode\u003d\"rb\") as infile:\n    reader \u003d csv.reader(infile)\n    Data \u003d namedtuple(\"Data\", next(reader))  # get names from column headers\n    for data in imap(Data._make, reader):\n        print data.foo\n        # ...further processing of a line..."},{"id":0,"score":0.0,"value":"import csv\nfrom collections import namedtuple\n\nwith open(\"data_file.txt\", newline\u003d\"\") as infile:\n    reader \u003d csv.reader(infile)\n    Data \u003d namedtuple(\"Data\", next(reader))  # get names from column headers\n    for data in map(Data._make, reader):\n        print(data.foo)\n        # ...further processing of a line..."},{"id":0,"score":0.0,"value":"with open(\u0027some.csv\u0027, newline\u003d\u0027\u0027) as f:\n  csv_reader \u003d csv.reader(f)\n  csv_headings \u003d next(csv_reader)\n  first_line \u003d next(csv_reader)"}]},{"query":"read csv file","hypotheses":[{"id":0,"score":0.0,"value":"import csv\n\ndef getstuff(filename, criterion):\n    with open(filename, \"rb\") as csvfile:\n        datareader \u003d csv.reader(csvfile)\n        yield next(datareader)  # yield the header row\n        count \u003d 0\n        for row in datareader:\n            if row[3] \u003d\u003d criterion:\n                yield row\n                count +\u003d 1\n            elif count:\n                # done when having read a consecutive series of rows \n                return"},{"id":0,"score":0.0,"value":"import csv\nfrom itertools import dropwhile, takewhile\n\ndef getstuff(filename, criterion):\n    with open(filename, \"rb\") as csvfile:\n        datareader \u003d csv.reader(csvfile)\n        yield next(datareader)  # yield the header row\n        # first row, plus any subsequent rows that match, then stop\n        # reading altogether\n        # Python 2: use `for row in takewhile(...): yield row` instead\n        # instead of `yield from takewhile(...)`.\n        yield from takewhile(\n            lambda r: r[3] \u003d\u003d criterion,\n            dropwhile(lambda r: r[3] !\u003d criterion, datareader))\n        return"},{"id":0,"score":0.0,"value":"def getdata(filename, criteria):\n    for criterion in criteria:\n        for row in getstuff(filename, criterion):\n            yield row"},{"id":0,"score":0.0,"value":"for row in getdata(somefilename, sequence_of_criteria):\n    # process row"},{"id":0,"score":0.0,"value":"import csv\n\nwith open(\"test.csv\", \"r\") as f:\n    reader \u003d csv.reader(f, delimiter\u003d\"\\t\")\n    for i, line in enumerate(reader):\n        print \u0027line[{}] \u003d {}\u0027.format(i, line)"},{"id":0,"score":0.0,"value":"line[0] \u003d [\u0027Year:\u0027, \u0027Dec:\u0027, \u0027Jan:\u0027]\nline[1] \u003d [\u00271\u0027, \u002750\u0027, \u002760\u0027]\nline[2] \u003d [\u00272\u0027, \u002725\u0027, \u002750\u0027]\nline[3] \u003d [\u00273\u0027, \u002730\u0027, \u002730\u0027]\nline[4] \u003d [\u00274\u0027, \u002740\u0027, \u002720\u0027]\nline[5] \u003d [\u00275\u0027, \u002710\u0027, \u002710\u0027]"},{"id":0,"score":0.0,"value":"import pandas as pd\nimport zipfile\n\nzf \u003d zipfile.ZipFile(\u0027C:/Users/Desktop/THEZIPFILE.zip\u0027) \ndf \u003d pd.read_csv(zf.open(\u0027intfile.csv\u0027))"}]}],[{"query":"delete first and last column of `df`","hypotheses":[{"id":0,"score":0.0,"value":"df \u003d df.drop(\u0027column_name\u0027, 1)"},{"id":0,"score":0.0,"value":"df.drop(\u0027column_name\u0027, axis\u003d1, inplace\u003dTrue)"},{"id":0,"score":0.0,"value":"df \u003d df.drop(df.columns[[0, 1, 3]], axis\u003d1)  # df.columns is zero-based pd.Index"},{"id":0,"score":0.0,"value":"df.drop([\u0027column_nameA\u0027, \u0027column_nameB\u0027], axis\u003d1, inplace\u003dTrue)"},{"id":0,"score":0.0,"value":"del df[\u0027column_name\u0027]"},{"id":0,"score":0.0,"value":"columns \u003d [\u0027Col1\u0027, \u0027Col2\u0027, ...]\ndf.drop(columns, inplace\u003dTrue, axis\u003d1)"},{"id":0,"score":0.0,"value":"df \u003d df.drop(columns, axis\u003d1)"}]},{"query":"delete first and last column of dataframe","hypotheses":[{"id":0,"score":0.0,"value":"df \u003d df.drop(\u0027column_name\u0027, 1)"},{"id":0,"score":0.0,"value":"df.drop(\u0027column_name\u0027, axis\u003d1, inplace\u003dTrue)"},{"id":0,"score":0.0,"value":"df \u003d df.drop(df.columns[[0, 1, 3]], axis\u003d1)  # df.columns is zero-based pd.Index"},{"id":0,"score":0.0,"value":"df.drop([\u0027column_nameA\u0027, \u0027column_nameB\u0027], axis\u003d1, inplace\u003dTrue)"},{"id":0,"score":0.0,"value":"del df[\u0027column_name\u0027]"},{"id":0,"score":0.0,"value":"columns \u003d [\u0027Col1\u0027, \u0027Col2\u0027, ...]\ndf.drop(columns, inplace\u003dTrue, axis\u003d1)"},{"id":0,"score":0.0,"value":"df \u003d df.drop(columns, axis\u003d1)"}]}],[{"query":"write output to csv file \"output.csv\"","hypotheses":[{"id":0,"score":0.0,"value":"p \u003d []\nfor row in reader:\n    ...\n    p.append(row[:5])"},{"id":0,"score":0.0,"value":"with open(\u0027names.csv\u0027, \u0027wb\u0027) as ofile:\n    writer \u003d csv.writer(ofile)\n    for row in p:\n        writer.writerow(row)"},{"id":0,"score":0.0,"value":"with open(\u0027names.csv\u0027, \u0027wb\u0027) as ofile:\n    writer \u003d csv.writer(ofile)\n    writer.writerow([row[0], row[1].lstrip(\u0027-\u0027), row[2].lstrip(\u00270\u0027), row[3].lstrip(\u00270\u0027), row[4]])\n    for row in p[1:]:\n        writer.writerow(row)"},{"id":0,"score":0.0,"value":"with open(file_name,\u0027rb\u0027) as f, open(\u0027names.csv\u0027, \u0027wb\u0027) as ofile:\n    writer \u003d csv.writer(ofile)\n    ...\n    for row in reader:\n        ...\n        writer.writerow(row[:5])"},{"id":0,"score":0.0,"value":"writer \u003d csv.writer(f)\n...\nwriter.writerow([int(x) for x in row])  # Note difference in parameter format"},{"id":0,"score":0.0,"value":"with open(\u0027output.csv\u0027, \u0027w\u0027) as csvfile:\n    csvwriter \u003d csv.writer(csvfile)\n    for row in result.items():\n        csvwriter.writerow(row)"},{"id":0,"score":0.0,"value":"#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nimport csv\nimport sys\n\n# Use with statement to properly close files\n# Use newline\u003d\u0027\u0027 which is the right option for Python 3.x\nwith open(sys.argv[1], \u0027r\u0027, newline\u003d\u0027\u0027) as fin, open(sys.argv[2], \u0027w\u0027, newline\u003d\u0027\u0027) as fout:\n    reader \u003d csv.reader(fin)\n    # You may need to redefine the dialect for some version of Excel that \n    # split cells on semicolons (for _Comma_ Separated Values, yes...)\n    writer \u003d csv.writer(fout, dialect\u003d\"excel\")\n    for row in reader:\n        # Write as reading, let the OS do the caching alone\n        # Process the data as it comes in a generator, checking all cells\n        # in a row. If cell is empty, the or will return \"0\"\n        # Keep strings all the time: if it\u0027s not an int it would fail\n        # Converting to int will force the writer to convert it back to str\n        # anwway, and Excel doesn\u0027t make any difference when loading.\n        writer.writerow( cell or \"0\" for cell in row )"}]},{"query":"write output to csv file","hypotheses":[{"id":0,"score":0.0,"value":"import numpy as np\nnp.savetxt(\u0027data.csv\u0027, (col1_array, col2_array, col3_array), delimiter\u003d\u0027,\u0027)"},{"id":0,"score":0.0,"value":"names \u003d [\u0027Player Name\u0027, \u0027Foo\u0027, \u0027Bar\u0027]\nscores \u003d [\u0027Score\u0027, 250, 500]"},{"id":0,"score":0.0,"value":"np.savetxt(\u0027scores.csv\u0027, [p for p in zip(names, scores)], delimiter\u003d\u0027,\u0027, fmt\u003d\u0027%s\u0027)"},{"id":0,"score":0.0,"value":"Player Name,Score\nFoo,250\nBar,500"},{"id":0,"score":0.0,"value":"import csv\n\nwith open(\u0027thefile.csv\u0027, \u0027rb\u0027) as f:\n  data \u003d list(csv.reader(f))\n\nimport collections\ncounter \u003d collections.defaultdict(int)\nfor row in data:\n    counter[row[0]] +\u003d 1\n\n\nwriter \u003d csv.writer(open(\"/path/to/my/csv/file\", \u0027w\u0027))\nfor row in data:\n    if counter[row[0]] \u003e\u003d 4:\n        writer.writerow(row)"},{"id":0,"score":0.0,"value":"a.writerow(line)"},{"id":0,"score":0.0,"value":"row \u003d cursor.fetchall()\n    with open(\u0027data.csv\u0027, \u0027w\u0027, newline\u003d\u0027\u0027) as fp:\n            a \u003d csv.writer(fp, delimiter\u003d\u0027,\u0027)\n            a.writerows(row)"}]}],[{"query":"write `output` to csv file","hypotheses":[{"id":0,"score":0.0,"value":"import numpy as np\nnp.savetxt(\u0027data.csv\u0027, (col1_array, col2_array, col3_array), delimiter\u003d\u0027,\u0027)"},{"id":0,"score":0.0,"value":"names \u003d [\u0027Player Name\u0027, \u0027Foo\u0027, \u0027Bar\u0027]\nscores \u003d [\u0027Score\u0027, 250, 500]"},{"id":0,"score":0.0,"value":"np.savetxt(\u0027scores.csv\u0027, [p for p in zip(names, scores)], delimiter\u003d\u0027,\u0027, fmt\u003d\u0027%s\u0027)"},{"id":0,"score":0.0,"value":"Player Name,Score\nFoo,250\nBar,500"},{"id":0,"score":0.0,"value":"import csv\n\nwith open(\u0027thefile.csv\u0027, \u0027rb\u0027) as f:\n  data \u003d list(csv.reader(f))\n\nimport collections\ncounter \u003d collections.defaultdict(int)\nfor row in data:\n    counter[row[0]] +\u003d 1\n\n\nwriter \u003d csv.writer(open(\"/path/to/my/csv/file\", \u0027w\u0027))\nfor row in data:\n    if counter[row[0]] \u003e\u003d 4:\n        writer.writerow(row)"},{"id":0,"score":0.0,"value":"a.writerow(line)"},{"id":0,"score":0.0,"value":"row \u003d cursor.fetchall()\n    with open(\u0027data.csv\u0027, \u0027w\u0027, newline\u003d\u0027\u0027) as fp:\n            a \u003d csv.writer(fp, delimiter\u003d\u0027,\u0027)\n            a.writerows(row)"}]},{"query":"write output csv file","hypotheses":[{"id":0,"score":0.0,"value":"a.writerow(line)"},{"id":0,"score":0.0,"value":"row \u003d cursor.fetchall()\n    with open(\u0027data.csv\u0027, \u0027w\u0027, newline\u003d\u0027\u0027) as fp:\n            a \u003d csv.writer(fp, delimiter\u003d\u0027,\u0027)\n            a.writerows(row)"},{"id":0,"score":0.0,"value":"row \u003d cursor.fetchall()\n    with open(\u0027data.csv\u0027, \u0027w\u0027) as fp:\n            a \u003d csv.writer(fp, delimiter\u003d\u0027,\u0027)\n            a.writerows(row)"},{"id":0,"score":0.0,"value":"resultFile \u003d open(\"out.csv\", \"w\", newline\u003d\u0027\u0027)"},{"id":0,"score":0.0,"value":"with open(\"input_1.csv\", \"r\") as f1, \\\n     open(\"out.csv\", \"w\", newline\u003d\u0027\u0027) as resultFile:\n    wr \u003d csv.writer(resultFile, dialect\u003d\u0027excel\u0027)\n    for var in f1:\n        wr.writerow([var.rstrip(\u0027\\n\u0027)])"},{"id":0,"score":0.0,"value":"import csv\nimport random\n\ndata \u003d [random.randint(1, 10) for _ in range(10)]\n\nwith open(\u0027data.csv\u0027, \u0027w\u0027) as f:\n    writer \u003d csv.writer(f)\n    writer.writerow(data)"},{"id":0,"score":0.0,"value":"9,3,7,4,1,3,7,8,1,3"}]}],[{"query":"search for pattern \"%d%d-%d%d\" in `file`","hypotheses":[{"id":0,"score":0.0,"value":"\u003e\u003e\u003e p \u003d re.compile(\"name (.*) is valid\")\n\u003e\u003e\u003e result \u003d p.search(s)\n\u003e\u003e\u003e result\n\u003c_sre.SRE_Match object at 0x10555e738\u003e\n\u003e\u003e\u003e result.group(1)     # group(1) will return the 1st capture (stuff within the brackets).\n                        # group(0) will returned the entire matched text.\n\u0027my_user_name\u0027"},{"id":0,"score":0.0,"value":"p \u003d re.compile(\u0027name (.*) is valid\u0027)"},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e import re\n\u003e\u003e\u003e p \u003d re.compile(\u0027name (.*) is valid\u0027)\n\u003e\u003e\u003e s \u003d \"\"\"\n... someline abc\n... someother line\n... name my_user_name is valid\n... some more lines\"\"\"\n\u003e\u003e\u003e p.findall(s)\n[\u0027my_user_name\u0027]"},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e p.search(s)   #gives a match object or None if no match is found\n\u003c_sre.SRE_Match object at 0xf5c60\u003e\n\u003e\u003e\u003e p.search(s).group() #entire string that matched\n\u0027name my_user_name is valid\u0027\n\u003e\u003e\u003e p.search(s).group(1) #first group that match in the string that matched\n\u0027my_user_name\u0027"},{"id":0,"score":0.0,"value":"p \u003d re.compile(\u0027name (.*?) is valid\u0027)"},{"id":0,"score":0.0,"value":"re.findall(r\u0027^PY (\\d\\d\\d\\d)\u0027, wosrecords, flags\u003dre.MULTILINE)"},{"id":0,"score":0.0,"value":"import re\ns \u003d #that big string\n# the parenthesis create a group with what was matched\n# and \u0027\\w\u0027 matches only alphanumeric charactes\np \u003d re.compile(\"name +(\\w+) +is valid\", re.flags)\n# use search(), so the match doesn\u0027t have to happen \n# at the beginning of \"big string\"\nm \u003d p.search(s)\n# search() returns a Match object with information about what was matched\nif m:\n    name \u003d m.group(1)\nelse:\n    raise Exception(\u0027name not found\u0027)"}]},{"query":"search for pattern in file","hypotheses":[{"id":0,"score":0.0,"value":"import glob\n\njpgFilenamesList \u003d glob.glob(\u0027145592*.jpg\u0027)"},{"id":0,"score":0.0,"value":"files \u003d [f for f in os.listdir(\u0027.\u0027) if re.match(r\u0027[0-9]+.*\\.jpg\u0027, f)]"},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e import glob\n\u003e\u003e\u003e glob.glob(\u0027./[0-9].*\u0027)\n[\u0027./1.gif\u0027, \u0027./2.txt\u0027]\n\u003e\u003e\u003e glob.glob(\u0027*.gif\u0027)\n[\u00271.gif\u0027, \u0027card.gif\u0027]\n\u003e\u003e\u003e glob.glob(\u0027?.gif\u0027)\n[\u00271.gif\u0027]"},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e import glob\n\u003e\u003e\u003e glob.glob(\u0027*.gif\u0027)\n[\u0027card.gif\u0027]\n\u003e\u003e\u003e glob.glob(\u0027.c*\u0027)\n[\u0027.card.gif\u0027]"},{"id":0,"score":0.0,"value":"import os\nrelevant_path \u003d \"[path to folder]\"\nincluded_extensions \u003d [\u0027jpg\u0027,\u0027jpeg\u0027, \u0027bmp\u0027, \u0027png\u0027, \u0027gif\u0027]\nfile_names \u003d [fn for fn in os.listdir(relevant_path)\n              if any(fn.endswith(ext) for ext in included_extensions)]"},{"id":0,"score":0.0,"value":"import re\npattern \u003d re.compile(\"\u003c(\\d{4,5})\u003e\")\n\nfor i, line in enumerate(open(\u0027test.txt\u0027)):\n    for match in re.finditer(pattern, line):\n        print \u0027Found on line %s: %s\u0027 % (i+1, match.group())"},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e import os, fnmatch\n\u003e\u003e\u003e fnmatch.filter(os.listdir(\u0027.\u0027), \u0027*.py\u0027)\n[\u0027manage.py\u0027]"}]}],[{"query":"copy file from `src_path` to `dest_path`","hypotheses":[{"id":0,"score":0.0,"value":"source_path \u003d r\"\\\\mynetworkshare\"\ndest_path \u003d r\"C:\\TEMP\"\nfile_name \u003d \"\\\\myfile.txt\"\n\nshutil.copyfile(source_path + file_name, dest_path + file_name)"},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e r\"\\\\myfile\" \u003d\u003d \"\\\\\\\\myfile\"\nTrue"},{"id":0,"score":0.0,"value":"source_path \u003d r\"\\\\mynetworkshare\"\ndest_path \u003d r\"C:\\TEMP\"\nfilename \u003d r\"\\my_file.txt\"\n\nshutil.copyfile(source_path + filename, dest_path + filename)"},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e source_path \u003d r\"\\\\mynetworkshare\"\n\u003e\u003e\u003e dest_path \u003d r\"C:\\TEMP\"\n\u003e\u003e\u003e filename \u003d r\"\\my_file.txt\"\n\u003e\u003e\u003e print (source_path + filename)\n\\\\mynetworkshare\\my_file.txt\n\u003e\u003e\u003e print (dest_path + filename)\nC:\\TEMP\\my_file.txt"},{"id":0,"score":0.0,"value":"if not os.path.exists(source_path) or not os.path.exists(dest_path):"},{"id":0,"score":0.0,"value":"if f.endswith(file_ending):\n    new_path \u003d os.path.join(dest_path, date, )\n    src_path \u003d os.path.join(source_path, f)\n    if not os.path.exists(new_path): # create the folders if they dont already exists\n        os.makedirs(new_path)\n    if not os.path.exists(os.path.join(new_path,f)):\n        print(\"copying \" + src_path)\n        shutil.copy(src_path, os.path.join(new_path,f))\n    else:\n        print( src_path + \"  already copied\")"},{"id":0,"score":0.0,"value":"source_path \u003d \"//mynetworkshare\"\ndest_path \u003d \"C:/TEMP\"\nfile_name \u003d \"/myfile.txt\""}]},{"query":"copy file from source path to destination path","hypotheses":[{"id":0,"score":0.0,"value":"from shutil import copyfile\ncopyfile(src, dst)"},{"id":0,"score":0.0,"value":"import shutil\nshutil.copy2(\u0027/src/dir/file.ext\u0027, \u0027/dst/dir/newname.ext\u0027) # complete target filename given\nshutil.copy2(\u0027/src/file.ext\u0027, \u0027/dst/dir\u0027) # target filename is /dst/dir/file.ext"},{"id":0,"score":0.0,"value":"import shutil\nshutil.copy(\u0027/etc/hostname\u0027, \u0027/var/tmp/testhostname\u0027)"},{"id":0,"score":0.0,"value":"import os\nimport shutil\nimport subprocess"},{"id":0,"score":0.0,"value":"shutil.copyfile(src_file, dest_file, *, follow_symlinks\u003dTrue)\n\n# example    \nshutil.copyfile(\u0027source.txt\u0027, \u0027destination.txt\u0027)"},{"id":0,"score":0.0,"value":"shutil.copy(src_file, dest_file, *, follow_symlinks\u003dTrue)\n\n# example\nshutil.copy(\u0027source.txt\u0027, \u0027destination.txt\u0027)"},{"id":0,"score":0.0,"value":"shutil.copy2(src_file, dest_file, *, follow_symlinks\u003dTrue)\n\n# example\nshutil.copy2(\u0027source.txt\u0027, \u0027destination.txt\u0027)"}]}],[{"query":"check if `file` is a directory","hypotheses":[{"id":0,"score":0.0,"value":"os.path.isfile(\"bob.txt\") # Does bob.txt exist?  Is it a file, or a directory?\nos.path.isdir(\"bob\")"},{"id":0,"score":0.0,"value":"import os\nos.path.isdir(d)"},{"id":0,"score":0.0,"value":"for fname in os.listdir(\u0027.\u0027):\n    if fname.endswith(\u0027.true\u0027):\n        # do stuff on the file\n        break\nelse:\n    # do stuff if a file .true doesn\u0027t exist."},{"id":0,"score":0.0,"value":"if not any(fname.endswith(\u0027.true\u0027) for fname in os.listdir(\u0027.\u0027)):\n    # do stuff if a file .true doesn\u0027t exist"},{"id":0,"score":0.0,"value":"import glob\n# stuff\nif not glob.glob(\u0027*.true\u0027)`:\n    # do stuff if no file ending in .true exists"},{"id":0,"score":0.0,"value":"import os, sys\nfrom stat import *\n\ndef walktree(top, callback):\n    \u0027\u0027\u0027recursively descend the directory tree rooted at top,\n       calling the callback function for each regular file\u0027\u0027\u0027\n\n    for f in os.listdir(top):\n        pathname \u003d os.path.join(top, f)\n        mode \u003d os.stat(pathname)[ST_MODE]\n        if S_ISDIR(mode):\n            # It\u0027s a directory, recurse into it\n            walktree(pathname, callback)\n        elif S_ISREG(mode):\n            # It\u0027s a file, call the callback function\n            callback(pathname)\n        else:\n            # Unknown file type, print a message\n            print \u0027Skipping %s\u0027 % pathname\n\ndef visitfile(file):\n    print \u0027visiting\u0027, file\n\nif __name__ \u003d\u003d \u0027__main__\u0027:\n    walktree(sys.argv[1], visitfile)"},{"id":0,"score":0.0,"value":"import os\nif any(File.endswith(\".true\") for File in os.listdir(\".\")):\n    print(\"true\")\nelse:\n    print(\"false\")"}]},{"query":"check if is a directory","hypotheses":[{"id":0,"score":0.0,"value":"\u003e\u003e\u003e import os\n\u003e\u003e\u003e os.path.isdir(\u0027new_folder\u0027)\nTrue\n\u003e\u003e\u003e os.path.exists(os.path.join(os.getcwd(), \u0027new_folder\u0027, \u0027file.txt\u0027))\nFalse"},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e from pathlib import Path\n \u003e\u003e\u003e Path(\u0027new_folder\u0027).is_dir()\n True\n \u003e\u003e\u003e (Path.cwd() / \u0027new_folder\u0027 / \u0027file.txt\u0027).exists()\n False"},{"id":0,"score":0.0,"value":"os.path.isfile(\"bob.txt\") # Does bob.txt exist?  Is it a file, or a directory?\nos.path.isdir(\"bob\")"},{"id":0,"score":0.0,"value":"In [1]: from pathlib import Path\n\nIn [2]: p \u003d Path(\u0027/usr\u0027)\n\nIn [3]: p.exists()\nOut[3]: True\n\nIn [4]: p.is_dir()\nOut[4]: True"},{"id":0,"score":0.0,"value":"In [5]: q \u003d p / \u0027bin\u0027 / \u0027vim\u0027\n\nIn [6]: q\nOut[6]: PosixPath(\u0027/usr/bin/vim\u0027) \n\nIn [7]: q.exists()\nOut[7]: True\n\nIn [8]: q.is_dir()\nOut[8]: False"},{"id":0,"score":0.0,"value":"import os\nos.path.isdir(d)"},{"id":0,"score":0.0,"value":"from pathlib import Path\n\nroot \u003d Path(\u0027/path/to/root\u0027)\nchild \u003d root / \u0027some\u0027 / \u0027child\u0027 / \u0027dir\u0027\nother \u003d Path(\u0027/some/other/path\u0027)"}]}],[{"query":"write `final_data` to csv file \"price.csv\"","hypotheses":[{"id":0,"score":0.0,"value":"import csv\n\ndate_reader \u003d csv.reader(open(\u0027Date.csv\u0027, \u0027rb\u0027))\nprice_reader \u003d csv.reader(open(\u0027Price.csv\u0027, \u0027rb\u0027))\nwriter \u003d csv.writer(open(\u0027NewData.csv\u0027, \u0027wb\u0027))\nfor date_row in date_reader:\n    price_row \u003d price_reader.next()\n    writer.writerow(date_row + [price_row[1]])"},{"id":0,"score":0.0,"value":"ID, Date, Price\n0,\"Jan 22, 2016\",27.89\n1,\"Jan 21, 2016\",26.80\n2,\"Jan 20, 2016\",26.78\n3,\"Jan 19, 2016\",26.00"},{"id":0,"score":0.0,"value":"with open(\u0027C:/Users/User/OneDrive/Documents/Date.csv\u0027) as file1, \\\n     open(\u0027C:/Users/User/OneDrive/Documents/Price.csv\u0027) as file2, \\\n     open(\u0027C:/Users/User/OneDrive/Documents/Output.csv\u0027, \u0027w\u0027) as output:\n    reader1 \u003d csv.DictReader(file1)\n    reader2 \u003d csv.DictReader(file2)\n    writer \u003d csv.DictWriter(output, [\u0027ID\u0027, \u0027Date\u0027, \u0027Price\u0027])\n    writer.writeheader()  # Optional if you want the header\n\n    for row1, row2 in zip(reader1, reader2):\n        row1.update(row2)\n        writer.writerow(row1)"},{"id":0,"score":0.0,"value":"import pandas as pd\nfile1 \u003d pd.read_csv(\u0027Data.csv\u0027, index_col\u003d\u0027ID\u0027)\nfile2 \u003d pd.read_csv(\u0027Price.csv\u0027, index_col\u003d\u0027ID\u0027)\npd.concat([file1,file2], axis\u003d1).to_csv(\u0027Output.csv\u0027)"},{"id":0,"score":0.0,"value":"ID,Date,Price\n0,\"Jan 22, 2016\",27.89\n1,\"Jan 21, 2016\",26.80\n2,\"Jan 20, 2016\",26.78\n3,\"Jan 19, 2016\",26.00"},{"id":0,"score":0.0,"value":"for item in items:\n    csv_writer.writerow([item[\u0027name\u0027], item[\u0027total_price\u0027]])\n    csv_writer.writerows([\u0027\u0027, p] for p in item[\u0027price\u0027])"},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e import csv\n\u003e\u003e\u003e from cStringIO import StringIO\n\u003e\u003e\u003e items \u003d [{\u0027name\u0027: \u0027foo\u0027, \u0027total_price\u0027 : 15, \u0027price\u0027: [4, 2, 4, 5]}, {\u0027name\u0027: \u0027bar\u0027, \u0027total_price\u0027 : 10, \u0027price\u0027: [5, 2, 3]}]\n\u003e\u003e\u003e f \u003d StringIO()\n\u003e\u003e\u003e csv_writer \u003d csv.writer(f)\n\u003e\u003e\u003e for item in items:\n...     csv_writer.writerow([item[\u0027name\u0027], item[\u0027total_price\u0027]])\n...     csv_writer.writerows([\u0027\u0027, p] for p in item[\u0027price\u0027])\n... \n\u003e\u003e\u003e print f.getvalue()\nfoo,15\n,4\n,2\n,4\n,5\nbar,10\n,5\n,2\n,3"}]},{"query":"write to csv file","hypotheses":[{"id":0,"score":0.0,"value":"df.to_csv(file_name, sep\u003d\u0027\\t\u0027)"},{"id":0,"score":0.0,"value":"df.to_csv(file_name, sep\u003d\u0027\\t\u0027, encoding\u003d\u0027utf-8\u0027)"},{"id":0,"score":0.0,"value":"df.to_csv(file_name, encoding\u003d\u0027utf-8\u0027, index\u003dFalse)"},{"id":0,"score":0.0,"value":"Color  Number\n0   red     22\n1  blue     10"},{"id":0,"score":0.0,"value":"Color,Number\nred,22\nblue,10"},{"id":0,"score":0.0,"value":",Color,Number\n0,red,22\n1,blue,10"},{"id":0,"score":0.0,"value":"import csv\n\nmy_dict \u003d {\"test\": 1, \"testing\": 2}\n\nwith open(\u0027mycsvfile.csv\u0027, \u0027w\u0027) as f:  # You will need \u0027wb\u0027 mode in Python 2.x\n    w \u003d csv.DictWriter(f, my_dict.keys())\n    w.writeheader()\n    w.writerow(my_dict)"}]}],[{"query":"get time and date in gmt in `date`","hypotheses":[{"id":0,"score":0.0,"value":"\u003e\u003e\u003e import datetime\n\u003e\u003e\u003e datetime.datetime.now()\ndatetime.datetime(2009, 1, 6, 15, 8, 24, 78915)\n\n\u003e\u003e\u003e print(datetime.datetime.now())\n2009-01-06 15:08:24.789150"},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e datetime.datetime.now().time()\ndatetime.time(15, 8, 24, 78915)\n\n\u003e\u003e\u003e print(datetime.datetime.now().time())\n15:08:24.789150"},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e from datetime import datetime"},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e from time import gmtime, strftime\n\u003e\u003e\u003e strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())\n\u00272009-01-05 22:14:39\u0027"},{"id":0,"score":0.0,"value":"from datetime import datetime\ndatetime.now().strftime(\u0027%Y-%m-%d %H:%M:%S\u0027)"},{"id":0,"score":0.0,"value":"\u003e\u003e\u003e from datetime import datetime\n\u003e\u003e\u003e str(datetime.now())\n\u00272011-05-03 17:45:35.177000\u0027"},{"id":0,"score":0.0,"value":"import time"}]},{"query":"get time and date in gmt","hypotheses":[{"id":0,"score":0.0,"value":"import time\n\ntime.time()"},{"id":0,"score":0.0,"value":"1369550494.884832"},{"id":0,"score":0.0,"value":"import time\n\nint(time.time())"},{"id":0,"score":0.0,"value":"1521462189"},{"id":0,"score":0.0,"value":"logging.Formatter.converter \u003d time.gmtime"},{"id":0,"score":0.0,"value":"from datetime import datetime\nimport calendar\n\nd \u003d datetime.utcnow()\nunixtime \u003d calendar.timegm(d.utctimetuple())\nprint unixtime"},{"id":0,"score":0.0,"value":"import time\nint(time.time())"}]}],[{"query":"open csv file `data.csv` ","hypotheses":[{"id":0,"score":0.0,"value":"for row in reader:\n    content \u003d list(row[i] for i in included_cols)\nprint content"},{"id":0,"score":0.0,"value":"for row in reader:\n        content \u003d list(row[i] for i in included_cols)\n        print content"},{"id":0,"score":0.0,"value":"import pandas as pd\ndf \u003d pd.read_csv(csv_file)\nsaved_column \u003d df.column_name #you can also use df[\u0027column_name\u0027]"},{"id":0,"score":0.0,"value":"names \u003d df.Names"},{"id":0,"score":0.0,"value":"import csv\n\ndef getstuff(filename, criterion):\n    with open(filename, \"rb\") as csvfile:\n        datareader \u003d csv.reader(csvfile)\n        yield next(datareader)  # yield the header row\n        count \u003d 0\n        for row in datareader:\n            if row[3] \u003d\u003d criterion:\n                yield row\n                count +\u003d 1\n            elif count:\n                # done when having read a consecutive series of rows \n                return"},{"id":0,"score":0.0,"value":"import csv\nfrom itertools import dropwhile, takewhile\n\ndef getstuff(filename, criterion):\n    with open(filename, \"rb\") as csvfile:\n        datareader \u003d csv.reader(csvfile)\n        yield next(datareader)  # yield the header row\n        # first row, plus any subsequent rows that match, then stop\n        # reading altogether\n        # Python 2: use `for row in takewhile(...): yield row` instead\n        # instead of `yield from takewhile(...)`.\n        yield from takewhile(\n            lambda r: r[3] \u003d\u003d criterion,\n            dropwhile(lambda r: r[3] !\u003d criterion, datareader))\n        return"},{"id":0,"score":0.0,"value":"def getdata(filename, criteria):\n    for criterion in criteria:\n        for row in getstuff(filename, criterion):\n            yield row"}]},{"query":"open csv file","hypotheses":[{"id":0,"score":0.0,"value":"import pandas as pd\nimport zipfile\n\nzf \u003d zipfile.ZipFile(\u0027C:/Users/Desktop/THEZIPFILE.zip\u0027) \ndf \u003d pd.read_csv(zf.open(\u0027intfile.csv\u0027))"},{"id":0,"score":0.0,"value":"import csv\nfrom io import TextIOWrapper\nfrom zipfile import ZipFile\n\nwith ZipFile(\u0027yourfile.zip\u0027) as zf:\n    with zf.open(\u0027your_csv_inside_zip.csv\u0027, \u0027r\u0027) as infile:\n        reader \u003d csv.reader(TextIOWrapper(infile, \u0027utf-8\u0027))\n        for row in reader:\n            # process the CSV here\n            print(row)"},{"id":0,"score":0.0,"value":"\u003copen file \u0027amount2.csv\u0027, mode \u0027r\u0027 at 0x1004656f0\u003e"},{"id":0,"score":0.0,"value":"with open(\u0027test.csv\u0027, \u0027rb\u0027) as f:\n    reader \u003d csv.reader(f)\n    for row in reader:\n        # row is a list of strings\n        # use string.join to put them together\n        print \u0027, \u0027.join(row)"},{"id":0,"score":0.0,"value":"changes \u003d [    \n    [\u00271 dozen\u0027,\u002712\u0027],                                                            \n    [\u00271 banana\u0027,\u002713\u0027],                                                           \n    [\u00271 dollar\u0027,\u0027elephant\u0027,\u0027heffalump\u0027],                                         \n    ]                                                                            \n\nwith open(\u0027test.csv\u0027, \u0027ab\u0027) as f:                                    \n    writer \u003d csv.writer(f)                                                       \n    writer.writerows(changes)"},{"id":0,"score":0.0,"value":"import csv\n\nnew_rows \u003d [] # a holder for our modified rows when we make them\nchanges \u003d {   # a dictionary of changes to make, find \u0027key\u0027 substitue with \u0027value\u0027\n    \u00271 dozen\u0027 : \u002712\u0027, # I assume both \u0027key\u0027 and \u0027value\u0027 are strings\n    }\n\nwith open(\u0027test.csv\u0027, \u0027rb\u0027) as f:\n    reader \u003d csv.reader(f) # pass the file to our csv reader\n    for row in reader:     # iterate over the rows in the file\n        new_row \u003d row      # at first, just copy the row\n        for key, value in changes.items(): # iterate over \u0027changes\u0027 dictionary\n            new_row \u003d [ x.replace(key, value) for x in new_row ] # make the substitutions\n        new_rows.append(new_row) # add the modified rows\n\nwith open(\u0027test.csv\u0027, \u0027wb\u0027) as f:\n    # Overwrite the old file with the modified rows\n    writer \u003d csv.writer(f)\n    writer.writerows(new_rows)"},{"id":0,"score":0.0,"value":"new_row \u003d [ x.replace(key, value) for x in new_row ]"}]}],[{"query":"delete the first column in csv file `df`","hypotheses":[{"id":0,"score":0.0,"value":"df \u003d df.drop(\u0027column_name\u0027, 1)"},{"id":0,"score":0.0,"value":"df.drop(\u0027column_name\u0027, axis\u003d1, inplace\u003dTrue)"},{"id":0,"score":0.0,"value":"df \u003d df.drop(df.columns[[0, 1, 3]], axis\u003d1)  # df.columns is zero-based pd.Index"},{"id":0,"score":0.0,"value":"df.drop([\u0027column_nameA\u0027, \u0027column_nameB\u0027], axis\u003d1, inplace\u003dTrue)"},{"id":0,"score":0.0,"value":"del df[\u0027column_name\u0027]"},{"id":0,"score":0.0,"value":"df.to_csv(filename, index\u003dFalse)"},{"id":0,"score":0.0,"value":"df.read_csv(filename, index\u003dFalse)"}]},{"query":"delete the first column in csv file","hypotheses":[{"id":0,"score":0.0,"value":"df.to_csv(filename, index\u003dFalse)"},{"id":0,"score":0.0,"value":"df.read_csv(filename, index\u003dFalse)"},{"id":0,"score":0.0,"value":"df_csv \u003d df0_fa.to_csv(\u0027revenue/data/test.csv\u0027,mode \u003d \u0027w\u0027, index\u003dFalse)"},{"id":0,"score":0.0,"value":"import csv\nwith open(\"source\",\"rb\") as source:\n    rdr\u003d csv.reader( source )\n    with open(\"result\",\"wb\") as result:\n        wtr\u003d csv.writer( result )\n        for r in rdr:\n            wtr.writerow( (r[0], r[1], r[3], r[4]) )"},{"id":0,"score":0.0,"value":"in_iter\u003d ( (r[0], r[1], r[3], r[4]) for r in rdr )\n        wtr.writerows( in_iter )"},{"id":0,"score":0.0,"value":"del r[2]\n            wtr.writerow( r )"},{"id":0,"score":0.0,"value":"import pandas as pd\nf\u003dpd.read_csv(\"test.csv\")\nkeep_col \u003d [\u0027day\u0027,\u0027month\u0027,\u0027lat\u0027,\u0027long\u0027]\nnew_f \u003d f[keep_col]\nnew_f.to_csv(\"newFile.csv\", index\u003dFalse)"}]}]]