[["''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(N))", "''.join(random.choice(string.ascii_uppercase) for _ in range(100))", 0], ["print(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))", "print(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))", 1], ["datetime.datetime.combine(datetime.date.today(), datetime.timedelta(days=12))", "datetime.datetime.now() + datetime.timedelta(days=7)", 1], ["from datetime import datetime\ndatetime.utcnow()", "datetime.datetime.utcnow()", 0], ["writer.writerow(write)", "writer.writerow(line)", 1], ["for dirname, dirnames, filenames in os.walk('file.txt'):\n    for subdirname in dirnames:\n        print(os.path.join(dirname, subdirname))\n    for filename in filenames:\n        pass", "for dirname, dirnames, filenames in os.walk('file.txt'):\n    for subdirname in dirnames:\n        print(os.path.join(dirname, subdirname))\n    for filename in filenames:\n        pass", 1], ["re.sub('#(\\\\w+)', '\\\\1', text)", "re.sub('#(\\\\w+)', '\\\\1', text)", 1], ["pandas.read_csv(file, sep='\\t', lineterminator='\\r')", "pandas.read_csv(file)", 1], ["df.groupby(np.arange(len(df.columns)) // 2 + 1, axis=1).mean()", "df.groupby(np.arange(len(df.columns)), axis=1).mean()", 1], ["In [479]: df\nOut[479]: \n         ID  birthyear    weight\n0    619040       1962  0.123123\n1    600161       1963  0.981742\n2  25602033       1963  1.312312\n3    624870       1987  0.942120\n\nIn [480]: df[\"weight\"].mean()\nOut[480]: 0.83982437500000007", "df[\"column_key\"].mean()", 0], ["pd.concat([df1, df2], axis=1)", "pd.concat([df1, df2], axis=1)", 1], ["In [1]: s1 = pd.Series([1, 2], index=['A', 'B'], name='s1')\n\nIn [2]: s2 = pd.Series([3, 4], index=['A', 'B'], name='s2')\n\nIn [3]: pd.concat([s1, s2], axis=1)\nOut[3]:\n   s1  s2\nA   1   3\nB   2   4\n\nIn [4]: pd.concat([s1, s2], axis=1).reset_index()\nOut[4]:\n  index  s1  s2\n0     A   1   3\n1     B   2   4", "In [1]: s1 = pd.Series([1, 2], index=['A', 'B'], name='s1')\n    \n    In [2]: s2 = pd.Series([3, 4], index=['A', 'B'], name='s2')\n    \n    In [3]: pd.concat([s1, s2], axis=1)\n    Out[3]:\n       s1  s2\n    A   1   3\n    B   2   4\n    \n    In [4]: pd.concat([s1, s2], axis=1).reset_index()\n    Out[4]:\n      index  s1  s2\n    0     A   1   3\n    1     B   2   4", 0], ["df = df.rename(columns={'oldName1': 'newName1', 'oldName2': 'newName2'})\n# Or rename the existing DataFrame (rather than creating a copy) \ndf.rename(columns={'oldName1': 'newName1', 'oldName2': 'newName2'}, inplace=True)", "df = df.rename(columns={'oldName1': 'newName1', 'oldName2': 'newName2'})", 0], ["df2 = df.set_axis(['V', 'W', 'X', 'Y', 'Z'], axis=1, inplace=False)\ndf2\n\n   V  W  X  Y  Z\n0  x  x  x  x  x\n1  x  x  x  x  x\n2  x  x  x  x  x", "df2 = df.set_axis(['V', 'W', 'X', 'Y', 'Z'], axis=1, inplace=False)\ndf2\n\n   V  W  X  Y  Z\n0  x  x  x  x  x\n1  x  x  x  x  x\n2  x  x  x  x  x", 0], ["df.to_csv(file_name, sep='\\t')", "df.to_csv(file_name, sep='\\t')", 0], ["import pandas as pd\npd.options.display.float_format = '${:,.2f}'.format\ndf = pd.DataFrame([123.4567, 234.5678, 345.6789, 456.7890],\n                  index=['foo','bar','baz','quux'],\n                  columns=['cost'])\nprint(df)", "import pandas as pd\n    pd.options.display.float_format = '${:,.2f}'.format\n    df = pd.DataFrame([123.4567, 234.5678, 345.6789, 456.7890],\n                      index=['foo','bar','baz','quux'],\n                      columns=['cost'])\n    print(df)", 0], ["with open('foo.csv', 'w') as f:\n    data.to_csv(f, index=True, header=True, decimal=',', sep=' ', float_format='%.3f')", "with open('foo.csv', 'w') as f:\n        data.to_csv(f, index=True, header=True, decimal=',', sep=' ', float_format='%.3f')", 0], ["bins = [0, 1, 5, 10, 25, 50, 100]\ndf['binned'] = pd.cut(df['percentage'], bins)\nprint (df)\n   percentage     binned\n0       46.50   (25, 50]\n1       44.20   (25, 50]\n2      100.00  (50, 100]\n3       42.12   (25, 50]", "bins = [0, 1, 5, 10, 25, 50, 100]\ndf['binned'] = pd.cut(df['percentage'], bins)", 0], ["df.loc[df['column_name'] == some_value]", "df.loc[df['column_name'] == some_value]", 0], ["In [11]: df.loc[df['col1'] >= 1, 'col1']\nOut[11]: \n1    1\n2    2\nName: col1\n\nIn [12]: df[df['col1'] >= 1]\nOut[12]: \n   col1  col2\n1     1    11\n2     2    12\n\nIn [13]: df[(df['col1'] >= 1) & (df['col1'] <=1 )]\nOut[13]: \n   col1  col2\n1     1    11", "In [13]: df[(df['col1'] >= 1) & (df['col1'] <=1 )]\n    Out[13]: \n       col1  col2\n    1     1    11", 0], ["output = df.to_string(formatters={\n    'var1': '{:,.2f}'.format,\n    'var2': '{:,.2f}'.format,\n    'var3': '{:,.2%}'.format\n})\nprint(output)", "output = df.to_string(formatters={\n        'var1': '{:,.2f}'.format,\n        'var2': '{:,.2f}'.format,\n        'var3': '{:,.2%}'.format\n    })\n    print(output)", 0], ["df['race_label'] = df.apply (lambda row: label_race(row), axis=1)", "df['race_label'] = df.apply (lambda row: label_race(row), axis=1)", 0], ["LogisticRegression(multi_class='multinomial',solver ='newton-cg').fit(X_train,y_train)", "LogisticRegression(multi_class='multinomial',solver ='newton-cg').fit(X_train,y_train)", 0], ["from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\nimport numpy as np\n\nclf = RandomForestClassifier() #Initialize with whatever parameters you want to\n\n# 10-Fold Cross validation\nprint np.mean(cross_val_score(clf, X_train, y_train, cv=10))", "from sklearn.ensemble import RandomForestClassifier\n    from sklearn.model_selection import cross_val_score\n    import numpy as np\n    \n    clf = RandomForestClassifier() #Initialize with whatever parameters you want to\n    \n    # 10-Fold Cross validation\n    print np.mean(cross_val_score(clf, X_train, y_train, cv=10))", 0], ["import warnings\nwarnings.filterwarnings('ignore')", "import warnings\n    warnings.filterwarnings('ignore')", 0], ["plt.savefig('plt', dpi=1000)", "plt.savefig('output.png')", 1], ["dates = matplotlib.dates.date2num(list_of_datetimes)\nmatplotlib.pyplot.plot_date(dates, values)", "dates = matplotlib.dates.date2num(list_of_datetimes)\n    matplotlib.pyplot.plot_date(dates, values)", 0], ["plt.plot([1,2], lw=4, c='#8f9805')", "plt.plot([1,2], lw=4, c='purple')", 0], ["from matplotlib import pyplot as plt    \n\nfig = plt.figure()\nplt.plot(data)\nfig.suptitle('test title', fontsize=20)\nplt.xlabel('xlabel', fontsize=18)\nplt.ylabel('ylabel', fontsize=16)\nfig.savefig('test.jpg')", "plt.xlabel('xlabel', fontsize=18)\n    plt.ylabel('ylabel', fontsize=16)", 0], ["import matplotlib.pyplot as plt\n# We prepare the plot  \nfig, ax = plt.subplots()\n\n# We change the fontsize of minor ticks label \nax.tick_params(axis='both', which='major', labelsize=10)\nax.tick_params(axis='both', which='minor', labelsize=8)", "ax.tick_params(axis='both', which='major', labelsize=10)", 0], ["plt.figure(figsize=(3, 4))", "plt.figure(figsize=(3, 4))", 1], ["df.groupby(['A', 'B'], axis=1)", "df.groupby(['A', 'B'], axis=1)", 1], ["import matplotlib.pyplot as plt\nfrom matplotlib.dates import date2num\nimport datetime\n\nx = [\n    datetime.datetime(2011, 1, 4, 0, 0),\n    datetime.datetime(2011, 1, 5, 0, 0),\n    datetime.datetime(2011, 1, 6, 0, 0)\n]\nx = date2num(x)\n\ny = [4, 9, 2]\nz = [1, 2, 3]\nk = [11, 12, 13]\n\nax = plt.subplot(111)\nax.bar(x-0.2, y, width=0.2, color='b', align='center')\nax.bar(x, z, width=0.2, color='g', align='center')\nax.bar(x+0.2, k, width=0.2, color='r', align='center')\nax.xaxis_date()\n\nplt.show()", "ax = plt.subplot(111)\n        ax.bar(x-0.2, y, width=0.2, color='b', align='center')\n        ax.bar(x, z, width=0.2, color='g', align='center')\n        ax.bar(x+0.2, k, width=0.2, color='r', align='center')\n        ax.xaxis_date()", 0], ["import matplotlib.pyplot as plt\n\nx = range(10)\ny = range(10)\n\nfig, ax = plt.subplots(nrows=2, ncols=2)\n\nfor row in ax:\n    for col in row:\n        col.plot(x, y)\n\nplt.show()", "fig, ax = plt.subplots(nrows=2, ncols=2)", 0], ["from matplotlib import pyplot as plt\nplt.style.use('ggplot')", "plt.style.use('ggplot')", 0], ["for i, v in enumerate(y):\n    ax.text(v + 3, i + .25, str(v), color='blue', fontweight='bold')", "for i, v in enumerate(y):\n            ax.text(v + 3, i + .25, str(v), color='blue', fontweight='bold')", 0], ["import random\nimport matplotlib.pyplot as plt\n\nx = range(1, 101)\ny1 = [random.randint(1, 100) for _ in xrange(len(x))]\ny2 = [random.randint(1, 100) for _ in xrange(len(x))]\n\nfig = plt.figure()\nax = fig.add_subplot(111)    # The big subplot\nax1 = fig.add_subplot(211)\nax2 = fig.add_subplot(212)\n\n# Turn off axis lines and ticks of the big subplot\nax.spines['top'].set_color('none')\nax.spines['bottom'].set_color('none')\nax.spines['left'].set_color('none')\nax.spines['right'].set_color('none')\nax.tick_params(labelcolor='w', top=False, bottom=False, left=False, right=False)\n\nax1.loglog(x, y1)\nax2.loglog(x, y2)\n\n# Set common labels\nax.set_xlabel('common xlabel')\nax.set_ylabel('common ylabel')\n\nax1.set_title('ax1 title')\nax2.set_title('ax2 title')\n\nplt.savefig('common_labels.png', dpi=300)", "ax.set_xlabel('common xlabel')\n            ax.set_ylabel('common ylabel')", 0], ["start, end = ax.get_xlim()\nax.xaxis.set_ticks(np.arange(start, end, stepsize))", "start, end = ax.get_xlim()\n        ax.xaxis.set_ticks(np.arange(start, end, stepsize))", 0], ["from matplotlib import pyplot as plt    \n\nfig = plt.figure()\nplt.plot(data)\nfig.suptitle('test title', fontsize=20)\nplt.xlabel('xlabel', fontsize=18)\nplt.ylabel('ylabel', fontsize=16)\nfig.savefig('test.jpg')", "fig.suptitle('test title', fontsize=20)", 0], ["plt.legend(frameon=False)", "plt.legend(loc=\"upper left\")", 1], ["random.choice(random.choice(sample), repeat=n)", ">>> list(map(chr, range(97, 123)))", 1], ["random.choice(random.choice(sample), repeat=n)", "sampled_keys = random.choice(random.choice(l_key), repeat=100)", 1], ["sorted(list(dict.items()), key=lambda x: x[1])", "sorted(list(dictionary.items()), key=lambda x: x[0])", 1], ["os.listdir('<unk>')", "all_files = os.listdir('data')", 1], ["from shutil import copyfile\ncopyfile(src, dst)", "from shutil import copyfile\n        copyfile(os.path.join(src_dir, filename), os.path.join(tgt_dir, filename))", 0], [">>> \"Hello\\n\\n\\n\".rstrip(\"\\n\")\n\"Hello\"", ">>> line = line.rstrip(\"\\n\") + \"\\n\"\n                \"Hello\"", 0], ["with open(\"test.txt\", \"a\") as myfile:\n    myfile.write(\"appended text\")", "with open(os.path.join(tgt_dir, filename), \"w\") as myfile:\n            for line in new_lines:\n                myfile.write(line)", 0], [">>> u8 = v.decode(\"iso-8859-1\").encode(\"utf-8\")\n>>> u8\n'\\xc3\\x84pple'    # convert iso-8859-1 to unicode to utf-8\n\n>>> tell_me_about(u8)\n(<type 'str'>, '\\xc3\\x84pple')\n\n>>> u16 = v.decode('iso-8859-1').encode('utf-16')\n>>> tell_me_about(u16)\n(<type 'str'>, '\\xff\\xfe\\xc4\\x00p\\x00p\\x00l\\x00e\\x00')\n\n>>> tell_me_about(u8.decode('utf8'))\n(<type 'unicode'>, u'\\xc4pple')\n\n>>> tell_me_about(u16.decode('utf16'))\n(<type 'unicode'>, u'\\xc4pple')", "line = line.decode(\"iso-8859-1\").encode(\"utf-8\")", 0], ["shutil.copy2('<unk>', '<unk>')", "shutil.copy2(src_filepath, tgt_filepath)", 1], ["datetime.datetime.now()", "time = time.strftime('%m-%d-%Y %H:%M')", 1], ["from datetime import datetime, timedelta\n\nd = datetime.today() - timedelta(days=days_to_subtract)", "from datetime import datetime, timedelta\n\ntime = datetime.today() + timedelta(days=7)", 0], ["import pandas as pd\ndf=pd.read_csv('myfile.csv', sep=',',header=None)\ndf.values\narray([[ 1. ,  2. ,  3. ],\n       [ 4. ,  5.5,  6. ]])", "import pandas as pd\ndf=pd.read_csv('data.csv', sep=',')", 0], ["df1 = df.iloc[:, 0:2] # Remember that Python does not slice inclusive of the ending index.", "df1 = df.iloc[:, 1:-1] # Remember that Python does not slice inclusive of the ending index.", 0], ["df.to_csv(file_name, sep='\\t')", "df1.to_csv(\"./example_output/output.csv\", index=False)", 0], [">>> import os\n>>> filename, file_extension = os.path.splitext('/path/to/somefile.ext')\n>>> filename\n'/path/to/somefile'\n>>> file_extension\n'.ext'", ">>> import os\n>>> filename, file_extension = os.path.splitext('/path/to/somefile.ext')\n>>> filename\n'/path/to/somefile'\n>>> file_extension\n'.ext'", 0], ["shutil.copy2(ddd.png, 'ddd.png')", "import shutil\n        shutil.copy2(os.path.join(\"./data\", fname), os.path.join(\"./output\", fname))", 1], ["shutil.copy2(file, 'en_US')", "import shutil\n        shutil.copy2(os.path.join(root, fname), save_dir)", 1], ["import os\nif not os.path.exists(directory):\n    os.makedirs(directory)", "if not os.path.exists(directory):\n            os.makedirs(directory)", 0], [">>> df = pd.DataFrame({'a': ['red', 'yellow', 'blue'], 'b': [0.5, 0.25, 0.125]})\n>>> df\n        a      b\n0     red  0.500\n1  yellow  0.250\n2    blue  0.125", "_company_info = {}\nfor k, v in company_info.items():\n    cur_v = np.array(v)\n    _company_info[k] = {'avg_price': np.mean(cur_v),\n                        'max_price': np.max(cur_v),\n                        'min_price': np.min(cur_v),\n                        'stddev_price': np.std(cur_v),\n                        'total_count': len(v)}\ncompany_df = pd.DataFrame(_company_info)\nprint(company_df)", 0], ["df = pd.DataFrame({'oldcol':[1,2,3]})\n\n#add column to existing df \ndf['col'] = L\nprint (df)\n   oldcol                  col\n0       1           Thanks You\n1       2  Its fine no problem\n2       3         Are you sure", "company_df.to_csv(\"./output/price_by_company.csv\")", 0], ["df = pd.DataFrame({'oldcol':[1,2,3]})\n\n#add column to existing df \ndf['col'] = L\nprint (df)\n   oldcol                  col\n0       1           Thanks You\n1       2  Its fine no problem\n2       3         Are you sure", "", 0], ["df = pd.DataFrame({'oldcol':[1,2,3]})\n\n#add column to existing df \ndf['col'] = L\nprint (df)\n   oldcol                  col\n0       1           Thanks You\n1       2  Its fine no problem\n2       3         Are you sure", "keys = company_info.keys()\ncompany_df = pd.DataFrame({'company': list(keys),\n                            'avg_price': [company_info[x]['avg_price'] for x in keys],\n                            'max_price': [company_info[x]['max_price'] for x in keys],\n                            'min_price': [company_info[x]['min_price'] for x in keys],\n                            'stddev_price': [company_info[x]['stddev_price'] for x in keys],\n                            'total_count': [company_info[x]['total_count'] for x in keys],\n                           })\n#add column to existing df\ndf['col'] = L\nprint (df)\n   oldcol                  col\n0       1           Thanks You\n1       2  Its fine no problem\n2       3         Are you sure", 0], ["df.to_csv(\"output.csv\", index=False)", "company_df.to_csv(\"output/price_by_company.csv\", index=False)", 0], ["float('{0:.2f}'.format(cast))", "avg_price = float('{0:.2f}'.format(np.mean(np.array(hp_info[key])))", 1], ["list(my_dataframe.columns.values)", "xx = list(df.columns.values)", 0], ["df1 = df1.assign(e=pd.Series(np.random.randn(sLength)).values)", "scores.append(cur_d[\"horsepower\"] / (cur_d[\"average-mileage\"] * cur_d[\"price\"]))\n        df1 = df1.assign(e=pd.Series(np.random.randn(sLength)).values)", 0], ["pd.DataFrame(data, columns=['x', 'y'], axis=1)", "jpd.DataFrame(selected_info, columns=xx)", 1], ["jdf.sort_values(by=scores.columns)", "jdf.sort_values(by=jdf.columns.scores)", 1], ["jdf.sort_values(by='scores')", "jdf = jdf.sort_values(by='scores')", 1], ["from sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics, cross_validation\nfrom sklearn import datasets\niris = datasets.load_iris()\npredicted = cross_validation.cross_val_predict(LogisticRegression(), iris['data'], iris['target'], cv=10)\nprint metrics.accuracy_score(iris['target'], predicted)\n\nOut [1] : 0.9537\n\nprint metrics.classification_report(iris['target'], predicted) \n\nOut [2] :\n                     precision    recall  f1-score   support\n\n                0       1.00      1.00      1.00        50\n                1       0.96      0.90      0.93        50\n                2       0.91      0.96      0.93        50\n\n      avg / total       0.95      0.95      0.95       150", "from sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics, cross_validation\nregressor = LogisticRegression(c=0.1)\npredicted = cross_validation.cross_val_predict(regressor, X, y, cv=5)\nprint(metrics.accuracy_score(y, predicted))", 0], ["from sklearn.svm import SVC\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import cross_validate\niris = load_iris()\nscoring = ['precision', 'recall', 'f1']\nclf = SVC(kernel='linear', C=1, random_state=0)\nscores = cross_validate(clf, iris.data, iris.target == 1, cv=5,\n                        scoring=scoring, return_train_score=False)", "from sklearn.model_selection import cross_validate\nregressor = LogisticRegression(c=0.1)\nclf = SVC(kernel='linear', C=1, random_state=0)\nscores = cross_validate(regressor, X, y, cv=5)", 0], [">>> numpy.random.seed(0) ; numpy.random.rand(4)\narray([ 0.55,  0.72,  0.6 ,  0.54])\n>>> numpy.random.seed(0) ; numpy.random.rand(4)\narray([ 0.55,  0.72,  0.6 ,  0.54])", "numpy.random.seed(0)", 0], ["datetime.today().strftime('%Y-%m-%d-%H:%M:%S')", "print(now.strftime('%m-%d-%Y %H:%M'))", 0], ["shutil.copy2(file, 'rb')", "shutil.copy2(in_file, out_file)", 1], ["import codecs\nwith codecs.open('unicode.rst', encoding='utf-8') as f:\n    for line in f:\n        print repr(line)", "import codecs\n    with codecs.open(in_file, encoding='ISO-8859-15') as in_f:", 0], [">>> import string\n>>> import random\n>>> def id_generator(size=6, chars=string.ascii_uppercase + string.digits):\n...    return ''.join(random.choice(chars) for _ in range(size))\n...\n>>> id_generator()\n'G5G74W'\n>>> id_generator(3, \"6793YUIO\")\n'Y3U'", "from collections import defaultdict", 0], [">>> import string\n>>> import random\n>>> def id_generator(size=6, chars=string.ascii_uppercase + string.digits):\n...    return ''.join(random.choice(chars) for _ in range(size))\n...\n>>> id_generator()\n'G5G74W'\n>>> id_generator(3, \"6793YUIO\")\n'Y3U'", "from collections import defaultdict", 0], [">>> import string\n>>> import random\n>>> def id_generator(size=6, chars=string.ascii_uppercase + string.digits):\n...    return ''.join(random.choice(chars) for _ in range(size))\n...\n>>> id_generator()\n'G5G74W'\n>>> id_generator(3, \"6793YUIO\")\n'Y3U'", "import string\nimport random", 0], [">>> from collections import defaultdict", "from collections import defaultdict", 0], ["sorted(list(dict.items()), key=lambda x: x[1])", "keySorted = sorted(list(dic.keys()))", 1], ["print(*myList, sep='\\n')", "print(key, *dic[key], sep=' ')", 0], ["os.listdir('<unk>')", "import os\n\nfiles = os.listdir('data')", 1], ["with open('file.txt', 'r') as f:\n    f = f.open('file.txt', 'r', encoding='utf-8')", "with codecs.open('data/' + file, 'r', encoding='ISO-8859-15') as f:\n        with codecs.open('output/' + file, 'w', encoding='UTF-8') as w:\n            for line in f.readlines():\n                w.write(line)", 1], ["with open('file.txt', 'r') as f:\n    f = f.open('file.txt', 'r', encoding='utf-8')", "with codecs.open('data/' + file, 'r', encoding='ISO-8859-15') as f:\n        with codecs.open('output/' + file, 'w', encoding='UTF-8') as w:\n            for line in f.readlines():\n                w.write(line)", 1], ["from shutil import copyfile\ncopyfile(src, dst)", "copyfile('data/' + file, 'output/' + file)\n        continue", 0], ["s = s.lstrip()", "line = line.lstrip()", 0], ["df = pd.read_csv('myfile.txt', sep=',', header=None)", "import pandas as pd\ndf = pd.read_csv('automobile_data.csv', sep=',')", 1], ["In [30]: df.dropna(subset=[1])   #Drop only if NaN in specific column (as asked in the question)\nOut[30]:\n          0         1         2\n1  2.677677 -1.466923 -0.750366\n2       NaN  0.798002 -0.906038\n3  0.672201  0.964789       NaN\n5 -1.250970  0.030561 -2.678622\n6       NaN  1.036043       NaN\n7  0.049896 -0.308003  0.823295\n9 -0.310130  0.078891       NaN", "df.dropna()   #Drop only if NaN in specific column (as asked in the question)", 0], ["In [36]: DataFrame({'count' : df1.groupby( [ \"Name\", \"City\"] ).size()}).reset_index()\nOut[36]: \n      Name      City  count\n0    Alice   Seattle      1\n1      Bob   Seattle      2\n2  Mallory  Portland      2\n3  Mallory   Seattle      1", "df.to_csv(\"output/price_by_company\")", 0], ["In [36]: DataFrame({'count' : df1.groupby( [ \"Name\", \"City\"] ).size()}).reset_index()\nOut[36]: \n      Name      City  count\n0    Alice   Seattle      1\n1      Bob   Seattle      2\n2  Mallory  Portland      2\n3  Mallory   Seattle      1", "pd.DataFrame({'count': df.groupby([\"company\"]).size()}).reset_index()", 0], ["df.to_csv('<unk>', index=False)", "df.to_csv('output/price_by_company', index=False)", 1], ["df.groupby(np.arange(len(df.columns)) // 3).mean()", "'avg_price': group.mean(),", 1], ["with open('foo.csv', 'w') as f:\n    data.to_csv(f, index=True, header=True, decimal=',', sep=' ', float_format='%.3f')", "price_by_company.to_csv('output/price_by_company.csv', index=False, float_format='%.2f')", 0], ["df.sort_values(by='*')", "price_by_company = price_by_company.sort_values(by='avg_price', ascending=False)", 1], ["df.sort_values(by='*')", "price_by_company = price_by_company.sort_values(by='avg_price', ascending=False)", 1], ["np.random.seed(0)\ndf = pd.DataFrame({\"a\": np.random.random_integers(1, high=100, size=100)})\nranges = [0,10,20,30,40,50,60,70,80,90,100]\ndf.groupby(pd.cut(df.a, ranges)).count()\n\n            a\na            \n(0, 10]    11\n(10, 20]   10\n(20, 30]    8\n(30, 40]   13\n(40, 50]   11\n(50, 60]    9\n(60, 70]   10\n(70, 80]   11\n(80, 90]   13\n(90, 100]   4", "ranges = range(0, max(df.horsepower), 20)\ngp_horsepower = df.groupby(pd.cut(df.horsepower, ranges))", 0], ["df.rename(columns={'row': 'row'}, inplace=True)", "price_by_horsepower.rename(columns={'horsepower': 'horsepower_range'}, inplace=True)", 1], ["from matplotlib import pyplot as plt\n\nimport matplotlib.pyplot as plt1\n\nprint(dir(plt) == dir(plt1))\nTrue", "f, axs = plt.subplots(2,2,figsize=(15,15))", 0], ["from matplotlib import pyplot as plt\n\nimport matplotlib.pyplot as plt1\n\nprint(dir(plt) == dir(plt1))\nTrue", "import matplotlib.pyplot as plt", 0], ["f, axs = plt.subplots(2,2,figsize=(15,15))", "f, axs = plt.subplots(1, 3, figsize=(20, 6))", 1], ["fig.add_subplot(1, 1, 1)", "fig.add_subplot(1, 1, 1)", 1], ["df.loc[df['column_name'] == some_value]", "df.loc[df['gender'] == 'male']", 0], ["os.path.chr().encode('utf-8')", "os.path.chr('output/' + filename).encode('utf-8')", 1], ["# Doing linear regression with leave one out cross val\n\nfrom sklearn import cross_validation, linear_model\nimport numpy as np\n\n# Including this to remind you that it is necessary to use numpy arrays rather \n# than lists otherwise you will get an error\nX_digits = np.array(x)\nY_digits = np.array(y)\n\nloo = cross_validation.LeaveOneOut(len(Y_digits))\n\nregr = linear_model.LinearRegression()\n\nscores = cross_validation.cross_val_score(regr, X_digits, Y_digits, scoring='mean_squared_error', cv=loo,)\n\n# This will print the mean of the list of errors that were output and \n# provide your metric for evaluation\nprint scores.mean()", "# Doing linear regression with leave one out cross val\n\nfrom sklearn import cross_validation, linear_model\nimport numpy as np\n\n# Including this to remind you that it is necessary to use numpy arrays rather \n# than lists otherwise you will get an error\nX_digits = np.array(x)\nY_digits = np.array(y)\n\nloo = cross_validation.LeaveOneOut(len(Y_digits))\n\nregr = linear_model.LinearRegression()\n\nscores = cross_validation.cross_val_score(regr, X_digits, Y_digits, scoring='mean_squared_error', cv=loo,)\n\n# This will print the mean of the list of errors that were output and \n# provide your metric for evaluation\nprint scores.mean()", 0], ["from random import randrange\nprint(randrange(10))", "from random import randrange\nprint(randrange(10))", 0], ["''.join(random.choices(string.ascii_uppercase + string.digits, k=N))", "import random\nimport string\n''.join(random.choices(string.ascii_uppercase + string.digits, k=N))", 0], [">>> import datetime\n>>> datetime.datetime.now()\ndatetime.datetime(2009, 1, 6, 15, 8, 24, 78915)\n\n>>> print(datetime.datetime.now())\n2009-01-06 15:08:24.789150", "import datetime\ndatetime.datetime.now()", 0], ["date_1 = datetime.datetime.strptime(start_date, \"%m/%d/%y\")\n\nend_date = date_1 + datetime.timedelta(days=10)", "end_date = date_1 + datetime.timedelta(days=7)", 0], ["import datetime\ndatetime.datetime.utcnow().replace(tzinfo=datetime.timezone.utc).isoformat()\n>>> 2020-03-20T01:31:12.467113+00:00", "import datetime\ndatetime.datetime.utcnow().replace(tzinfo=datetime.timezone.utc)", 0], [">>> import datetime\n>>> '{0:%Y-%m-%d %H:%M:%S}'.format(datetime.datetime.now())\n'2014-02-07 11:52:21'", "import datetime\n'{0:%Y-%m-%d %H:%M:%S}'.format(datetime.datetime.now())", 0], ["import csv\n\nwith open(\"test.csv\", \"r\") as f:\n    reader = csv.reader(f, delimiter=\"\\t\")\n    for i, line in enumerate(reader):\n        print 'line[{}] = {}'.format(i, line)", "import csv\n\nwith open(\"test.csv\", \"r\") as f:\n    reader = csv.reader(f, delimiter=\",\")\n    for i, line in enumerate(reader):\n        print('line[{}] = {}'.format(i, line))", 0], ["import os\nif not os.path.exists(directory):\n    os.makedirs(directory)", "import os\nif not os.path.exists(directory):\n    os.makedirs(directory)", 0], ["from os import listdir\nfrom os.path import isfile, join\nonlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]", "from os import listdir\nfrom os.path import isfile, join\nonlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]", 0], ["def whatisthis(s):\n    if isinstance(s, str):\n        print \"ordinary string\"\n    elif isinstance(s, unicode):\n        print \"unicode string\"\n    else:\n        print \"not a string\"", "def whatisthis(s):\n            if isinstance(s, str):\n                print \"ordinary string\"\n            elif isinstance(s, unicode):\n                print \"unicode string\"\n            else:\n                print \"not a string\"", 0], ["from shutil import copyfile\ncopyfile(src, dst)", "from shutil import copyfile\n            copyfile(src, dst)", 0], ["datetime.datetime.now().time()", "datetime.datetime.now().time()", 1], ["datetime.datetime.now().date()", "datetime.datetime.now().date()", 0], ["datetime.datetime.now().time()", "datetime.datetime.now().time()", 1], ["s = random.choice('<unk>')", "s = random.choice([x for x in 'abcdefghijklmnopqrstuvwxyz'])", 1], ["df = pd.read_csv('data.csv', sep='data.csv')", "df = pd.read_csv('data.csv')", 1], ["import os\nif not os.path.exists(directory):\n    os.makedirs(directory)", "import os\nif not os.path.exists('output'):\n    os.makedirs('output')", 0], ["data = json.loads(f)", "data = json.loads(f)", 1], ["import json\nwith open('data.json', 'w') as f:\n    json.dump(data, f)", "with open(outfile, 'w') as f:\n        json.dump(ret, f)", 0], ["np.genfromtxt('<unk>', delimiter=',')", "np.genfromtxt('<unk>', delimiter=',')", 1], ["import warnings\nwarnings.filterwarnings('ignore')", "import warnings\nwarnings.filterwarnings('ignore')", 0], ["for x in range(0, 100, 2):\n    print(x)", "for x in range(0, 100, 2):\n    print(x)", 0], ["import os\n arr = os.listdir()\n print(arr)\n\n >>> ['$RECYCLE.BIN', 'work.txt', '3ebooks.txt', 'documents']", ">>> s = \"Hello!\"\n>>> u = unicode(s, \"utf-8\")", 0], ["import os\n arr = os.listdir()\n print(arr)\n\n >>> ['$RECYCLE.BIN', 'work.txt', '3ebooks.txt', 'documents']", "\"\"\"\"\"\".join(str(c) for c in 'Andr\u00c3\u00a9').decode('utf8')", 0], ["text_file = open(\"Output.txt\", \"w\")\ntext_file.write(\"Purchase Amount: %s\" % TotalAmount)\ntext_file.close()", "text_file = open(\"Output.txt\", \"w\")\n    text_file.write(\"Purchase Amount: %s\" % TotalAmount)\n    text_file.close()", 0], ["json.loads(json.loads(json))", "json.loads(json.loads(json))", 1], [">>> str(10)\n'10'\n>>> int('10')\n10", ">>> str(10)\n    '10'\n    >>> int('10')\n    10", 0], [">>> import ast\n>>> ast.literal_eval(\"{'muffin' : 'lolz', 'foo' : 'kitty'}\")\n{'muffin': 'lolz', 'foo': 'kitty'}", ">>> import ast\n    >>> ast.literal_eval(\"{'muffin' : 'lolz', 'foo' : 'kitty'}\")\n    {'muffin': 'lolz', 'foo': 'kitty'}", 0], ["data = json.loads(data)", "data = json.loads(data)", 1], ["data = json.loads(data)", "data = json.loads(data)", 1], ["import re\n\nEMAIL_REGEX = re.compile(r\"... regex here ...\")\n\nif not EMAIL_REGEX.match(email):\n  # whatever", "import re\n\nEMAIL_REGEX = re.compile(r\"... regex here ...\")\n\nif not EMAIL_REGEX.match(email):\n  # whatever", 0], ["for x in range(0, 10):\n    pass", "for x in range(count):\n    pass", 1], ["random.choice(random.choice(seq.random))", "random.choice(seq)", 1], ["[(x + y) for x, y in zip(hundred_characters, hundred_numbers)]", "zip(hundred_characters, hundred_numbers)", 1], ["import os\nfor root, dirs, files in os.walk(\"/mydir\"):\n    for file in files:\n        if file.endswith(\".txt\"):\n             print(os.path.join(root, file))", "import os\n    for root, dirs, files in os.walk(\"data\"):\n        for file in files:\n            if file.endswith(\".txt\"):\n                 print(os.path.join(root, file))", 0], ["with open(\"file.txt\") as file_in:\n    lines = []\n    for line in file_in:\n        lines.append(line)", "with open(\"file.txt\") as file_in:\n    lines = []\n    for line in file_in:\n        lines.append(line)", 0], ["import os\nrootdir = 'C:/Users/sid/Desktop/test'\n\nfor subdir, dirs, files in os.walk(rootdir):\n    for file in files:\n        print os.path.join(subdir, file)", "import os\nrootdir = 'data'\n\nfor subdir, dirs, files in os.walk(rootdir):\n    for file in files:\n        print(os.path.join(subdir, file))", 0], ["re.findall('<unk>', '<unk>')", "re.findall('<unk>', '<unk>')", 1], [">>> import re\n>>> s=\"four digits 1234 five digits 56789 six digits 012345\"\n>>> re.findall(r\"\\D(\\d{5})\\D\", s)\n['56789']", "re.findall(r\"\\d\", s)", 0], ["import re\nfrom datetime import datetime\n\nmatch = re.search(r'\\d{4}-\\d{2}-\\d{2}', text)\ndate = datetime.strptime(match.group(), '%Y-%m-%d').date()", "import re\nfrom datetime import datetime\n\nmatch = re.search(r'\\d{4}-\\d{2}-\\d{2}', text)\ndate = datetime.strptime(match.group(), '%Y-%m-%d').date()", 0], ["import argparse\nparser = argparse.ArgumentParser()\nparser.add_argument('--foo')\nsub = parser.add_subparsers()\nfor i in range(1,4):\n    sp = sub.add_parser('cmd%i'%i)\n    sp.add_argument('--foo%i'%i) # optionals have to be distinct\n\nrest = '--foo 0 cmd2 --foo2 2 cmd3 --foo3 3 cmd1 --foo1 1'.split() # or sys.argv\nargs = argparse.Namespace()\nwhile rest:\n    args,rest =  parser.parse_known_args(rest,namespace=args)\n    print args, rest", "import argparse\nparser = argparse.ArgumentParser()\nparser.add_argument('--foo')\nsub = parser.add_subparsers()\nfor i in range(1,4):\n    sp = sub.add_parser('cmd%i'%i)\n    sp.add_argument('--foo%i'%i) # optionals have to be distinct", 0], ["import requests\n\nurl = 'http://192.168.3.45:8080/api/v2/event/log'\n\ndata = {\"eventType\": \"AAS_PORTAL_START\", \"data\": {\"uid\": \"hfe3hf45huf33545\", \"aid\": \"1\", \"vid\": \"1\"}}\nparams = {'sessionKey': '9ebbd0b25760557393a43064a92bae539d962103', 'format': 'xml', 'platformId': 1}\n\nrequests.post(url, params=params, json=data)", "import requests\n    \n    url = 'http://192.168.3.45:8080/api/v2/event/log'\n    \n    params = {'sessionKey': '9ebbd0b25760557393a43064a92bae539d962103', 'format': 'xml', 'platformId': 1}\n    \n    requests.post(url, params=params)", 0], ["now = datetime.now()", "now = datetime.now()", 1], ["datetime.datetime.now() + datetime.timedelta(days=1)", "datetime.datetime.now() + datetime.timedelta(days=1)", 1], ["week_date.strftime('%Y-%m-%d %H:%M')", "week_date.strftime('%m-%d-%Y %H:%M')", 1], ["len(df.columns)", "len(df.columns)", 1], ["output_f.to_csv('output/output.csv', index=False)", "output_f.to_csv('output/output.csv', sep=',')", 1], ["import os\nif not os.path.exists(directory):\n    os.makedirs(directory)", "import os\nif os.path.exists(\"output\"):", 0], ["df.to_csv('your.csv', index=False)", "df.to_csv('your.csv', index=False)", 0], ["os.path.exists(output_file)", "os.path.exists(output_file)", 1], ["r = requests.get('https://jsonplaceholder.typicode.com/posts', params=userid)", "r = requests.get('https://jsonplaceholder.typicode.com/posts', params=userid)", 1], ["print('<unk> %s, <unk>' % (1, 2))", "print('<unk> %s, <unk>' % (1, 2))", 1], ["sys.exit()", "sys.exit()", 1], ["from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y,\n                                                    stratify=y, \n                                                    test_size=0.25)", "from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y,\n                                                    stratify=y, \n                                                    test_size=0.20)", 0], ["# Doing linear regression with leave one out cross val\n\nfrom sklearn import cross_validation, linear_model\nimport numpy as np\n\n# Including this to remind you that it is necessary to use numpy arrays rather \n# than lists otherwise you will get an error\nX_digits = np.array(x)\nY_digits = np.array(y)\n\nloo = cross_validation.LeaveOneOut(len(Y_digits))\n\nregr = linear_model.LinearRegression()\n\nscores = cross_validation.cross_val_score(regr, X_digits, Y_digits, scoring='mean_squared_error', cv=loo,)\n\n# This will print the mean of the list of errors that were output and \n# provide your metric for evaluation\nprint scores.mean()", "# Doing linear regression with leave one out cross val\n    \n    from sklearn import cross_validation, linear_model\n    import numpy as np\n    \n    # Including this to remind you that it is necessary to use numpy arrays rather \n    # than lists otherwise you will get an error\n    X_digits = np.array(x)\n    Y_digits = np.array(y)\n    \n    loo = cross_validation.LeaveOneOut(len(Y_digits))\n    \n    regr = linear_model.LinearRegression()\n    \n    scores = cross_validation.cross_val_score(regr, X_digits, Y_digits, scoring='mean_squared_error', cv=loo,)\n    \n    # This will print the mean of the list of errors that were output and \n    # provide your metric for evaluation\n    print scores.mean()", 0], ["\"\"\"\"\"\".join(choice(ascii_uppercase) for i in range(12))", "randint(1, 20)", 1], ["\"\"\"\"\"\".join(choice(ascii_uppercase) for i in range(12))", "randint(1, 20)", 1], ["import os, errno\n\ntry:\n    os.makedirs(directory)\nexcept OSError as e:\n    if e.errno != errno.EEXIST:\n        raise", "import os, errno\n\ntry:\n    os.makedirs(directory)\nexcept OSError as e:\n    if e.errno != errno.EEXIST:\n        raise", 0], ["os.path.abspath(os.path)", "os.path.abspath(os.path)", 1], ["In [146]: import re\nIn [152]: match = re.search(r'(\\d+/\\d+/\\d+)','The date is 11/12/98')\n\nIn [153]: match.group(1)\nOut[153]: '11/12/98'", "In [146]: import re\nIn [152]: match = re.search(r'(\\d+/\\d+/\\d+)','The date is 11/12/98')\n\nIn [153]: match.group(1)\nOut[153]: '11/12/98'", 0], ["import os\nimport errno\n\nfilename = \"/foo/bar/baz.txt\"\nif not os.path.exists(os.path.dirname(filename)):\n    try:\n        os.makedirs(os.path.dirname(filename))\n    except OSError as exc: # Guard against race condition\n        if exc.errno != errno.EEXIST:\n            raise\n\nwith open(filename, \"w\") as f:\n    f.write(\"FOOBAR\")", "import os\nimport errno\n\nfilename = \"/foo/bar/baz.txt\"\nif not os.path.exists(os.path.dirname(filename)):\n    try:\n        os.makedirs(os.path.dirname(filename))\n    except OSError as exc: # Guard against race condition\n        if exc.errno != errno.EEXIST:\n            raise\n\nwith open(filename, \"w\") as f:\n    f.write(\"FOOBAR\")", 0], ["import os\nif not os.path.exists(directory):\n    os.makedirs(directory)", "import os\nif not os.path.exists(directory):\n    os.makedirs(directory)", 0], [">>> datetime.datetime.now().time()\ndatetime.time(15, 8, 24, 78915)\n\n>>> print(datetime.datetime.now().time())\n15:08:24.789150", ">>> datetime.datetime.now().time()\ndatetime.time(15, 8, 24, 78915)\n\n>>> print(datetime.datetime.now().time())\n15:08:24.789150", 0], [">>> from time import gmtime, strftime\n>>> strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())\n'2009-01-05 22:14:39'", ">>> from time import gmtime, strftime\n>>> strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())\n'2009-01-05 22:14:39'", 0], ["import csv\n\ndef getstuff(filename, criterion):\n    with open(filename, \"rb\") as csvfile:\n        datareader = csv.reader(csvfile)\n        yield next(datareader)  # yield the header row\n        count = 0\n        for row in datareader:\n            if row[3] == criterion:\n                yield row\n                count += 1\n            elif count:\n                # done when having read a consecutive series of rows \n                return", "import csv\n\ndef getstuff(filename, criterion):\n    with open(filename, \"rb\") as csvfile:\n        datareader = csv.reader(csvfile)\n        yield next(datareader)  # yield the header row\n        count = 0\n        for row in datareader:\n            if row[3] == criterion:\n                yield row\n                count += 1\n            elif count:\n                # done when having read a consecutive series of rows \n                return", 0], ["with open('output.csv', 'w', newline='') as f:\n    writer = csv.writer(f)\n    ...", "with open('output.csv', 'w', newline='') as f:\n    writer = csv.writer(f)\n    ...", 0], ["import csv\n\nwith open(\"test.csv\", \"r\") as f:\n    reader = csv.reader(f, delimiter=\"\\t\")\n    for i, line in enumerate(reader):\n        print 'line[{}] = {}'.format(i, line)", "import csv\n\nwith open(\"test.csv\", \"r\") as f:\n    reader = csv.reader(f, delimiter=\"\\t\")\n    for i, line in enumerate(reader):\n        print 'line[{}] = {}'.format(i, line)", 0], ["##text=List of strings to be written to file\nwith open('csvfile.csv','wb') as file:\n    for line in text:\n        file.write(line)\n        file.write('\\n')", "##text=List of strings to be written to file\nwith open('csvfile.csv','wb') as file:\n    for line in text:\n        file.write(line)\n        file.write('\\n')", 0], ["import csv\nwith open(<path to output_csv>, \"wb\") as csv_file:\n        writer = csv.writer(csv_file, delimiter=',')\n        for line in data:\n            writer.writerow(line)", "import csv\nwith open(<path to output_csv>, \"wb\") as csv_file:\n        writer = csv.writer(csv_file, delimiter=',')\n        for line in data:\n            writer.writerow(line)", 0], ["try:\n    os.makedirs(\"path/to/directory\")\nexcept FileExistsError:\n    # directory already exists\n    pass", "try:\n    os.makedirs(\"path/to/directory\")\nexcept FileExistsError:\n    # directory already exists\n    pass", 0], ["import fnmatch\nimport os\n\nmatches = []\nfor root, dirnames, filenames in os.walk('src'):\n    for filename in fnmatch.filter(filenames, '*.c'):\n        matches.append(os.path.join(root, filename))", "import fnmatch\nimport os\n\nmatches = []\nfor root, dirnames, filenames in os.walk('src'):\n    for filename in fnmatch.filter(filenames, '*.c'):\n        matches.append(os.path.join(root, filename))", 0], ["import csv\n\nwith open('file.csv', newline='') as f:\n    reader = csv.reader(f)\n    data = list(reader)\n\nprint(data)", "import csv\n\nwith open('file.csv', newline='') as f:\n    reader = csv.reader(f)\n    data = list(reader)\n\nprint(data)", 0], ["# Python 2\nwith open('/pythonwork/thefile_subset11.csv', 'wb') as outfile:\n    writer = csv.writer(outfile)\n\n# Python 3\nwith open('/pythonwork/thefile_subset11.csv', 'w', newline='') as outfile:\n    writer = csv.writer(outfile)", "# Python 2\nwith open('/pythonwork/thefile_subset11.csv', 'wb') as outfile:\n    writer = csv.writer(outfile)\n\n# Python 3\nwith open('/pythonwork/thefile_subset11.csv', 'w', newline='') as outfile:\n    writer = csv.writer(outfile)", 0], ["random.randint(0, 9)", "print(random.randint(0, 9))", 1], ["print('.', end='')", "print(chr(i+ord('a')), end=' ')", 0], ["os.chdir('data')", "os.chdir('data')", 1], ["import os\nfor file in os.listdir(\"/mydir\"):\n    if file.endswith(\".txt\"):\n        print(os.path.join(\"/mydir\", file))", "for file in os.listdir(\"data\"):\n    if file.endswith(\".txt\"):\n        print(os.path.join(\"data\", file))", 0], ["import codecs\nwith codecs.open(filename, 'r', encoding='utf8') as f:\n    text = f.read()\n# process Unicode text\nwith codecs.open(filename, 'w', encoding='utf8') as f:\n    f.write(text)", "with codecs.open(filename, 'r', encoding='ISO-8859-15') as f:\n    text = f.read()\n# process Unicode text\nwith codecs.open(filename, 'w', encoding='utf8') as f:\n    f.write(text)", 0], ["from shutil import copyfile\ncopyfile(src, dst)", "from shutil import copyfile\n        copyfile(os.path.join(\"data\", file), \"output/\"+file)", 0], ["os.path.exists()", "if not os.path.exists(\"output\"):\n    os.mkdir(\"ouput\")", 1], ["from sklearn.datasets import load_iris\n\niris = load_iris()\n# `iris.data` holds the numerical values\n# `iris.feature_names` holds the numerical column names\n# `iris.target` holds the categorical (species) values (as ints)\n# `iris.target_names` holds the unique categorical names", "from sklearn.datasets import load_iris\n\niris = load_iris()\n# `iris.data` holds the numerical values\n# `iris.feature_names` holds the numerical column names\n# `iris.target` holds the categorical (species) values (as ints)\n# `iris.target_names` holds the unique categorical names", 0], ["from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\nimport numpy as np\n\nclf = RandomForestClassifier() #Initialize with whatever parameters you want to\n\n# 10-Fold Cross validation\nprint np.mean(cross_val_score(clf, X_train, y_train, cv=10))", "from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\nimport numpy as np\n\nclf = RandomForestClassifier() #Initialize with whatever parameters you want to\n\n# 10-Fold Cross validation\nprint np.mean(cross_val_score(clf, X_train, y_train, cv=10))", 0], ["import pandas as pd\nprint pd.read_csv('value.txt')\n\n        Date    price  factor_1  factor_2\n0  2012-06-11  1600.20     1.255     1.548\n1  2012-06-12  1610.02     1.258     1.554\n2  2012-06-13  1618.07     1.249     1.552\n3  2012-06-14  1624.40     1.253     1.556\n4  2012-06-15  1626.15     1.258     1.552\n5  2012-06-16  1626.15     1.263     1.558\n6  2012-06-17  1626.15     1.264     1.572", "import pandas as pd\nprint pd.read_csv('value.txt')\n\n        Date    price  factor_1  factor_2\n0  2012-06-11  1600.20     1.255     1.548\n1  2012-06-12  1610.02     1.258     1.554\n2  2012-06-13  1618.07     1.249     1.552\n3  2012-06-14  1624.40     1.253     1.556\n4  2012-06-15  1626.15     1.258     1.552\n5  2012-06-16  1626.15     1.263     1.558\n6  2012-06-17  1626.15     1.264     1.572", 0], ["df.groupby('User').agg({'A': x.mean})", "df.groupby('User')", 1], ["import numpy as np\nimport matplotlib.pyplot as plt\n\n#makes the data\ny1 = np.random.normal(-2, 2, 1000)\ny2 = np.random.normal(2, 2, 5000)\ncolors = ['b','g']\n\n#plots the histogram\nfig, ax1 = plt.subplots()\nax1.hist([y1,y2],color=colors)\nax1.set_xlim(-10,10)\nax1.set_ylabel(\"Count\")\nplt.tight_layout()\nplt.show()", "#makes the data\ncolors = ['b','g']\n\n#plots the histogram\nfig,(ax0,ax1,ax2) = plt.subplots(nrows=1 , ncols=3)\n#ax1.hist([y1,y2],color=colors)\n#ax1.set_xlim(-10,10)\n#ax1.set_ylabel(\"Count\")\n#plt.tight_layout()\n#plt.show()", 0], ["import numpy as np\nimport matplotlib.pyplot as plt\n\nN = 3\nind = np.arange(N)  # the x locations for the groups\nwidth = 0.27       # the width of the bars\n\nfig = plt.figure()\nax = fig.add_subplot(111)\n\nyvals = [4, 9, 2]\nrects1 = ax.bar(ind, yvals, width, color='r')\nzvals = [1,2,3]\nrects2 = ax.bar(ind+width, zvals, width, color='g')\nkvals = [11,12,13]\nrects3 = ax.bar(ind+width*2, kvals, width, color='b')\n\nax.set_ylabel('Scores')\nax.set_xticks(ind+width)\nax.set_xticklabels( ('2011-Jan-4', '2011-Jan-5', '2011-Jan-6') )\nax.legend( (rects1[0], rects2[0], rects3[0]), ('y', 'z', 'k') )\n\ndef autolabel(rects):\n    for rect in rects:\n        h = rect.get_height()\n        ax.text(rect.get_x()+rect.get_width()/2., 1.05*h, '%d'%int(h),\n                ha='center', va='bottom')\n\nautolabel(rects1)\nautolabel(rects2)\nautolabel(rects3)\n\nplt.show()", "import numpy as np\nimport matplotlib.pyplot as plt\n\nN = 3\nind = np.arange(N)  # the x locations for the groups\nwidth = 0.27       # the width of the bars\n\nfig = plt.figure()\nax = fig.add_subplot(111)\n\nyvals = [4, 9, 2]\nrects1 = ax.bar(ind, yvals, width, color='r')\nzvals = [1,2,3]\nrects2 = ax.bar(ind+width, zvals, width, color='g')\nkvals = [11,12,13]\nrects3 = ax.bar(ind+width*2, kvals, width, color='b')\n\nax.set_ylabel('Scores')\nax.set_xticks(ind+width)\nax.set_xticklabels( ('2011-Jan-4', '2011-Jan-5', '2011-Jan-6') )\nax.legend( (rects1[0], rects2[0], rects3[0]), ('y', 'z', 'k') )\n\ndef autolabel(rects):\n    for rect in rects:\n        h = rect.get_height()\n        ax.text(rect.get_x()+rect.get_width()/2., 1.05*h, '%d'%int(h),\n                ha='center', va='bottom')\n\nautolabel(rects1)\nautolabel(rects2)\nautolabel(rects3)\n\nplt.show()", 0], ["df = pd.read_csv('<unk>', header=None)", "df = pd.read_csv('data.csv',header=None)\nprint(df)", 1], ["import pandas as pd\nf=pd.read_csv(\"test.csv\")\nkeep_col = ['day','month','lat','long']\nnew_f = f[keep_col]\nnew_f.to_csv(\"newFile.csv\", index=False)", "import pandas as pd\nf=pd.read_csv(\"data.csv\")\nkeep_col = ['day','month','lat','long']\nnew_f = f[keep_col]\nnew_f.to_csv(\"newFile.csv\", index=False)", 0], ["import os\n\nos.rename('a.txt', 'b.kml')", "os.rename('a.txt', 'b.kml')", 0], ["requests.get(html, headers={1}.__class__())", "import requests\n\nurl = 'https://en.wikipedia.org/wiki/List_of_countries_and_dependencies_by_population'\nx = requests.get(url)\nprint(x)", 1], ["tr.findAll('td', style='tr')", "tr.findAll('td', style='tr')", 1], ["import csv\ntoCSV = [{'name':'bob','age':25,'weight':200},\n         {'name':'jim','age':31,'weight':180}]\nkeys = toCSV[0].keys()\nwith open('people.csv', 'w', newline='')  as output_file:\n    dict_writer = csv.DictWriter(output_file, keys)\n    dict_writer.writeheader()\n    dict_writer.writerows(toCSV)", "import csv\ntoCSV = [{'name':'bob','age':25,'weight':200},\n         {'name':'jim','age':31,'weight':180}]\nkeys = toCSV[0].keys()\nwith open('people.csv', 'w', newline='')  as output_file:\n    dict_writer = csv.DictWriter(output_file, keys)\n    dict_writer.writeheader()\n    dict_writer.writerows(toCSV)", 0], ["import urllib\nurllib.urlretrieve(\"http://www.gunnerkrigg.com//comics/00000001.jpg\", \"00000001.jpg\")", "urllib.urlretrieve(\"http://www.gunnerkrigg.com//comics/00000001.jpg\", \"00000001.jpg\")", 0], [">>> keys = ['a', 'b', 'c']\n>>> values = [1, 2, 3]\n>>> dictionary = dict(zip(keys, values))\n>>> print(dictionary)\n{'a': 1, 'b': 2, 'c': 3}", "dictionary = dict(zip(letters, numbers))\nprint(dictionary)", 0], ["def merge_two_dicts(x, y):\n      z = x.copy()   # start with x's keys and values\n      z.update(y)    # modifies z with y's keys and values & returns None\n      return z", "", 0], ["sorted(var_1, key=sorted)", "", 1], ["sorted(list, key=sorted)", "print(sorted(values, key=sorted)", 1], ["sorted(values, key=values.index)", "print(sorted(values, key=values.index))", 1], ["import httplib2\nfrom bs4 import BeautifulSoup, SoupStrainer\n\nhttp = httplib2.Http()\nstatus, response = http.request('http://www.nytimes.com')\n\nfor link in BeautifulSoup(response, parse_only=SoupStrainer('a')):\n    if link.has_attr('href'):\n        print(link['href'])", "http = httplib2.Http()\nstatus, response = http.request('https://frankxfz.me/snapshot.html')\n\nfor link in BeautifulSoup(response, parse_only=SoupStrainer('a')):\n    if link.has_attr('href'):\n        print(link['href'])", 0], [">>> 125650429603636838/(2**53)\n13.949999999999999\n\n>>> 234042163/(2**24)\n13.949999988079071\n\n>>> a = 13.946\n>>> print(a)\n13.946\n>>> print(\"%.2f\" % a)\n13.95\n>>> round(a,2)\n13.949999999999999\n>>> print(\"%.2f\" % round(a, 2))\n13.95\n>>> print(\"{:.2f}\".format(a))\n13.95\n>>> print(\"{:.2f}\".format(round(a, 2)))\n13.95\n>>> print(\"{:.15f}\".format(round(a, 2)))\n13.949999999999999", "", 1], [">>> a = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n>>> del a[-1]\n>>> a\n[0, 1, 2, 3, 4, 5, 6, 7, 8]", "del companies[n]\n        del avg_price[n]\n        del max_price[n]\n        del min_price[n]\n        del cars[n]", 0], ["dict(zip(keys, values))", "dict = zip(index, scores)", 1], ["random.randint(0, 7)", "random.randint(0, 7)", 1], ["from random import randrange\nprint(randrange(10))", "from random import randrange\nprint(randrange(10))", 0], ["dict((k, ':') for k, v in list(d.items()))", "dict((k, ':') for k, v in list(d.items()))", 1], ["df.drop('column_name', axis=1, inplace=True)", "df.drop('column_name', axis=1, inplace=True)", 0], ["plt.savefig('save')", "plt.savefig('save')", 1], [">>> from time import gmtime, strftime\n>>> strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())\n'2009-01-05 22:14:39'", "from time import gmtime, strftime\n\nprint(strftime(\"%Y-%m-%d %H:%M:%S\", gmtime()))", 0], ["\"\"\"time\"\"\".strftime('%Y-%m-%d %H:%M:%S')", "\"\"\"time\"\"\".strftime('%Y-%m-%d %H:%M:%S')", 1], ["now = datetime.datetime.now().strftime('%H:%M:%S')", "now = datetime.datetime.now().strftime('%H:%M:%S')", 1], ["with open('data.txt', 'r') as file:\n    data = file.read().replace('\\n', '')", "with open('data.txt', 'r') as file:\n    data = file.read().replace('\\n', '')", 0], ["data_uri = open('11.png', 'rb').read().encode('base64').replace('\\n', '')\nimg_tag = '<img src=\"data:image/png;base64,{0}\">'.format(data_uri)\n\nprint(img_tag)", "data_uri = open('11.png', 'rb').read().encode('base64').replace('\\n', '')\nimg_tag = '<img src=\"data:image/png;base64,{0}\">'.format(data_uri)\n\nprint(img_tag)", 0], ["df.groupby(np.arange(len(mean)) // 2 + 1, axis=1).mean()", "df.groupby(np.arange(len(mean)) // 2 + 1, axis=1).mean()", 1], ["pd.read_csv('<unk>', sep='')", "pd.read_csv('<unk>', sep='')", 1], ["df.to_csv(file_name, sep='\\t')", "df.to_csv(file_name, sep='\\t')", 0], ["numbers = list(zip(characters, numbers))", "pairs = list(zip(characters, numbers))", 1], ["datetime.datetime.now().strftime('%Y-%m-%d')", "datetime.datetime.now().strftime('%Y-%m-%d')", 1], ["a = [a_list]", "a = [a_list]", 1], ["random.randint(0, 7)", "random.randint(0, 7)", 1], [">>> import string\n>>> string.ascii_letters\n'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'\n>>> import random\n>>> random.choice(string.ascii_letters)\n'j'", ">>> import string\n    >>> string.ascii_letters\n    'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'\n    >>> import random\n    >>> random.choice(string.ascii_letters)\n    'j'", 0], ["s.sort(key = operator.itemgetter(1, 2))", "s.sort(key = operator.itemgetter(1, 2))", 0], ["import csv\nreader = csv.reader(open('output.csv', 'rb'))\nreader1 = csv.reader(open('output1.csv', 'rb'))\nwriter = csv.writer(open('appended_output.csv', 'wb'))\nfor row in reader:\n    row1 = reader1.next()\n    writer.writerow(row + row1)", "import csv\nreader = csv.reader(open('output.csv', 'rb'))\nreader1 = csv.reader(open('output1.csv', 'rb'))\nwriter = csv.writer(open('appended_output.csv', 'wb'))\nfor row in reader:\n    row1 = reader1.next()\n    writer.writerow(row + row1)", 0], ["import csv\n\nwith open(..., 'wb') as myfile:\n    wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n    wr.writerow(mylist)", "import csv\n\nwith open(..., 'wb') as myfile:\n    wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n    wr.writerow(mylist)", 0], ["writer.writerow(write)", "writer.writerow(write)", 1], ["mmap.write('\\n')", "mmap.write('\\n')", 1], ["del r[2]\n            wtr.writerow( r )", "del r[2]\n                wtr.writerow( r )", 0], ["pd.read_csv('<unk>', sep=',', header=None)", "pd.read_csv('<unk>', sep=',', header=None)", 1], ["df = df.drop('column_name', 1)", "df = df.drop('column_name', 1)", 0], ["from os import walk\n\nf = []\nfor (dirpath, dirnames, filenames) in walk(mypath):\n    f.extend(filenames)\n    break", "from os import walk\n\nf = []\nfor (dirpath, dirnames, filenames) in walk(mypath):\n    f.extend(filenames)\n    break", 0], ["import os\n arr = os.listdir()\n print(arr)\n\n >>> ['$RECYCLE.BIN', 'work.txt', '3ebooks.txt', 'documents']", "import os\n arr = os.listdir()\n print(arr)\n\n >>> ['$RECYCLE.BIN', 'work.txt', '3ebooks.txt', 'documents']", 0], ["re.findall('\\\\[(.*?)\\\\]', s)", "re.findall('\\\\[(.*?)\\\\]', s)", 1], ["import re\nfrom datetime import datetime\n\nmatch = re.search(r'\\d{4}-\\d{2}-\\d{2}', text)\ndate = datetime.strptime(match.group(), '%Y-%m-%d').date()", "import re\nfrom datetime import datetime\n\nmatch = re.search(r'\\d{4}-\\d{2}-\\d{2}', text)\ndate = datetime.strptime(match.group(), '%Y-%m-%d').date()", 0], ["import re\nline = re.sub(r\"</?\\[\\d+>\", \"\", line)", "import re\n        line = re.sub(r\"</?\\[\\d+>\", \"\", line)", 0], ["import datetime\nt = datetime.datetime(2012, 2, 23, 0, 0)\nt.strftime('%m/%d/%Y')", "import datetime\n        t = datetime.datetime(2012, 2, 23, 0, 0)\n        t.strftime('%m/%d/%Y')", 0], ["import shutil\nshutil.copy2('/src/dir/file.ext', '/dst/dir/newname.ext') # complete target filename given\nshutil.copy2('/src/file.ext', '/dst/dir') # target filename is /dst/dir/file.ext", "import shutil\n        shutil.copy2('/src/dir/file.ext', '/dst/dir/newname.ext') # complete target filename given\n        shutil.copy2('/src/file.ext', '/dst/dir') # target filename is /dst/dir/file.ext", 0], ["import os\nif not os.path.exists(directory):\n    os.makedirs(directory)", "import os\n        if not os.path.exists(directory):\n            os.makedirs(directory)", 0], ["file = open('myfile.dat', 'w+')", "file = open('myfile.dat', 'w+')", 0], ["import os\nold_file = os.path.join(\"directory\", \"a.txt\")\nnew_file = os.path.join(\"directory\", \"b.kml\")\nos.rename(old_file, new_file)", "import os\n        old_file = os.path.join(\"directory\", \"a.txt\")\n        new_file = os.path.join(\"directory\", \"b.kml\")\n        os.rename(old_file, new_file)", 0], ["with open('somefile.txt', 'a') as the_file:\n    the_file.write('Hello\\n')", "with open('somefile.txt', 'a') as the_file:\n            the_file.write('Hello\\n')", 0], ["df = pd.read_csv('my.csv', header=None)", "df = pd.read_csv('my.csv', header=None)", 1], ["import pandas as pd\ndata_df = pd.DataFrame('highfrequency2.csv')\nprint(data_df.columns)", "import pandas as pd\ndata_df = pd.DataFrame('highfrequency2.csv')\nprint(data_df.columns)", 0], ["g = df['b'].unique()", "g = df['b'].unique()", 0], ["week_grouped = df.groupby('week')\nweek_grouped.sum().reset_index().to_csv('week_grouped.csv')", "week_grouped = df.groupby('week')\nweek_grouped.sum().reset_index().to_csv('week_grouped.csv')", 0], ["In [58]: df.groupby(['cluster']).mean()\nOut[58]:\n              time\ncluster\n1        12.333333\n2        54.000000\n3         6.000000", "In [58]: df.groupby(['cluster']).mean()\nOut[58]:\n              time\ncluster\n1        12.333333\n2        54.000000\n3         6.000000", 0], ["In [202]:\n\ndf.groupby('A').agg(np.std, ddof=0)\n\nOut[202]:\n     B  values\nA             \n1  0.5     2.5\n2  0.5     2.5\n\nIn [203]:\n\ndf.groupby('A').agg(np.std, ddof=1)\n\nOut[203]:\n          B    values\nA                    \n1  0.707107  3.535534\n2  0.707107  3.535534", "In [202]:\n\ndf.groupby('A').agg(np.std, ddof=0)\n\nOut[202]:\n     B  values\nA             \n1  0.5     2.5\n2  0.5     2.5\n\nIn [203]:\n\ndf.groupby('A').agg(np.std, ddof=1)\n\nOut[203]:\n          B    values\nA                    \n1  0.707107  3.535534\n2  0.707107  3.535534", 0], ["\"\"\" \"\"\".rstrip('\\r\\n')", "\"\"\" \"\"\".rstrip('\\r\\n')", 1], ["df.to_csv('pandasfile.csv', float_format='%.3f')", "df.to_csv('pandasfile.csv', float_format='%.3f')", 0], ["df = df.drop(df.columns[[0, 1, 3]], axis=1)  # df.columns is zero-based pd.Index", "df = df.drop(df.columns[[0, 1, 3]], axis=1)  # df.columns is zero-based pd.Index", 0], ["re.findall('<unk>', '\u0440\u0430\u0437')", "re.findall('<unk>', '\u0440\u0430\u0437')", 1], ["''.join(random.choices(string.ascii_uppercase + string.digits, k=N))", "import string\nimport random\n''.join(random.choices(string.ascii_lowercase, k=1))", 0], ["print(random.randint(0, 50))", "print(random.randint(1,20))", 1], ["letters = [(x + y) for x, y in zip(letters, integers)]", "dic = {}\nfor i in range(100):\n    letter = letters[i]\n    num = integers[i]\n\n    if letter in dic:\n        dic[letter].append(num)\n    else:\n        dic[letter] = [num]\nprint(dic)", 1], ["In [1]: import collections\n\nIn [2]: d = {2:3, 1:89, 4:5, 3:0}\n\nIn [3]: od = collections.OrderedDict(sorted(d.items()))\n\nIn [4]: od\nOut[4]: OrderedDict([(1, 89), (2, 3), (3, 0), (4, 5)])", "In [1]: import collections\n\nIn [2]: d = {2:3, 1:89, 4:5, 3:0}\n\nIn [3]: od = collections.OrderedDict(sorted(d.items()))\n\nIn [4]: od\nOut[4]: OrderedDict([(1, 89), (2, 3), (3, 0), (4, 5)])", 0], ["In [1]: import collections\n\nIn [2]: d = {2:3, 1:89, 4:5, 3:0}\n\nIn [3]: od = collections.OrderedDict(sorted(d.items()))\n\nIn [4]: od\nOut[4]: OrderedDict([(1, 89), (2, 3), (3, 0), (4, 5)])", "for key in sorted(dic.keys()):\n    print(key, ' '.join(map(str, sorted(dic[key]))))", 0], ["df = pd.read_csv('data.csv', sep=',', header=None)", "import pandas as pd\ndf = pd.read_csv('data.csv', sep=',', header=None)", 1], ["df = df.loc[-1]", "df = df.iloc[1:len(df)-1]", 1], ["df.to_csv(file_name, sep='\\t')", "file_name = 'output/output.csv'\ndf.to_csv(file_name, sep=',')", 0], ["import os\nimport shutil\nsrc_files = os.listdir(src)\nfor file_name in src_files:\n    full_file_name = os.path.join(src, file_name)\n    if os.path.isfile(full_file_name):\n        shutil.copy(full_file_name, dest)", "from distutils.dir_util import copy_tree\n\nsrc = 'data'\ndest = 'output'\n\n# copy subdirectory example\nfromDirectory = src\ntoDirectory =  dest\n\ncopy_tree(fromDirectory, toDirectory)", 0], ["import requests\nr = requests.get(\"http://example.com/foo/bar\")", "import requests\nr = requests.get(\"http://example.com/foo/bar\")", 0], ["r = requests.get(url, verify=False)", "import requests\nr = requests.get(url)", 1], ["from BeautifulSoup import BeautifulSoup\n\nhtml = '''<a href=\"some_url\">next</a>\n<span class=\"class\"><a href=\"another_url\">later</a></span>'''\n\nsoup = BeautifulSoup(html)\n\nfor a in soup.find_all('a', href=True):\n    print \"Found the URL:\", a['href']", "for a in soup.find_all('a', href=True):\n    print \"Found the URL:\", a['href']", 0], ["for strong_tag in soup.find_all('strong'):\n    print(strong_tag.text, strong_tag.next_sibling)", "for strong_tag in soup.find_all('b'):\n    print(strong_tag.text)", 0], ["soup.find_all(\"a\", string=\"Elsie\")\n# [<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>]", "for ita in soup.find_all('span'):\n    print(ita.text)\n    # [<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>]", 0], ["''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(N))", "random_letters = ''.join(random.choice(string.ascii_lowercase) for _ in range(100))\nprint(random_letters)", 0], ["print(random.randint(0, 100))", "random_numbers = [random.randint(1, 20) for _ in range(100)]", 1], ["random_numbers = dict((key, value) for key, value in list(random_letters.\n    items()))", "dic = dict((key, value) for key, value in zip(random_letters, random_numbers))", 1], ["print(sorted(list(dic.items()), key=k))", "print(sorted(list(dic.keys())))", 1], ["print('\\n'.join(str(key) for line in dic))", "print('\\n'.join(str(key) for key in dic))", 1], ["df = pd.read_csv('data.csv', sep=',', header=None)", "df = pd.read_csv('data.csv', sep=',', header=None)", 1], ["df.drop('column_name', axis=1, inplace=True)", "output = df.drop('id', axis=1)\noutput = output.drop('ip_address', axis=1)", 0], ["output.to_csv('output', index=False)", "output.to_csv('output.csv', index=False)", 1], ["copyfile(src_path, dest_path)", "copyfile(src_path, dest_path)", 1], ["os.path.isfile(file)", "if os.path.isfile(file):\n        pass", 1], ["final_data.to_csv('price.csv')", "final_data.to_csv('price.csv')", 1], [">>> import datetime\n>>> datetime.datetime.today()\ndatetime.datetime(2012, 3, 23, 23, 24, 55, 173504)\n>>> datetime.datetime.today().weekday()\n4", ">>> import datetime\n>>> datetime.datetime.today()\ndatetime.datetime(2012, 3, 23, 23, 24, 55, 173504)\n>>> datetime.datetime.today().weekday()\n4", 0], ["from datetime import datetime, timedelta\n\nd = datetime.today() - timedelta(days=days_to_subtract)", "from datetime import datetime, timedelta\n\nd = datetime.today() + timedelta(days=7)", 0], ["time.strftime('%Y-%m-%d %H:%M:%S', gmtime())", "time.strftime('%Y-%m-%d %H:%M:%S', gmtime())", 1], ["for i, v in enumerate(y):\n    ax.text(v + 3, i + .25, str(v), color='blue', fontweight='bold')", "for i, v in enumerate(y):\n    ax.text(v + 3, i + .25, str(v), color='blue', fontweight='bold')", 0], [">>> from time import gmtime, strftime\n>>> strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())\n'2009-01-05 22:14:39'", ">>> from time import gmtime, strftime\n>>> strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())\n'2009-01-05 22:14:39'", 0], [">>> from time import gmtime, strftime\n>>> strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())\n'2009-01-05 22:14:39'", ">>> from time import gmtime, strftime\n>>> strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())\n'2009-01-05 22:14:39'", 0], ["timedelta(hours=5) - timedelta(hours=2)", "timedelta(hours=5) - timedelta(hours=2)", 1], ["datetime.datetime.combine(datetime.datetime.now(), datetime.datetime.now() +\n    datetime.timedelta(days=1))", "datetime.datetime.combine(datetime.datetime.now(), datetime.datetime.now() +\n    datetime.timedelta(days=1))", 1], [">>> from time import gmtime, strftime\n>>> strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())\n'2009-01-05 22:14:39'", ">>> from time import gmtime, strftime\n>>> strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())\n'2009-01-05 22:14:39'", 0], ["print(codecs.open('file.txt', 'w', encoding='utf-8').decode('utf-8'))", "print(codecs.open('file.txt', 'w', encoding='utf-8').decode('utf-8'))", 1], [">>> u8 = v.decode(\"iso-8859-1\").encode(\"utf-8\")\n>>> u8\n'\\xc3\\x84pple'    # convert iso-8859-1 to unicode to utf-8\n\n>>> tell_me_about(u8)\n(<type 'str'>, '\\xc3\\x84pple')\n\n>>> u16 = v.decode('iso-8859-1').encode('utf-16')\n>>> tell_me_about(u16)\n(<type 'str'>, '\\xff\\xfe\\xc4\\x00p\\x00p\\x00l\\x00e\\x00')\n\n>>> tell_me_about(u8.decode('utf8'))\n(<type 'unicode'>, u'\\xc4pple')\n\n>>> tell_me_about(u16.decode('utf16'))\n(<type 'unicode'>, u'\\xc4pple')", ">>> u8 = v.decode(\"iso-8859-1\").encode(\"utf-8\")\n        >>> u8\n        '\\xc3\\x84pple'    # convert iso-8859-1 to unicode to utf-8\n        \n        >>> tell_me_about(u8)\n        (<type 'str'>, '\\xc3\\x84pple')\n        \n        >>> u16 = v.decode('iso-8859-1').encode('utf-16')\n        >>> tell_me_about(u16)\n        (<type 'str'>, '\\xff\\xfe\\xc4\\x00p\\x00p\\x00l\\x00e\\x00')\n        \n        >>> tell_me_about(u8.decode('utf8'))\n        (<type 'unicode'>, u'\\xc4pple')\n        \n        >>> tell_me_about(u16.decode('utf16'))\n        (<type 'unicode'>, u'\\xc4pple')", 0], [">>> u8 = v.decode(\"iso-8859-1\").encode(\"utf-8\")\n>>> u8\n'\\xc3\\x84pple'    # convert iso-8859-1 to unicode to utf-8\n\n>>> tell_me_about(u8)\n(<type 'str'>, '\\xc3\\x84pple')\n\n>>> u16 = v.decode('iso-8859-1').encode('utf-16')\n>>> tell_me_about(u16)\n(<type 'str'>, '\\xff\\xfe\\xc4\\x00p\\x00p\\x00l\\x00e\\x00')\n\n>>> tell_me_about(u8.decode('utf8'))\n(<type 'unicode'>, u'\\xc4pple')\n\n>>> tell_me_about(u16.decode('utf16'))\n(<type 'unicode'>, u'\\xc4pple')", ">>> u8 = v.decode(\"iso-8859-1\").encode(\"utf-8\")\n>>> u8\n'\\xc3\\x84pple'    # convert iso-8859-1 to unicode to utf-8\n\n>>> tell_me_about(u8)\n(<type 'str'>, '\\xc3\\x84pple')\n\n>>> u16 = v.decode('iso-8859-1').encode('utf-16')\n>>> tell_me_about(u16)\n(<type 'str'>, '\\xff\\xfe\\xc4\\x00p\\x00p\\x00l\\x00e\\x00')\n\n>>> tell_me_about(u8.decode('utf8'))\n(<type 'unicode'>, u'\\xc4pple')\n\n>>> tell_me_about(u16.decode('utf16'))\n(<type 'unicode'>, u'\\xc4pple')", 0], ["import encodings.idna", "import encodings.idna", 0], ["x = {1: 2, 3: 4, 4: 3, 2: 1, 0: 0}\nsorted_x = sorted(x.items(), key=lambda kv: kv[1])", "x = {1: 2, 3: 4, 4: 3, 2: 1, 0: 0}\nsorted_x = sorted(x.items(), key=lambda kv: kv[1])", 0], ["dict((k, ':') for k, v in list(d.items()))", "dict((k, ':') for k, v in list(d.items()))", 1], ["datetime.datetime.now().strftime('%a')", "date = atetime.datetime.now().strftime('%a')", 1], ["datetime.datetime.combine(date, datetime.time())", "date = datetime.datetime.combine(date datetime.time())", 1], ["today = datetime.datetime.utcnow().date()", "today = datetime.datetime.utcnow().date()", 1], ["now = datetime.datetime.utcnow().date()", "now = datetime.datetime.utcnow().time()", 1], ["from datetime import datetime, timedelta\n\nd = datetime.today() - timedelta(days=days_to_subtract)", "from datetime import datetime, timedelta\n\nd = datetime.today() - timedelta(days=7)", 0], ["df = pd.read_csv('data.csv', sep=',', header=None)", "df = pd.read_csv('data.csv', sep=',', header=None)", 1], ["df = df.drop('column_name', 1)", "df = df.drop('column_name', 1)", 0], ["writer.writerow(file)", "writer.writerow(file)", 1], ["df = pd.read_csv('<unk>', quotechar=',')", "df = pd.read_csv('<unk>', quotechar=',')", 1], ["df.to_csv(file_name, sep='\\t')", "df.to_csv(file_name, sep='\\t')", 0]]